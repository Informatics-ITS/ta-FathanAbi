{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a5a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "GPU Name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from HSI_class import HSI\n",
    "import createSample as CS\n",
    "import augmentation as aug\n",
    "\n",
    "import simsiam.loader\n",
    "import random\n",
    "import zeroPadding\n",
    "start_time = time.time()\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "\n",
    "# If available, print the GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    \n",
    "sample_per_class = 5\n",
    "num_per_category_augment_1 = 10\n",
    "num_per_category_augment_2 = 10\n",
    "patch_size = 9\n",
    "n_category = 2\n",
    "band_size = 224\n",
    "base_encoder = 'vgg16'\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "batch_size = 20\n",
    "test_size = 0.5\n",
    "\n",
    "random_indices = 1\n",
    "\n",
    "seeded_run = True\n",
    "seed = 10\n",
    "\n",
    "mode = \"full\"\n",
    "project_path = r\"C:\\Users\\Asus TUF\\Documents\\code\\TA\"\n",
    "# project_path = r\"D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25da8a0f-8f90-4f9e-9a04-991692e9ebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed has been set\n",
      "seet used: 10\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # PyTorch determinism\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "if seeded_run:\n",
    "    set_seed(seed)\n",
    "    print(\"seed has been set\")\n",
    "    print(f\"seet used: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "578786fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM01.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM02.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM03.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM04.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM05.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM06.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM07.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM08.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM09.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM10.mat\n",
      "random: 1\n",
      "generating random indices\n",
      "hsi shape\n",
      "(1243, 684, 224)\n",
      "creating 5 Randomly chosen 0 indices:\n",
      "creating 5 Randomly chosen 1 indices:\n",
      "indices 0 used: [(np.int64(910), np.int64(192)), (np.int64(51), np.int64(255)), (np.int64(689), np.int64(202)), (np.int64(772), np.int64(547)), (np.int64(920), np.int64(471))]\n",
      "indices 1 used: [(np.int64(22), np.int64(455)), (np.int64(170), np.int64(145)), (np.int64(410), np.int64(233)), (np.int64(1055), np.int64(123)), (np.int64(469), np.int64(582))]\n",
      "number of element equal 0 5\n",
      "number of element equal 1 5\n",
      "x_train shape: (10, 9, 9, 224)\n",
      "y_train shape: (10,)\n",
      "hasil augmentasi 1 shape: (20, 9, 9, 224)\n",
      "label augmentai 1 shape: (20,)\n",
      "hasil augmentasi 2 shape: (20, 9, 9, 224)\n",
      "label augmentasi 2 shape: (20,)\n",
      "label augment:\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "hasil augmentasi gabungan untuk training: (40, 9, 9, 224)\n",
      "label augmentasi gabungan: (40,)\n",
      "Element 0 occurs 20 times.\n",
      "Element 1 occurs 20 times.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = rf\"{project_path}\\Hyperspectral oil spill detection datasets\"\n",
    "\n",
    "dataset = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if i > 9:\n",
    "        break\n",
    "    file_path = os.path.join(dataset_path, filename)\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        hsi = HSI(file_path)\n",
    "        dataset.append(hsi)\n",
    "    i += 1\n",
    "\n",
    "train_hsi = dataset[0]\n",
    "patch_size = patch_size\n",
    "half_patch = patch_size // 2\n",
    "sample_per_class = sample_per_class\n",
    "\n",
    "train_indices_0 = []\n",
    "train_indices_1 = []\n",
    "\n",
    "print(f\"random: {random_indices}\")\n",
    "\n",
    "if random_indices:\n",
    "    print(\"generating random indices\")\n",
    "    selected_patches_0, selected_patches_1, train_indices_0, train_indices_1 = CS.createSample(train_hsi, patch_size, sample_per_class)\n",
    "else:\n",
    "    print(\"using generated indices\")\n",
    "    train_indices_0 = [(np.int64(188), np.int64(124)), (np.int64(523), np.int64(150)), (np.int64(1003), np.int64(474)), (np.int64(616), np.int64(508)), (np.int64(905), np.int64(552))]\n",
    "    train_indices_1 = [(np.int64(106), np.int64(606)), (np.int64(297), np.int64(468)), (np.int64(926), np.int64(35)), (np.int64(536), np.int64(519)), (np.int64(508), np.int64(442))]\n",
    "\n",
    "    selected_patches_0, selected_patches_1 = CS.getSample(train_hsi, patch_size, sample_per_class, train_indices_0, train_indices_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_indices = train_indices_0 +  train_indices_1\n",
    "\n",
    "# Concatenating along axis 0\n",
    "x_train = np.concatenate((selected_patches_0, selected_patches_1), )\n",
    "\n",
    "y_train = np.array([])\n",
    "\n",
    "gt = train_hsi.gt\n",
    "for indice in train_indices:\n",
    "    # print(gt[indice[0]][indice[1]])\n",
    "    y_train = np.append(y_train, gt[indice[0]][indice[1]])\n",
    "\n",
    "count = np.count_nonzero(y_train == 0)  # Count elements equal to 0\n",
    "print(f'number of element equal 0 {count}')\n",
    "\n",
    "count = np.count_nonzero(y_train == 1)  # Count elements equal to 1\n",
    "print(f'number of element equal 1 {count}')\n",
    "\n",
    "# Print shape to verify\n",
    "print(f\"x_train shape: {x_train.shape}\")  # Expected output: (10, 9, 9, 224)\n",
    "print(f\"y_train shape: {y_train.shape}\") \n",
    "\n",
    "\n",
    "n_category = n_category\n",
    "band_size = band_size\n",
    "num_per_category_augment_1 = num_per_category_augment_1\n",
    "num_per_category_augment_2 = num_per_category_augment_2\n",
    "\n",
    "data_augment1, label_augment1 = aug.Augment_data(x_train, y_train, n_category, patch_size, band_size, num_per_category_augment_1)\n",
    "\n",
    "data_augment2, label_augment2 = aug.Augment_data2(x_train, y_train, n_category, patch_size, band_size, num_per_category_augment_2)\n",
    "\n",
    "print(f\"hasil augmentasi 1 shape: {data_augment1.shape}\")\n",
    "print(f\"label augmentai 1 shape: {label_augment1.shape}\")\n",
    "\n",
    "print(f\"hasil augmentasi 2 shape: {data_augment2.shape}\")\n",
    "print(f\"label augmentasi 2 shape: {label_augment2.shape}\")\n",
    "\n",
    "print(\"label augment:\")\n",
    "print(label_augment1)\n",
    "print(label_augment2)\n",
    "\n",
    "data_augment = np.concatenate((data_augment1, data_augment2))\n",
    "label_augment = np.concatenate((label_augment1, label_augment2))\n",
    "\n",
    "print(f\"hasil augmentasi gabungan untuk training: {data_augment.shape}\")\n",
    "print(f\"label augmentasi gabungan: {label_augment.shape}\")\n",
    "\n",
    "\n",
    "# Count occurrences of each unique element\n",
    "counts = np.bincount(label_augment)\n",
    "\n",
    "# Print results\n",
    "for i, count in enumerate(counts):\n",
    "    print(f\"Element {i} occurs {count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cab1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    \"\"\"\n",
    "    Build a SimSiam model.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_encoder, spectral_band, dim=2048, pred_dim=512):\n",
    "        \"\"\"\n",
    "        dim: feature dimension (default: 2048)\n",
    "        pred_dim: hidden dimension of the predictor (default: 512)\n",
    "        \"\"\"\n",
    "        super(SimSiam, self).__init__()\n",
    "    \n",
    "        self.encoder = base_encoder(pretrained=True)\n",
    "\n",
    "        self.encoder.features = nn.Sequential(*list(self.encoder.features.children())[28:])\n",
    "        self.encoder.features[0] = nn.Conv2d(spectral_band, 512, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.encoder.features[1] = nn.ReLU(inplace=True)\n",
    "        self.encoder.features[2] = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.encoder.classifier[0] = nn.Linear(in_features=25088, out_features=512, bias=True)\n",
    "        self.encoder.classifier[1] = nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.encoder.classifier[3] = nn.Linear(in_features=512, out_features=512, bias=False)\n",
    "        self.encoder.classifier[4] = nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        # Modify the classifier to match the desired output dimensions\n",
    "        # self.encoder.classifier[0] = nn.Linear(512, 4096, bias=True)\n",
    "        self.encoder.classifier[6] = nn.Linear(512, dim)\n",
    "\n",
    "        # # Fix: Get the correct input dimension from VGG16 classifier\n",
    "        prev_dim = self.encoder.classifier[3].out_features\n",
    "\n",
    "        # Fix: Assign modified layers to classifier instead of non-existing 'fc'\n",
    "        self.encoder.classifier[6] = nn.Sequential(\n",
    "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(prev_dim),\n",
    "                                        nn.ReLU(inplace=True), # first layer\n",
    "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(prev_dim),\n",
    "                                        nn.ReLU(inplace=True), # second layer\n",
    "                                        self.encoder.classifier[6],\n",
    "                                        nn.BatchNorm1d(dim, affine=False)) # output layer# output layer\n",
    "                                        \n",
    "        self.encoder.classifier[6][6].bias.requires_grad = False\n",
    "        # self.projector[6].bias.requires_grad = False\n",
    "\n",
    "        # build a 3-layer projector\n",
    "        # prev_dim = self.encoder.fc.weight.shape[1]\n",
    "        # self.encoder.fc = nn.Sequential(nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "        #                                 nn.BatchNorm1d(prev_dim),\n",
    "        #                                 nn.ReLU(inplace=True), # first layer\n",
    "        #                                 nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "        #                                 nn.BatchNorm1d(prev_dim),\n",
    "        #                                 nn.ReLU(inplace=True), # second layer\n",
    "        #                                 self.encoder.fc,\n",
    "        #                                 nn.BatchNorm1d(dim, affine=False)) # output layer\n",
    "        # self.encoder.fc[6].bias.requires_grad = False # hack: not use bias as it is followed by BN\n",
    "\n",
    "        # build a 2-layer predictor\n",
    "        self.predictor = nn.Sequential(nn.Linear(dim, pred_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(pred_dim),\n",
    "                                        nn.ReLU(inplace=True), # hidden layer\n",
    "                                        nn.Linear(pred_dim, dim)) # output layer\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            x1: first views of images\n",
    "            x2: second views of images\n",
    "        Output:\n",
    "            p1, p2, z1, z2: predictors and targets of the network\n",
    "            See Sec. 3 of https://arxiv.org/abs/2011.10566 for detailed notations\n",
    "        \"\"\"\n",
    "\n",
    "       \n",
    "        z1 = self.encoder.features(x1) # NxC\n",
    "        z2 = self.encoder.features(x2) # NxC\n",
    "      \n",
    "\n",
    "        z1 = self.encoder.avgpool(z1)\n",
    "        z2 = self.encoder.avgpool(z2)\n",
    "\n",
    "\n",
    "        z1 = torch.flatten(z1, 1)\n",
    "        z2 = torch.flatten(z2, 1)\n",
    "   \n",
    "        z1 = self.encoder.classifier(z1)\n",
    "        z2 = self.encoder.classifier(z2)\n",
    "\n",
    "\n",
    "\n",
    "        p1 = self.predictor(z1) # NxC\n",
    "        p2 = self.predictor(z2) # NxC\n",
    "\n",
    "        return p1, p2, z1.detach(), z2.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4613ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'vgg16'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimSiam(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (7): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (predictor): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=512, bias=False)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  )\n",
      ")\n",
      "parameter 17819648\n"
     ]
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "\n",
    "# create model\n",
    "base_encoder = base_encoder\n",
    "print(\"=> creating model '{}'\".format(base_encoder))\n",
    "pretrain_model = SimSiam(models.__dict__[base_encoder],224)\n",
    "\n",
    "\n",
    "lr = 0.01\n",
    "init_lr = lr * batch_size / 256\n",
    "gpu = 0\n",
    "\n",
    "print(pretrain_model)\n",
    "pretrain_parameters = sum(p.numel() for p in pretrain_model.parameters())\n",
    "print(f\"parameter {pretrain_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07ffc071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 224, 9, 9])\n",
      "input2 shape: torch.Size([1, 224, 9, 9])\n",
      "p1 shape torch.Size([1, 2048]), p2 shape torch.Size([1, 2048])\n",
      "z1 shape torch.Size([1, 2048]), z2 shape torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "test = data_augment[0]\n",
    "input = torch.tensor(test).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "test2 = data_augment[1]\n",
    "test2 = torch.tensor(test2).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "input2 = test2\n",
    "\n",
    "\n",
    "print(f\"input shape: {input.shape}\")\n",
    "print(f\"input2 shape: {input2.shape}\")\n",
    "\n",
    "# Pass the input through the model\n",
    "pretrain_model.eval()\n",
    "p1, p2, z1, z2  = pretrain_model(input, input2)\n",
    "\n",
    "print(f\"p1 shape {p1.shape}, p2 shape {p2.shape}\")\n",
    "print(f\"z1 shape {z1.shape}, z2 shape {z2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0224d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(40, 9, 9, 224)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CosineSimilarity(dim=1).cuda(gpu)\n",
    "print(gpu)\n",
    "optim_params = pretrain_model.parameters()\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "optimizer = torch.optim.SGD(optim_params, init_lr,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "augmentation = [\n",
    "    transforms.RandomHorizontalFlip(),  # Flip along width\n",
    "    transforms.RandomVerticalFlip(),    # Flip along height\n",
    "    transforms.RandomRotation(20),      # Rotate image slightly\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize hyperspectral data\n",
    "]\n",
    "\n",
    "transform = simsiam.loader.TwoCropsTransform(transforms.Compose(augmentation))\n",
    "\n",
    "print(data_augment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd6786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([40, 224, 9, 9])\n",
      "generate data loader using seed\n",
      "bacth size: torch.Size([20, 224, 9, 9])\n",
      "length batch: 20\n",
      "Train loader size: 2\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (Tensor or list of Tensors): Preloaded images of shape (N, 9, 9, 224)\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.images = images  # Assuming it's a list or tensor\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img1 = self.transform(img)  # First augmentation\n",
    "            img2 = self.transform(img)  # Second augmentation\n",
    "        \n",
    "            return img1, img2  # Return both augmented versions\n",
    "        \n",
    "        return img, img  # If no transform is provided, return the original image twice\n",
    "\n",
    "\n",
    "# Example usage\n",
    "pretrain_preloaded_image = data_augment \n",
    "\n",
    "pretrain_X_train = torch.tensor(pretrain_preloaded_image)\n",
    "pretrain_X_train = pretrain_X_train.to(torch.float32)\n",
    "pretrain_X_train = pretrain_X_train.permute(0, 3, 1, 2)\n",
    "print(f\"X_train shape: {pretrain_X_train.shape}\")\n",
    "\n",
    "# Define transformations if needed\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),  # Example normalization\n",
    "])\n",
    "\n",
    "pretrain_train_dataset = CustomDataset(pretrain_X_train, transform=transform)\n",
    "\n",
    "train_sampler = None\n",
    "\n",
    "if seeded_run:\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    \n",
    "    pretrain_train_loader = DataLoader(\n",
    "        pretrain_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    print(\"generate data loader using seed\")\n",
    "else:\n",
    "    pretrain_train_loader = DataLoader(\n",
    "        pretrain_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(train_sampler is None),\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 7. Check Output\n",
    "\n",
    "batch1, batch2 = next(iter(pretrain_train_loader))\n",
    "\n",
    "print(f\"bacth size: {batch1.size()}\")\n",
    "print(f\"length batch: {len(batch1)}\")  # Should print 2 (Two transformed views per image)\n",
    "print(f\"Train loader size: {len(pretrain_train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c59999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if 'fix_lr' in param_group and param_group['fix_lr']:\n",
    "            param_group['lr'] = init_lr\n",
    "        else:\n",
    "            param_group['lr'] = cur_lr\n",
    "\n",
    "class Pretrain_AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "    \n",
    "\n",
    "class Pretrain_ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "    \n",
    "def pretrain_save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6abedcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_train(train_loader, model, criterion, optimizer, epoch, device):\n",
    "    batch_time = Pretrain_AverageMeter('Time', ':6.3f')\n",
    "    data_time = Pretrain_AverageMeter('Data', ':6.3f')\n",
    "    losses = Pretrain_AverageMeter('Loss', ':.4f')\n",
    "    progress = Pretrain_ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    for i, (images1, images2) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input1 = images1.to(device, non_blocking=True)\n",
    "        input2 = images2.to(device, non_blocking=True)\n",
    "\n",
    "        p1, p2, z1, z2 = model(x1=input1, x2=input2) \n",
    "        loss = -(criterion(p1, z2).mean() + criterion(p2, z1).mean()) * 0.5\n",
    "\n",
    "        losses.update(loss.item(), input1.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "    # Return average training loss for early stopping\n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1714672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch: [0][0/2]\tTime  1.195 ( 1.195)\tData  0.020 ( 0.020)\tLoss -0.0038 (-0.0038)\n",
      "Epoch 1: Average Training Loss: -0.000481\n",
      "✅ New best model saved with loss -0.000481\n",
      "Epoch: [1][0/2]\tTime  0.070 ( 0.070)\tData  0.022 ( 0.022)\tLoss -0.0037 (-0.0037)\n",
      "Epoch 2: Average Training Loss: 0.000435\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [2][0/2]\tTime  0.087 ( 0.087)\tData  0.024 ( 0.024)\tLoss 0.0005 (0.0005)\n",
      "Epoch 3: Average Training Loss: -0.000118\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [3][0/2]\tTime  0.057 ( 0.057)\tData  0.018 ( 0.018)\tLoss 0.0003 (0.0003)\n",
      "Epoch 4: Average Training Loss: -0.000944\n",
      "✅ New best model saved with loss -0.000944\n",
      "Epoch: [4][0/2]\tTime  0.080 ( 0.080)\tData  0.024 ( 0.024)\tLoss 0.0012 (0.0012)\n",
      "Epoch 5: Average Training Loss: 0.000028\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [5][0/2]\tTime  0.082 ( 0.082)\tData  0.024 ( 0.024)\tLoss -0.0053 (-0.0053)\n",
      "Epoch 6: Average Training Loss: -0.004990\n",
      "✅ New best model saved with loss -0.004990\n",
      "Epoch: [6][0/2]\tTime  0.067 ( 0.067)\tData  0.022 ( 0.022)\tLoss 0.0009 (0.0009)\n",
      "Epoch 7: Average Training Loss: 0.001023\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [7][0/2]\tTime  0.070 ( 0.070)\tData  0.020 ( 0.020)\tLoss -0.0018 (-0.0018)\n",
      "Epoch 8: Average Training Loss: -0.003878\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [8][0/2]\tTime  0.057 ( 0.057)\tData  0.016 ( 0.016)\tLoss -0.0019 (-0.0019)\n",
      "Epoch 9: Average Training Loss: -0.003192\n",
      "❌ No improvement. Patience: 3/50\n",
      "Epoch: [9][0/2]\tTime  0.064 ( 0.064)\tData  0.021 ( 0.021)\tLoss -0.0046 (-0.0046)\n",
      "Epoch 10: Average Training Loss: -0.003554\n",
      "❌ No improvement. Patience: 4/50\n",
      "Epoch: [10][0/2]\tTime  0.068 ( 0.068)\tData  0.019 ( 0.019)\tLoss -0.0050 (-0.0050)\n",
      "Epoch 11: Average Training Loss: -0.002841\n",
      "❌ No improvement. Patience: 5/50\n",
      "Epoch: [11][0/2]\tTime  0.065 ( 0.065)\tData  0.020 ( 0.020)\tLoss -0.0062 (-0.0062)\n",
      "Epoch 12: Average Training Loss: -0.007035\n",
      "✅ New best model saved with loss -0.007035\n",
      "Epoch: [12][0/2]\tTime  0.071 ( 0.071)\tData  0.027 ( 0.027)\tLoss -0.0048 (-0.0048)\n",
      "Epoch 13: Average Training Loss: -0.004196\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [13][0/2]\tTime  0.089 ( 0.089)\tData  0.024 ( 0.024)\tLoss -0.0066 (-0.0066)\n",
      "Epoch 14: Average Training Loss: -0.004087\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [14][0/2]\tTime  0.094 ( 0.094)\tData  0.025 ( 0.025)\tLoss -0.0006 (-0.0006)\n",
      "Epoch 15: Average Training Loss: -0.002511\n",
      "❌ No improvement. Patience: 3/50\n",
      "Epoch: [15][0/2]\tTime  0.071 ( 0.071)\tData  0.021 ( 0.021)\tLoss -0.0055 (-0.0055)\n",
      "Epoch 16: Average Training Loss: -0.003174\n",
      "❌ No improvement. Patience: 4/50\n",
      "Epoch: [16][0/2]\tTime  0.061 ( 0.061)\tData  0.018 ( 0.018)\tLoss -0.0107 (-0.0107)\n",
      "Epoch 17: Average Training Loss: -0.010402\n",
      "✅ New best model saved with loss -0.010402\n",
      "Epoch: [17][0/2]\tTime  0.082 ( 0.082)\tData  0.024 ( 0.024)\tLoss -0.0079 (-0.0079)\n",
      "Epoch 18: Average Training Loss: -0.006257\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [18][0/2]\tTime  0.066 ( 0.066)\tData  0.021 ( 0.021)\tLoss -0.0028 (-0.0028)\n",
      "Epoch 19: Average Training Loss: -0.005194\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [19][0/2]\tTime  0.082 ( 0.082)\tData  0.018 ( 0.018)\tLoss -0.0043 (-0.0043)\n",
      "Epoch 20: Average Training Loss: -0.007085\n",
      "❌ No improvement. Patience: 3/50\n"
     ]
    }
   ],
   "source": [
    "# Early stopping parameters\n",
    "best_loss = float('inf')\n",
    "patience = 50  # Number of epochs to wait for improvement\n",
    "patience_counter = 0\n",
    "\n",
    "start_epoch = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "pretrain_model.to(device)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "filename = f\"{timestamp}_model.pth.tar\"\n",
    "filepath = f\"models/pretrain/{filename}\"\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    pretrain_adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "\n",
    "    # Train and get average loss\n",
    "    avg_loss = pretrain_train(pretrain_train_loader, pretrain_model, criterion, optimizer, epoch, device)\n",
    "    print(f\"Epoch {epoch + 1}: Average Training Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': 'vgg16',\n",
    "            'state_dict': pretrain_model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'best_loss': best_loss\n",
    "        }, filepath)\n",
    "\n",
    "        print(f\"✅ New best model saved with loss {best_loss:.6f}\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"❌ No improvement. Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d5f40d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain Parameter 17819648\n",
      "models\\pretrain\\20250726_115004_model.pth.tar\n"
     ]
    }
   ],
   "source": [
    "pretrain_parameters = sum(p.numel() for p in pretrain_model.parameters())\n",
    "print(f\"pretrain Parameter {pretrain_parameters}\")\n",
    "\n",
    "pretrained = rf'models\\pretrain\\{filename}'\n",
    "print(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32ba8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "\n",
    "class VGG16_HSI(nn.Module):\n",
    "    def __init__(self, num_classes=2, spectral_band=224):\n",
    "        super(VGG16_HSI, self).__init__()\n",
    "\n",
    "        self.encoder =  vgg16(pretrained=True)\n",
    "\n",
    "        self.encoder.features = nn.Sequential(*list(self.encoder.features.children())[28:])\n",
    "        self.encoder.features[0] = nn.Conv2d(spectral_band, 512, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.encoder.features[1] = nn.ReLU(inplace=True)\n",
    "        self.encoder.features[2] = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.encoder.classifier[0] = nn.Linear(in_features=25088, out_features=512, bias=True)\n",
    "        self.encoder.classifier[1] = nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.encoder.classifier[3] = nn.Linear(in_features=512, out_features=512, bias=False)\n",
    "        self.encoder.classifier[4] = nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        # Modify the classifier to match the desired output dimensions\n",
    "        # self.encoder.classifier[0] = nn.Linear(512, 4096, bias=True)\n",
    "        self.encoder.classifier[6] = nn.Linear(512, 2048)\n",
    "        self.encoder.added_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=128, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3, inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=2, bias=True)\n",
    "        )   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder.features(x)  # Pass to VGG-16\n",
    "        x = self.encoder.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.encoder.classifier(x)  # Final classification layer\n",
    "        x = self.encoder.added_classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee42b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: 0 for training\n",
      "=> creating model\n",
      "finetune_parameter 15455618\n",
      "VGG16_HSI(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gpu = 0\n",
    "\n",
    "print(\"Use GPU: {} for training\".format(gpu))\n",
    "\n",
    "print(\"=> creating model\")\n",
    "\n",
    "model_finetune = VGG16_HSI()\n",
    "finetune_parameter = sum(p.numel() for p in model_finetune.parameters())\n",
    "print(f\"finetune_parameter {finetune_parameter}\")\n",
    "\n",
    "print(model_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9fa84ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'models\\pretrain\\20250726_115004_model.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_6020\\2432251866.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_6020\\2432251866.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually loading parameters with remapping:\n",
      "\n",
      "✓ Loaded: encoder.features.0.weight → encoder.features.0.weight\n",
      "✓ Loaded: encoder.features.0.bias → encoder.features.0.bias\n",
      "✓ Loaded: encoder.classifier.0.weight → encoder.classifier.0.weight\n",
      "✓ Loaded: encoder.classifier.0.bias → encoder.classifier.0.bias\n",
      "✓ Loaded: encoder.classifier.1.weight → encoder.classifier.1.weight\n",
      "✓ Loaded: encoder.classifier.1.bias → encoder.classifier.1.bias\n",
      "✓ Loaded: encoder.classifier.1.running_mean → encoder.classifier.1.running_mean\n",
      "✓ Loaded: encoder.classifier.1.running_var → encoder.classifier.1.running_var\n",
      "✓ Loaded: encoder.classifier.1.num_batches_tracked → encoder.classifier.1.num_batches_tracked\n",
      "✓ Loaded: encoder.classifier.3.weight → encoder.classifier.3.weight\n",
      "✓ Loaded: encoder.classifier.4.weight → encoder.classifier.4.weight\n",
      "✓ Loaded: encoder.classifier.4.bias → encoder.classifier.4.bias\n",
      "✓ Loaded: encoder.classifier.4.running_mean → encoder.classifier.4.running_mean\n",
      "✓ Loaded: encoder.classifier.4.running_var → encoder.classifier.4.running_var\n",
      "✓ Loaded: encoder.classifier.4.num_batches_tracked → encoder.classifier.4.num_batches_tracked\n",
      "❌ Key not found in model: encoder.classifier.6.0.weight\n",
      "❌ Key not found in model: encoder.classifier.6.1.weight\n",
      "❌ Key not found in model: encoder.classifier.6.1.bias\n",
      "❌ Key not found in model: encoder.classifier.6.1.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.1.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.1.num_batches_tracked\n",
      "❌ Key not found in model: encoder.classifier.6.3.weight\n",
      "❌ Key not found in model: encoder.classifier.6.4.weight\n",
      "❌ Key not found in model: encoder.classifier.6.4.bias\n",
      "❌ Key not found in model: encoder.classifier.6.4.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.4.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.4.num_batches_tracked\n",
      "✓ Loaded: encoder.classifier.6.6.weight → encoder.classifier.6.weight\n",
      "✓ Loaded: encoder.classifier.6.6.bias → encoder.classifier.6.bias\n",
      "❌ Key not found in model: encoder.classifier.6.7.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.7.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.7.num_batches_tracked\n",
      "❌ Key not found in model: predictor.0.weight\n",
      "❌ Key not found in model: predictor.1.weight\n",
      "❌ Key not found in model: predictor.1.bias\n",
      "❌ Key not found in model: predictor.1.running_mean\n",
      "❌ Key not found in model: predictor.1.running_var\n",
      "❌ Key not found in model: predictor.1.num_batches_tracked\n",
      "❌ Key not found in model: predictor.3.weight\n",
      "❌ Key not found in model: predictor.3.bias\n",
      "\n",
      "=== Summary ===\n",
      "Total checkpoint keys: 40\n",
      "Successfully loaded: 17\n",
      "Missing keys in model: 23\n",
      "Shape mismatches: 0\n",
      "\n",
      "Missing keys:\n",
      "  encoder.classifier.6.0.weight\n",
      "  encoder.classifier.6.1.weight\n",
      "  encoder.classifier.6.1.bias\n",
      "  encoder.classifier.6.1.running_mean\n",
      "  encoder.classifier.6.1.running_var\n",
      "  encoder.classifier.6.1.num_batches_tracked\n",
      "  encoder.classifier.6.3.weight\n",
      "  encoder.classifier.6.4.weight\n",
      "  encoder.classifier.6.4.bias\n",
      "  encoder.classifier.6.4.running_mean\n",
      "  encoder.classifier.6.4.running_var\n",
      "  encoder.classifier.6.4.num_batches_tracked\n",
      "  encoder.classifier.6.7.running_mean\n",
      "  encoder.classifier.6.7.running_var\n",
      "  encoder.classifier.6.7.num_batches_tracked\n",
      "  predictor.0.weight\n",
      "  predictor.1.weight\n",
      "  predictor.1.bias\n",
      "  predictor.1.running_mean\n",
      "  predictor.1.running_var\n",
      "  predictor.1.num_batches_tracked\n",
      "  predictor.3.weight\n",
      "  predictor.3.bias\n",
      "=> loaded pre-trained model 'models\\pretrain\\20250726_115004_model.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "if pretrained:\n",
    "    if os.path.isfile(pretrained):\n",
    "        print(\"=> loading checkpoint '{}'\".format(pretrained))\n",
    "        checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
    "\n",
    "        checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
    "        pretrained_dict = checkpoint['state_dict']\n",
    "        finetune_model_dict = model_finetune.state_dict()\n",
    "\n",
    "        # Key remapping: map .6.6.weight → .6.weight and .6.6.bias → .6.bias\n",
    "        key_mapping = {\n",
    "            'encoder.classifier.6.6.weight': 'encoder.classifier.6.weight',\n",
    "            'encoder.classifier.6.6.bias': 'encoder.classifier.6.bias',\n",
    "        }\n",
    "\n",
    "        # Prepare containers\n",
    "        remapped_dict = {}\n",
    "        loaded_keys = []\n",
    "        shape_mismatches = []\n",
    "        missing_keys = []\n",
    "\n",
    "        print(\"Manually loading parameters with remapping:\\n\")\n",
    "\n",
    "        for k, v in pretrained_dict.items():\n",
    "            new_k = key_mapping.get(k, k)  # Remap if necessary\n",
    "            if new_k in finetune_model_dict:\n",
    "                if finetune_model_dict[new_k].shape == v.shape:\n",
    "                    remapped_dict[new_k] = v\n",
    "                    loaded_keys.append((k, new_k))\n",
    "                    print(f\"✓ Loaded: {k} → {new_k}\")\n",
    "                else:\n",
    "                    shape_mismatches.append((new_k, finetune_model_dict[new_k].shape, v.shape))\n",
    "                    print(f\"⚠️ Shape mismatch: {new_k} | model: {finetune_model_dict[new_k].shape} vs checkpoint: {v.shape}\")\n",
    "            else:\n",
    "                missing_keys.append(new_k)\n",
    "                print(f\"❌ Key not found in model: {new_k}\")\n",
    "\n",
    "        # Load state dict\n",
    "        model_finetune.load_state_dict(remapped_dict, strict=False)\n",
    "\n",
    "        # Summary\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(f\"Total checkpoint keys: {len(pretrained_dict)}\")\n",
    "        print(f\"Successfully loaded: {len(loaded_keys)}\")\n",
    "        print(f\"Missing keys in model: {len(missing_keys)}\")\n",
    "        print(f\"Shape mismatches: {len(shape_mismatches)}\")\n",
    "\n",
    "        if missing_keys:\n",
    "            print(\"\\nMissing keys:\")\n",
    "            for key in missing_keys:\n",
    "                print(f\"  {key}\")\n",
    "\n",
    "        if shape_mismatches:\n",
    "            print(\"\\nShape mismatches:\")\n",
    "            for key, model_shape, ckpt_shape in shape_mismatches:\n",
    "                print(f\"  {key} | model: {model_shape}, checkpoint: {ckpt_shape}\")\n",
    "\n",
    "  \n",
    "     \n",
    "\n",
    "        print(\"=> loaded pre-trained model '{}'\".format(pretrained))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(pretrained))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28417fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16_HSI(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "encoder.features.0.weight: requires_grad=False\n",
      "encoder.features.0.bias: requires_grad=False\n",
      "encoder.classifier.0.weight: requires_grad=False\n",
      "encoder.classifier.0.bias: requires_grad=False\n",
      "encoder.classifier.1.weight: requires_grad=False\n",
      "encoder.classifier.1.bias: requires_grad=False\n",
      "encoder.classifier.3.weight: requires_grad=False\n",
      "encoder.classifier.4.weight: requires_grad=False\n",
      "encoder.classifier.4.bias: requires_grad=False\n",
      "encoder.classifier.6.weight: requires_grad=False\n",
      "encoder.classifier.6.bias: requires_grad=False\n",
      "encoder.added_classifier.0.weight: requires_grad=True\n",
      "encoder.added_classifier.0.bias: requires_grad=True\n",
      "encoder.added_classifier.3.weight: requires_grad=True\n",
      "encoder.added_classifier.3.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for param in model_finetune.encoder.features.parameters():\n",
    "    param.requires_grad = False  # Freeze convolutional layers\n",
    "\n",
    "for param in model_finetune.encoder.classifier.parameters():\n",
    "    param.requires_grad = False  # Freeze all but the last FC layer\n",
    "\n",
    "\n",
    "print(model_finetune)\n",
    "# Check which layers are trainable\n",
    "for name, param in model_finetune.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5f67fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 224, 9, 9])\n",
      "input2 shape: torch.Size([1, 224, 9, 9])\n",
      "output shape torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "test = data_augment[0]\n",
    "test = torch.tensor(test).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "input = test\n",
    "\n",
    "\n",
    "test2 = data_augment[1]\n",
    "test2 = torch.tensor(test2).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "input2 = test2\n",
    "\n",
    "\n",
    "print(f\"input shape: {input.shape}\")\n",
    "print(f\"input2 shape: {input2.shape}\")\n",
    "\n",
    "# Pass the input through the model\n",
    "model_finetune.eval()\n",
    "output = model_finetune(input)\n",
    "\n",
    "print(f\"output shape {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7321178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_augment shape (40, 9, 9, 224)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 0\n",
    "\n",
    "init_lr = lr * batch_size / 256\n",
    "\n",
    "torch.cuda.set_device(gpu)\n",
    "model_finetune = model_finetune.cuda(gpu)\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "\n",
    "# optimize only the linear classifier\n",
    "parameters = list(filter(lambda p: p.requires_grad, model_finetune.parameters()))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(parameters, init_lr,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=weight_decay)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "\n",
    "print(f\"data_augment shape {data_augment.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d915ed95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune_X_train shape: torch.Size([40, 224, 9, 9])\n",
      "Train shape: torch.Size([20, 224, 9, 9]), Validation shape: torch.Size([20, 224, 9, 9])\n",
      "generate data loader using seed\n",
      "torch.Size([20])\n",
      "Train loader size: 1, Validation loader size: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Example usage\n",
    "class CustomDatasetFinetune(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (Tensor or list of Tensors): Preloaded images of shape (N, 9, 9, 224)\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.images = images  # Assuming it's a list or tensor\n",
    "        self.transform = transform\n",
    "        self.label = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img1 = self.transform(img)  # First augmentation\n",
    "        \n",
    "            return img1, label  # Return both augmented versions\n",
    "        \n",
    "        return img, label  # If no transform is provided, return the original image twice\n",
    "    \n",
    "finetune_preloaded_images = data_augment  \n",
    "finetune_X = torch.tensor(finetune_preloaded_images)\n",
    "finetune_X= finetune_X.to(torch.float32)\n",
    "finetune_X = finetune_X.permute(0, 3, 1, 2)\n",
    "print(f\"finetune_X_train shape: {finetune_X.shape}\")\n",
    "\n",
    "finetune_y = torch.tensor(label_augment)\n",
    "#\n",
    "# Define transformations if needed\n",
    "\n",
    "testSize = test_size\n",
    "finetune_X_train, finetune_X_val, finetune_y_train, finetune_y_val = train_test_split(finetune_X, finetune_y, test_size = testSize, random_state=seed, stratify=finetune_y)\n",
    "print(f\"Train shape: {finetune_X_train.shape}, Validation shape: {finetune_X_val.shape}\")\n",
    "\n",
    "finetune_train_dataset = CustomDatasetFinetune(finetune_X_train, finetune_y_train)\n",
    "finetune_val_dataset = CustomDatasetFinetune(finetune_X_val, finetune_y_val)\n",
    "\n",
    "train_sampler = None\n",
    "\n",
    "if seeded_run:\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    \n",
    "    finetune_train_loader = DataLoader(\n",
    "        finetune_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    finetune_val_loader = DataLoader(\n",
    "        finetune_val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    \n",
    "    print(\"generate data loader using seed\")\n",
    "else:\n",
    "    finetune_train_loader = DataLoader(finetune_train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=False)\n",
    "    finetune_val_loader = DataLoader(finetune_val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "# 7. Check Output\n",
    "\n",
    "batch1 = next(iter(finetune_train_loader))\n",
    "\n",
    "print(batch1[1].size())\n",
    "print(f\"Train loader size: {len(finetune_train_loader)}, Validation loader size: {len(finetune_val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b237e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = FinetuneAverageMeter('Time', ':6.3f')\n",
    "    data_time = FinetuneAverageMeter('Data', ':6.3f')\n",
    "    losses = FinetuneAverageMeter('Loss', ':.4e')\n",
    "    top1 = FinetuneAverageMeter('Acc@1', ':6.2f')\n",
    "    progress = FinetuneProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    \"\"\"\n",
    "    Switch to eval mode:\n",
    "    Under the protocol of linear classification on frozen features/models,\n",
    "    it is not legitimate to change any part of the pre-trained model.\n",
    "    BatchNorm in train mode may revise running mean/std (even if it receives\n",
    "    no gradient), which are part of the model parameters too.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        gpu = 0\n",
    "        images = images.cuda(gpu, non_blocking=True)\n",
    "        target = target.cuda(gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, = finetune_accuracy(output, target, topk=(1,))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        print_freq = 10\n",
    "        if i % print_freq == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "\n",
    "def finetune_validate(val_loader, model, criterion):\n",
    "    batch_time = FinetuneAverageMeter('Time', ':6.3f')\n",
    "    losses = FinetuneAverageMeter('Loss', ':.4e')\n",
    "    top1 = FinetuneAverageMeter('Acc@1', ':6.2f')\n",
    "  \n",
    "    progress = FinetuneProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "       \n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "      \n",
    "            gpu = 0\n",
    "            images = images.cuda(gpu, non_blocking=True)\n",
    "            target = target.cuda(gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, = finetune_accuracy(output, target, topk=(1,))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            # top5.update(acc5[0], images.size(0))\n",
    "            print(f\"in validation finction {acc1}\")\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            print_freq = 10\n",
    "            if i % print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def finetune_save_checkpoint(timestamp, epoch, state, is_best, filename='models/checkpoint.pth.tar'):\n",
    "    filename='models/finetune/{}_model.pth.tar'.format(timestamp)\n",
    "    torch.save(state, filename)\n",
    "    # if is_best:\n",
    "    #     shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "def finetune_sanity_check(state_dict, pretrained_weights):\n",
    "    \"\"\"\n",
    "    Linear classifier should not change any weights other than the linear layer.\n",
    "    This sanity check asserts nothing wrong happens (e.g., BN stats updated).\n",
    "    \"\"\"\n",
    "    print(\"=> loading '{}' for sanity check\".format(pretrained_weights))\n",
    "    checkpoint = torch.load(pretrained_weights, map_location=\"cpu\")\n",
    "    state_dict_pre = checkpoint['state_dict']\n",
    "\n",
    "    for k in list(state_dict.keys()):\n",
    "        # Ignore fc layer\n",
    "        if 'fc.weight' in k or 'fc.bias' in k:\n",
    "            continue\n",
    "\n",
    "        # Adjust key mapping to match checkpoint format\n",
    "        k_pre = k.replace('module.encoder.', '')  # Remove unnecessary prefix\n",
    "\n",
    "        # Skip missing keys\n",
    "        if k_pre not in state_dict_pre:\n",
    "            print(f\"Warning: {k_pre} not found in pretrained model. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Check if tensor shapes match before comparing values\n",
    "        if state_dict[k].shape != state_dict_pre[k_pre].shape:\n",
    "            print(f\"Warning: Shape mismatch for {k}: {state_dict[k].shape} vs {state_dict_pre[k_pre].shape}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Assert that the weights remain unchanged\n",
    "        assert ((state_dict[k].cpu() == state_dict_pre[k_pre]).all()), \\\n",
    "            '{} is changed in linear classifier training.'.format(k)\n",
    "\n",
    "    print(\"=> sanity check passed.\")\n",
    "\n",
    "\n",
    "\n",
    "class FinetuneAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class FinetuneProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def finetune_adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = cur_lr\n",
    "\n",
    "\n",
    "def finetune_accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8982a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.features.0.weight: requires_grad=False\n",
      "encoder.features.0.bias: requires_grad=False\n",
      "encoder.classifier.0.weight: requires_grad=False\n",
      "encoder.classifier.0.bias: requires_grad=False\n",
      "encoder.classifier.1.weight: requires_grad=False\n",
      "encoder.classifier.1.bias: requires_grad=False\n",
      "encoder.classifier.3.weight: requires_grad=False\n",
      "encoder.classifier.4.weight: requires_grad=False\n",
      "encoder.classifier.4.bias: requires_grad=False\n",
      "encoder.classifier.6.weight: requires_grad=False\n",
      "encoder.classifier.6.bias: requires_grad=False\n",
      "encoder.added_classifier.0.weight: requires_grad=True\n",
      "encoder.added_classifier.0.bias: requires_grad=True\n",
      "encoder.added_classifier.3.weight: requires_grad=True\n",
      "encoder.added_classifier.3.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_finetune.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa72c1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/1]\tTime  0.089 ( 0.089)\tData  0.005 ( 0.005)\tLoss 6.8283e-01 (6.8283e-01)\tAcc@1  55.00 ( 55.00)\n",
      "in validation finction tensor([55.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.136 ( 0.136)\tLoss 6.7800e-01 (6.7800e-01)\tAcc@1  55.00 ( 55.00)\n",
      " * Acc@1 55.000\n",
      "✅ Epoch 1: New best Acc@1: 55.00. Model saved.\n",
      "Epoch: [1][0/1]\tTime  0.015 ( 0.015)\tData  0.002 ( 0.002)\tLoss 6.7586e-01 (6.7586e-01)\tAcc@1  55.00 ( 55.00)\n",
      "in validation finction tensor([60.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.022 ( 0.022)\tLoss 6.6407e-01 (6.6407e-01)\tAcc@1  60.00 ( 60.00)\n",
      " * Acc@1 60.000\n",
      "✅ Epoch 2: New best Acc@1: 60.00. Model saved.\n",
      "Epoch: [2][0/1]\tTime  0.017 ( 0.017)\tData  0.002 ( 0.002)\tLoss 6.6544e-01 (6.6544e-01)\tAcc@1  60.00 ( 60.00)\n",
      "in validation finction tensor([60.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.024 ( 0.024)\tLoss 6.4745e-01 (6.4745e-01)\tAcc@1  60.00 ( 60.00)\n",
      " * Acc@1 60.000\n",
      "❌ Epoch 3: No improvement. Patience counter: 1/50\n",
      "Epoch: [3][0/1]\tTime  0.014 ( 0.014)\tData  0.003 ( 0.003)\tLoss 6.5319e-01 (6.5319e-01)\tAcc@1  60.00 ( 60.00)\n",
      "in validation finction tensor([65.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.015 ( 0.015)\tLoss 6.2982e-01 (6.2982e-01)\tAcc@1  65.00 ( 65.00)\n",
      " * Acc@1 65.000\n",
      "✅ Epoch 4: New best Acc@1: 65.00. Model saved.\n",
      "Epoch: [4][0/1]\tTime  0.021 ( 0.021)\tData  0.008 ( 0.008)\tLoss 6.4057e-01 (6.4057e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.015 ( 0.015)\tLoss 6.1243e-01 (6.1243e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "✅ Epoch 5: New best Acc@1: 75.00. Model saved.\n",
      "Epoch: [5][0/1]\tTime  0.014 ( 0.014)\tData  0.004 ( 0.004)\tLoss 6.2796e-01 (6.2796e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.012 ( 0.012)\tLoss 5.9672e-01 (5.9672e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 6: No improvement. Patience counter: 1/50\n",
      "Epoch: [6][0/1]\tTime  0.017 ( 0.017)\tData  0.005 ( 0.005)\tLoss 6.1627e-01 (6.1627e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.016 ( 0.016)\tLoss 5.8082e-01 (5.8082e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 7: No improvement. Patience counter: 2/50\n",
      "Epoch: [7][0/1]\tTime  0.013 ( 0.013)\tData  0.004 ( 0.004)\tLoss 6.0376e-01 (6.0376e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.011 ( 0.011)\tLoss 5.6647e-01 (5.6647e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 8: No improvement. Patience counter: 3/50\n",
      "Epoch: [8][0/1]\tTime  0.016 ( 0.016)\tData  0.002 ( 0.002)\tLoss 5.9233e-01 (5.9233e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.016 ( 0.016)\tLoss 5.5359e-01 (5.5359e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 9: No improvement. Patience counter: 4/50\n",
      "Epoch: [9][0/1]\tTime  0.019 ( 0.019)\tData  0.004 ( 0.004)\tLoss 5.8213e-01 (5.8213e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.020 ( 0.020)\tLoss 5.4218e-01 (5.4218e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 10: No improvement. Patience counter: 5/50\n",
      "Epoch: [10][0/1]\tTime  0.021 ( 0.021)\tData  0.006 ( 0.006)\tLoss 5.7298e-01 (5.7298e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.029 ( 0.029)\tLoss 5.3198e-01 (5.3198e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 11: No improvement. Patience counter: 6/50\n",
      "Epoch: [11][0/1]\tTime  0.019 ( 0.019)\tData  0.005 ( 0.005)\tLoss 5.6496e-01 (5.6496e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.022 ( 0.022)\tLoss 5.2315e-01 (5.2315e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 12: No improvement. Patience counter: 7/50\n",
      "Epoch: [12][0/1]\tTime  0.022 ( 0.022)\tData  0.005 ( 0.005)\tLoss 5.5795e-01 (5.5795e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([80.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.015 ( 0.015)\tLoss 5.1588e-01 (5.1588e-01)\tAcc@1  80.00 ( 80.00)\n",
      " * Acc@1 80.000\n",
      "✅ Epoch 13: New best Acc@1: 80.00. Model saved.\n",
      "Epoch: [13][0/1]\tTime  0.016 ( 0.016)\tData  0.003 ( 0.003)\tLoss 5.5206e-01 (5.5206e-01)\tAcc@1  70.00 ( 70.00)\n",
      "in validation finction tensor([85.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.030 ( 0.030)\tLoss 5.1005e-01 (5.1005e-01)\tAcc@1  85.00 ( 85.00)\n",
      " * Acc@1 85.000\n",
      "✅ Epoch 14: New best Acc@1: 85.00. Model saved.\n",
      "Epoch: [14][0/1]\tTime  0.022 ( 0.022)\tData  0.004 ( 0.004)\tLoss 5.4748e-01 (5.4748e-01)\tAcc@1  75.00 ( 75.00)\n",
      "in validation finction tensor([85.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.014 ( 0.014)\tLoss 5.0551e-01 (5.0551e-01)\tAcc@1  85.00 ( 85.00)\n",
      " * Acc@1 85.000\n",
      "❌ Epoch 15: No improvement. Patience counter: 1/50\n",
      "Epoch: [15][0/1]\tTime  0.016 ( 0.016)\tData  0.004 ( 0.004)\tLoss 5.4393e-01 (5.4393e-01)\tAcc@1  75.00 ( 75.00)\n",
      "in validation finction tensor([85.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.014 ( 0.014)\tLoss 5.0219e-01 (5.0219e-01)\tAcc@1  85.00 ( 85.00)\n",
      " * Acc@1 85.000\n",
      "❌ Epoch 16: No improvement. Patience counter: 2/50\n",
      "Epoch: [16][0/1]\tTime  0.021 ( 0.021)\tData  0.003 ( 0.003)\tLoss 5.4133e-01 (5.4133e-01)\tAcc@1  75.00 ( 75.00)\n",
      "in validation finction tensor([85.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.017 ( 0.017)\tLoss 4.9996e-01 (4.9996e-01)\tAcc@1  85.00 ( 85.00)\n",
      " * Acc@1 85.000\n",
      "❌ Epoch 17: No improvement. Patience counter: 3/50\n",
      "Epoch: [17][0/1]\tTime  0.016 ( 0.016)\tData  0.003 ( 0.003)\tLoss 5.3960e-01 (5.3960e-01)\tAcc@1  75.00 ( 75.00)\n",
      "in validation finction tensor([85.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.016 ( 0.016)\tLoss 4.9865e-01 (4.9865e-01)\tAcc@1  85.00 ( 85.00)\n",
      " * Acc@1 85.000\n",
      "❌ Epoch 18: No improvement. Patience counter: 4/50\n",
      "Epoch: [18][0/1]\tTime  0.018 ( 0.018)\tData  0.005 ( 0.005)\tLoss 5.3859e-01 (5.3859e-01)\tAcc@1  75.00 ( 75.00)\n",
      "in validation finction tensor([90.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.015 ( 0.015)\tLoss 4.9805e-01 (4.9805e-01)\tAcc@1  90.00 ( 90.00)\n",
      " * Acc@1 90.000\n",
      "✅ Epoch 19: New best Acc@1: 90.00. Model saved.\n",
      "Epoch: [19][0/1]\tTime  0.031 ( 0.031)\tData  0.005 ( 0.005)\tLoss 5.3813e-01 (5.3813e-01)\tAcc@1  75.00 ( 75.00)\n",
      "in validation finction tensor([90.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.013 ( 0.013)\tLoss 4.9789e-01 (4.9789e-01)\tAcc@1  90.00 ( 90.00)\n",
      " * Acc@1 90.000\n",
      "❌ Epoch 20: No improvement. Patience counter: 1/50\n"
     ]
    }
   ],
   "source": [
    "best_acc1 = 0.0\n",
    "patience = 50  # Adjust as needed\n",
    "patience_counter = 0\n",
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "start_epoch = 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_finetune.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    finetune_adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "\n",
    "    # Train for one epoch\n",
    "    finetune_train(finetune_train_loader, model_finetune, criterion, optimizer, epoch)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    acc1 = finetune_validate(finetune_val_loader, model_finetune, criterion)\n",
    "\n",
    "    # Check if current accuracy is the best\n",
    "    is_best = acc1 > best_acc1\n",
    "\n",
    "    if is_best:\n",
    "        best_acc1 = acc1\n",
    "        patience_counter = 0\n",
    "\n",
    "        # Save best model only\n",
    "        finetune_save_checkpoint(timestamp, epoch, {\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': 'vgg16',\n",
    "            'state_dict': model_finetune.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best=True)\n",
    "\n",
    "        print(f\"✅ Epoch {epoch+1}: New best Acc@1: {best_acc1:.2f}. Model saved.\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"❌ Epoch {epoch+1}: No improvement. Patience counter: {patience_counter}/{patience}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"⏹️ Early stopping triggered at epoch {epoch+1}. Best Acc@1: {best_acc1:.2f}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "828ce5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250726_115004\n"
     ]
    }
   ],
   "source": [
    "train_time = time.time()\n",
    "\n",
    "\n",
    "print(timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c42bbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9859cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWithDataset(n): \n",
    "    hsi_test = dataset[n]\n",
    "\n",
    "    test_img = hsi_test.img\n",
    "    test_gt = hsi_test.gt\n",
    "\n",
    "    patch_size = 9\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    height = test_img.shape[0]\n",
    "    width = test_img.shape[1]\n",
    "\n",
    "    matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "    print(f\"img shape: {test_img.shape}\")\n",
    "    print(f\"img shape after padding {matrix.shape}\")\n",
    "    print(f\"number of pixel {width * height}\")\n",
    "\n",
    "    print(f\"ground truth shape: {test_gt.shape}\")\n",
    "\n",
    "    indices0 = np.argwhere(test_gt == 0)\n",
    "    indices1 = np.argwhere(test_gt == 1)\n",
    "\n",
    "    print(f\"indices = 0 shape: {indices0.shape}\")\n",
    "    print(f\"indices = 1 shape: {indices1.shape}\")\n",
    "\n",
    "    num_samples = 5000\n",
    "\n",
    "    random_indices0 = indices0[np.random.choice(len(indices0), num_samples, replace=False)]\n",
    "    random_indices1 = indices1[np.random.choice(len(indices1), num_samples, replace=False)]\n",
    "\n",
    "    test_indices = np.vstack((random_indices0, random_indices1))\n",
    "\n",
    "    print(test_indices.shape)\n",
    "\n",
    "    return test_indices, test_gt, matrix, random_indices0.shape, random_indices1.shape\n",
    "\n",
    "\n",
    "def testWithWholeDataset(n): \n",
    "    hsi_test = dataset[n]\n",
    "\n",
    "    test_img = hsi_test.img\n",
    "    gt= hsi_test.gt\n",
    "\n",
    "    patch_size = 9\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    height = test_img.shape[0]\n",
    "    width = test_img.shape[1]\n",
    "\n",
    "    matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "    print(f\"img shape: {test_img.shape}\")\n",
    "    print(f\"img shape after padding {matrix.shape}\")\n",
    "    print(f\"number of pixel {width * height}\")\n",
    "\n",
    "    print(f\"ground truth shape: {gt.shape}\")\n",
    "\n",
    "    indices0 = np.argwhere(gt == 0)\n",
    "    indices1 = np.argwhere(gt == 1)\n",
    "\n",
    "    print(f\"indices = 0 shape: {indices0.shape}\")\n",
    "    print(f\"indices = 1 shape: {indices1.shape}\")\n",
    "\n",
    "    return matrix, gt, indices0.shape, indices1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a0cfff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(model, batch_input, device):\n",
    "    model.eval()\n",
    "    batch_input = batch_input.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_input)\n",
    "        # Apply softmax to get class probabilities\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "        # Get predicted class (0 or 1)\n",
    "        predicted_classes = torch.argmax(probabilities, dim=1).cpu().numpy()\n",
    "\n",
    "        # Get probability of class 1 (positive class) — required for ROC\n",
    "        positive_class_probs = probabilities[:, 1].cpu().numpy()\n",
    "\n",
    "    \n",
    "\n",
    "    return predicted_classes, positive_class_probs\n",
    "\n",
    "\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, matrix, gt, half_patch, expected_shape):\n",
    "        self.matrix = matrix\n",
    "        self.gt = gt\n",
    "        self.half_patch = half_patch\n",
    "        self.expected_shape = expected_shape\n",
    "        self.size_x, self.size_y = matrix.shape[0], matrix.shape[1]\n",
    "        self.valid_coords = [\n",
    "            (x, y)\n",
    "            for x in range(half_patch, self.size_x - half_patch)\n",
    "            for y in range(half_patch, self.size_y - half_patch)\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.valid_coords[idx]\n",
    "        true_label = self.gt[x - self.half_patch, y - self.half_patch]\n",
    "\n",
    "        selected_rows = self.matrix[x- self.half_patch:x + 2 * self.half_patch + 1 - self.half_patch, :]\n",
    "        testing_patch = selected_rows[:, y - self.half_patch:y + 2 * self.half_patch + 1 - self.half_patch]\n",
    "\n",
    "        # Verify patch size\n",
    "        if testing_patch.shape != self.expected_shape:\n",
    "            raise ValueError(f\"Patch at ({x},{y}) has wrong shape {testing_patch.shape}\")\n",
    "\n",
    "        patch_tensor = torch.tensor(testing_patch, dtype=torch.float32)\n",
    "        patch_tensor = patch_tensor.permute(2, 0, 1)  # (C, H, W)\n",
    "\n",
    "        return patch_tensor, true_label, x, y  # Also return (x, y) for positioning later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "575b807c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\finetune\\20250726_115004_model.pth.tar\n",
      "Creating model 20250726_115004_model.pth.tar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and moved to device\n",
      "saved_model for testing Parameter 15455618\n",
      "VGG16_HSI(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_6020\\3084895309.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 64  # You can change this depending on your GPU capacity\n",
    "\n",
    "model_path = rf\"models\\finetune\\{timestamp}_model.pth.tar\"\n",
    "model_name = model_path.split('\\\\')[-1]\n",
    "print(model_path)\n",
    "\n",
    "print(f\"Creating model {model_name}...\")\n",
    "saved_model = VGG16_HSI().to(device)\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "saved_model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Model loaded and moved to device\")\n",
    "\n",
    "saved_model_parameters = sum(p.numel() for p in saved_model.parameters())\n",
    "print(f\"saved_model for testing Parameter {saved_model_parameters}\")\n",
    "print(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13871a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScoreTest(prediction, y_probs, groundtruth):\n",
    "    groundtruths = groundtruth\n",
    "    groundtruth_in = []\n",
    "\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "    predictions = prediction\n",
    "    prediction_in = []\n",
    "\n",
    "    for x in predictions:\n",
    "        for y in x:\n",
    "            prediction_in.append(y)\n",
    "\n",
    "\n",
    "    y_prob_in = []\n",
    "\n",
    "    for x in y_probs:\n",
    "        for y in x:\n",
    "            y_prob_in.append(y)\n",
    "\n",
    "    print(len(groundtruth_in))\n",
    "    print(len(prediction_in))\n",
    "    print(len(y_prob_in))\n",
    "\n",
    "    y_test = groundtruth_in\n",
    "    y_pred = prediction_in\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in zip(y_test, y_pred):\n",
    "        total += 1\n",
    "        if x == y:\n",
    "            correct += 1\n",
    "    \n",
    "    print(f'{correct}/{total}')\n",
    "\n",
    "    y_test_np = np.array([label.item() for label in y_test])\n",
    "    # Ensure labels are binary (0 and 1)\n",
    "    # print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "    # # Check if y_pred is probability (float) or hard prediction (int)\n",
    "    # print(\"Sample y_pred values:\", y_pred[:5])\n",
    "\n",
    "    test_df = pd.DataFrame(\n",
    "        {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Two Models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "    y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "    # Precision, Recall, F1\n",
    "    precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Overall Accuracy (OA)\n",
    "    oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Average Accuracy (AA) — mean of per-class accuracies\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    aa = per_class_acc.mean()\n",
    "\n",
    "    # Print all metrics\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"OA:        {oa:.4f}\")\n",
    "    print(f\"AA:        {aa:.4f}\")\n",
    "\n",
    "    performance = {\n",
    "        'AUC': float(roc_auc),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'F1 Score': float(f1),\n",
    "        'OA': float(oa),\n",
    "        'AA': float(aa),\n",
    "    }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a467139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(prediction, y_probs, groundtruth):\n",
    "    groundtruths = groundtruth\n",
    "    groundtruth_in = []\n",
    "\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "    predictions = prediction\n",
    "    prediction_in = []\n",
    "\n",
    "    for x in predictions:\n",
    "        for y in x:\n",
    "            prediction_in.append(y)\n",
    "\n",
    "\n",
    "    y_prob_in = []\n",
    "\n",
    "    for x in y_probs:\n",
    "        for y in x:\n",
    "            y_prob_in.append(y)\n",
    "\n",
    "    # print(len(groundtruth_in))\n",
    "    # print(len(prediction_in))\n",
    "    # print(len(y_prob_in))\n",
    "\n",
    "    y_test = groundtruth_in\n",
    "    y_pred = prediction_in\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in zip(y_test, y_pred):\n",
    "        total += 1\n",
    "        if x == y:\n",
    "            correct += 1\n",
    "    \n",
    "    print(f'{correct}/{total}')\n",
    "\n",
    "    y_test_np = np.array([label.item() for label in y_test])\n",
    "    # Ensure labels are binary (0 and 1)\n",
    "    # print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "    # # Check if y_pred is probability (float) or hard prediction (int)\n",
    "    # print(\"Sample y_pred values:\", y_pred[:5])\n",
    "\n",
    "    test_df = pd.DataFrame(\n",
    "        {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Two Models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "    y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "    # Precision, Recall, F1\n",
    "    precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Overall Accuracy (OA)\n",
    "    oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Average Accuracy (AA) — mean of per-class accuracies\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    aa = per_class_acc.mean()\n",
    "\n",
    "    # Print all metrics\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"OA:        {oa:.4f}\")\n",
    "    print(f\"AA:        {aa:.4f}\")\n",
    "\n",
    "    performance = {\n",
    "        'AUC': float(roc_auc),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'F1 Score': float(f1),\n",
    "        'OA': float(oa),\n",
    "        'AA': float(aa),\n",
    "    }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9ae6c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tes: 0\n",
      "dataset: 1\n",
      "img shape: (1243, 684, 224)\n",
      "img shape after padding (1251, 692, 224)\n",
      "number of pixel 850212\n",
      "ground truth shape: (1243, 684)\n",
      "indices = 0 shape: (820876, 2)\n",
      "indices = 1 shape: (29336, 2)\n",
      "820876\n",
      "29336\n",
      "generate data loader using seed\n",
      "torch.Size([64, 224, 9, 9])\n",
      "torch.Size([64])\n",
      "data loader size: 13285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 13285/13285 [08:01<00:00, 27.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822746/850212\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7587\n",
      "Recall:    0.7282\n",
      "F1 Score:  0.7424\n",
      "OA:        0.9677\n",
      "AA:        0.7282\n",
      "correct0 = 808930\n",
      "correct1 = 13816\n",
      "Score: 822746/850212\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "scores = []\n",
    "\n",
    "groundtruth = []\n",
    "prediction = []\n",
    "y_probs = []\n",
    "\n",
    "\n",
    "if mode == \"test\":\n",
    "    for hsi_test in range(len(dataset)):\n",
    "        print(f\"tes: {hsi_test + 1}\")\n",
    "\n",
    "        hsi_prediction = []\n",
    "        hsi_yprobs = []\n",
    "        hsi_groundtruth = []\n",
    "\n",
    "\n",
    "        test_indices, test_gt, matrix, indices_0_shape, indices_1_shape = testWithDataset(hsi_test)\n",
    "\n",
    "        total = len(test_indices)\n",
    "        correct0 = 0\n",
    "        correct1 = 0\n",
    "\n",
    "        input_patches = []\n",
    "        true_labels = []\n",
    "\n",
    "        # Prepare all patches\n",
    "        for x_pos, y_pos in test_indices:\n",
    "            true_label = test_gt[x_pos][y_pos]\n",
    "\n",
    "            selected_rows = matrix[x_pos:x_pos + 2*half_patch + 1, :]\n",
    "            testing_patch = selected_rows[:, y_pos:y_pos + 2*half_patch + 1]\n",
    "\n",
    "            patch_tensor = torch.tensor(testing_patch, dtype=torch.float32)\n",
    "            patch_tensor = patch_tensor.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "            input_patches.append(patch_tensor)\n",
    "            true_labels.append(true_label)\n",
    "\n",
    "        input_patches = torch.cat(input_patches, dim=0)  # Shape: (N, C, H, W)\n",
    "        true_labels = torch.tensor(true_labels)\n",
    "\n",
    "        # Process in batches\n",
    "        for i in tqdm(range(0, total, batch_size), desc=\"Predicting\"):\n",
    "            batch = input_patches[i:i+batch_size]\n",
    "            labels = true_labels[i:i+batch_size]\n",
    "\n",
    "            groundtruth.append(labels)\n",
    "            \n",
    "\n",
    "            preds, postive_class_probs = predict_batch(saved_model, batch, device)\n",
    "\n",
    "            prediction.append(preds)\n",
    "            hsi_prediction.append(preds)\n",
    "\n",
    "            hsi_yprobs.append(postive_class_probs)\n",
    "            y_probs.append(postive_class_probs)\n",
    "\n",
    "            for j in range(len(preds)):\n",
    "                index = i + j\n",
    "                hsi_groundtruth.append(labels[j])\n",
    "                # print(f\"{index+1}: prediction = {preds[j]}, confidence: {confs[j]:.4f}, expected: {labels[j].item()}\")\n",
    "                if preds[j] == labels[j].item():\n",
    "                    if labels[j].item() == 0:\n",
    "                        correct0 += 1\n",
    "                    elif labels[j] == 1:\n",
    "                        correct1 += 1\n",
    "\n",
    "        performance_metrics = getScoreTest(hsi_prediction, hsi_yprobs, hsi_groundtruth) \n",
    "        correct = correct0 + correct1\n",
    "        print(f\"Score: {correct}/{total}\")\n",
    "        \n",
    "        score = {\n",
    "            'dataset': hsi_test,\n",
    "            'class0_size': indices_0_shape[0],\n",
    "            'class1_size': indices_1_shape[0],\n",
    "            'correct_0': correct0,\n",
    "            'correct_1': correct1,\n",
    "            'correct_total': correct,\n",
    "            'total': total,\n",
    "            'AUC': float(performance_metrics['AUC']),\n",
    "            'precision': float(performance_metrics['precision']),\n",
    "            'recall': float(performance_metrics['recall']),\n",
    "            'F1 Score': float(performance_metrics['F1 Score']),\n",
    "            'OA': float(performance_metrics['OA']),\n",
    "            'AA': float(performance_metrics['AA']),\n",
    "        }\n",
    "        scores.append(score)\n",
    "\n",
    "if mode == \"full\":\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    os.makedirs(f\"predictions/{timestamp}\", exist_ok=True)\n",
    "    for hsi_full in range(len(dataset)):\n",
    "        if hsi_full > 0:\n",
    "            break\n",
    "        print(f\"tes: {hsi_full}\")\n",
    "        # if hsi_full > 2:\n",
    "        #     break\n",
    "        print(f\"dataset: {hsi_full + 1}\")\n",
    "        hsi_prediction = []\n",
    "        hsi_yprobs = []\n",
    "        hsi_groundtruth = []\n",
    "\n",
    "        score = []\n",
    "        patch_size = 9\n",
    "        half_patch = patch_size // 2\n",
    "\n",
    "        data_sampler = None\n",
    "        batch_size = 64\n",
    "\n",
    "        correct0 = 0\n",
    "        correct1 = 0\n",
    "        matrix = []\n",
    "        gt = []\n",
    "        expected_patch_shape = []\n",
    "        dataset_patches = []\n",
    "        data_loader = []\n",
    "        patch_tensor = []\n",
    "        true_label = [] \n",
    "        x = []\n",
    "        y = []\n",
    "        pred_matrix = []\n",
    "\n",
    "        matrix, gt, indices_0_shape, indices_1_shape = testWithWholeDataset(hsi_full)\n",
    "        print(indices_0_shape[0])\n",
    "        print(indices_1_shape[0])\n",
    "\n",
    "        expected_patch_shape = (2 * half_patch + 1, 2 * half_patch + 1, matrix.shape[2])\n",
    "        dataset_patches = PatchDataset(matrix, gt, half_patch, expected_patch_shape)\n",
    "\n",
    "        if seeded_run:\n",
    "            g = torch.Generator()\n",
    "            g.manual_seed(seed)\n",
    "\n",
    "            data_loader = DataLoader(\n",
    "                dataset_patches,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,  # set to True if needed\n",
    "                num_workers=0,\n",
    "                pin_memory=True,\n",
    "                drop_last=False,\n",
    "                generator=g\n",
    "            )\n",
    "            print(\"generate data loader using seed\")\n",
    "        else:\n",
    "            data_loader = DataLoader(dataset_patches, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        patch_tensor, true_label, x, y = next(iter(data_loader))\n",
    "\n",
    "        print(patch_tensor.size())\n",
    "        print(true_label.size())\n",
    "        print(f\"data loader size: {len(data_loader)}\")\n",
    "\n",
    "        pred_matrix = np.full(gt.shape, -1, dtype=np.int32)\n",
    "        correct = 0\n",
    "\n",
    "        for input_batch, label_batch, x_batch, y_batch in tqdm(data_loader, desc=\"Predicting\"):\n",
    "\n",
    "\n",
    "            preds, confs = predict_batch(saved_model, input_batch, device)\n",
    "\n",
    "            hsi_prediction.append(preds)\n",
    "            prediction.append(preds)\n",
    "            hsi_yprobs.append(confs)\n",
    "            y_probs.append(confs)\n",
    "            \n",
    "            label_batch = label_batch.numpy()\n",
    "            x_batch = x_batch.numpy()\n",
    "            y_batch = y_batch.numpy()\n",
    "\n",
    "            for pred, label, x, y in zip(preds, label_batch, x_batch, y_batch):\n",
    "                hsi_groundtruth.append(label)\n",
    "                groundtruth.append(label)\n",
    "                pred_matrix[x - half_patch, y - half_patch] = pred\n",
    "                if pred == label:\n",
    "                    if label == 0:\n",
    "                        correct0 += 1\n",
    "                    elif label == 1:\n",
    "                        correct1 += 1\n",
    "\n",
    "        performance_metrics = getScore(hsi_prediction, hsi_yprobs, hsi_groundtruth)      \n",
    "            \n",
    "        correct = correct0+correct1\n",
    "        print(f\"correct0 = {correct0}\")\n",
    "        print(f\"correct1 = {correct1}\")\n",
    "        total = gt.shape[0] * gt.shape[1]\n",
    "        print(f\"Score: {correct}/{total}\")\n",
    "\n",
    "        score = {\n",
    "            'dataset': hsi_full,\n",
    "            'class0_size': indices_0_shape[0],\n",
    "            'class1_size': indices_1_shape[0],\n",
    "            'correct_0': correct0,\n",
    "            'correct_1': correct1,\n",
    "            'correct_total': correct,\n",
    "            'total': total,\n",
    "            'AUC': float(performance_metrics['AUC']),\n",
    "            'precision': float(performance_metrics['precision']),\n",
    "            'recall': float(performance_metrics['recall']),\n",
    "            'F1 Score': float(performance_metrics['F1 Score']),\n",
    "            'OA': float(performance_metrics['OA']),\n",
    "            'AA': float(performance_metrics['AA']),\n",
    "        }\n",
    "        # print(score)\n",
    "        scores.append(score)\n",
    "        # Save prediction matrix\n",
    "        # timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        np.save(f\"predictions/{timestamp}/results {hsi_full} MyMethod.npy\", pred_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3802cccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: 0\t 808930/820876\t 13816/29336\t 822746/850212\t 0.967695116041646 0.7282022198098141\n",
      "dataset: 0\t AUC: 0.9698038974874897 precission: 0.7587345475095862 recall: 0.7282022198098141 F1 SCore0.7424065292285185\n",
      "total: \t\t 808930/410438.0 \t 13816/14668.0 \t 822746/850212\n",
      "acc: 0.967695116041646\n"
     ]
    }
   ],
   "source": [
    "all_correct = 0\n",
    "all_total = 0\n",
    "all_correct0 = 0\n",
    "all_correct1 = 0\n",
    "class0_total = 0\n",
    "class1_total = 0\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    dataset = score['dataset']\n",
    "    correct0 = score['correct_0']\n",
    "    correct1 = score['correct_1']\n",
    "    class0_size = score['class0_size']\n",
    "    class1_size = score['class1_size']\n",
    "    correct = score['correct_total']\n",
    "    total = score['total']\n",
    "    auc_score = score['AUC']\n",
    "    precission = score['precision']\n",
    "    recall = score['recall']\n",
    "    f1 = score['F1 Score']\n",
    "    oa = score['OA']\n",
    "    aa = score['AA']\n",
    "    \n",
    "    print(f\"dataset: {dataset}\\t\", f'{correct0}/{class0_size}\\t', f'{correct1}/{class1_size}\\t', f'{correct}/{total}\\t', f\"{oa}\", f\"{aa}\")\n",
    "\n",
    "    all_correct += correct\n",
    "    all_total += total\n",
    "    all_correct0 += correct0\n",
    "    all_correct1 += correct1\n",
    "    class0_total += class0_size\n",
    "    class1_total += class1_size\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    dataset = score['dataset']\n",
    "    correct0 = score['correct_0']\n",
    "    correct1 = score['correct_1']\n",
    "    class0_size = score['class0_size']\n",
    "    class1_size = score['class1_size']\n",
    "    correct = score['correct_total']\n",
    "    total = score['total']\n",
    "    auc_score = score['AUC']\n",
    "    precission = score['precision']\n",
    "    recall = score['recall']\n",
    "    f1 = score['F1 Score']\n",
    "    oa = score['OA']\n",
    "    aa = score['AA']\n",
    "    print(f\"dataset: {dataset}\\t\", f\"AUC: {auc_score}\", f\"precission: {precission}\", f\"recall: {recall}\", f\"F1 SCore{f1}\")\n",
    "\n",
    "print(f\"total: \\t\\t {all_correct0}/{class0_total/2} \\t {all_correct1}/{class1_total/2} \\t {all_correct}/{all_total}\")\n",
    "\n",
    "print(f\"acc: {all_correct/all_total}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c74a969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_total_score = {\n",
    "    'dataset': 'Total Dataset',\n",
    "    'correct_0': all_correct0,\n",
    "    'correct_1': all_correct1,\n",
    "    'class0_total': class0_total,\n",
    "    'class1_total': class1_total,\n",
    "    'correct_total': all_correct,\n",
    "    'total': all_total\n",
    "}\n",
    "\n",
    "scores.append(all_total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddab0694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850212\n",
      "850212\n",
      "850212\n"
     ]
    }
   ],
   "source": [
    "groundtruths = groundtruth\n",
    "groundtruth_in = []\n",
    "\n",
    "if mode == \"test\":\n",
    "    for x in groundtruths:\n",
    "        for y in x:\n",
    "            groundtruth_in.append(y)    \n",
    "\n",
    "if mode == \"full\":\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "predictions = prediction\n",
    "prediction_in = []\n",
    "\n",
    "for x in predictions:\n",
    "    for y in x:\n",
    "        prediction_in.append(y)\n",
    "\n",
    "\n",
    "y_prob_in = []\n",
    "\n",
    "for x in y_probs:\n",
    "    for y in x:\n",
    "        y_prob_in.append(y)\n",
    "\n",
    "print(len(groundtruth_in))\n",
    "print(len(prediction_in))\n",
    "print(len(y_prob_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e85a806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822746/850212\n"
     ]
    }
   ],
   "source": [
    "y_test = groundtruth_in\n",
    "y_pred = prediction_in\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for x, y in zip(y_test, y_pred):\n",
    "    total += 1\n",
    "    if x == y:\n",
    "        correct += 1\n",
    "\n",
    "print(f'{correct}/{total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a4761e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_test: [0 1]\n",
      "Sample y_pred values: [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n"
     ]
    }
   ],
   "source": [
    "y_test_np = np.array([label.item() for label in y_test])\n",
    "# Ensure labels are binary (0 and 1)\n",
    "print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "# Check if y_pred is probability (float) or hard prediction (int)\n",
    "print(\"Sample y_pred values:\", y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29515cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(\n",
    "    {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Two Models')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6a288ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7587\n",
      "Recall:    0.7282\n",
      "F1 Score:  0.7424\n",
      "OA:        0.9677\n",
      "AA:        0.7282\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "# Precision, Recall, F1\n",
    "precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "# Overall Accuracy (OA)\n",
    "oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Average Accuracy (AA) — mean of per-class accuracies\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "aa = per_class_acc.mean()\n",
    "\n",
    "# Print all metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"OA:        {oa:.4f}\")\n",
    "print(f\"AA:        {aa:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8abb93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {\n",
    "    'AUC': float(roc_auc),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'F1 Score': float(f1),\n",
    "    'OA': float(oa),\n",
    "    'AA': float(aa),\n",
    "}\n",
    "result_json = {\n",
    "    'prediction' : scores,\n",
    "    'performance' : performance,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c0c5d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [{'dataset': 0, 'class0_size': 820876, 'class1_size': 29336, 'correct_0': 808930, 'correct_1': 13816, 'correct_total': 822746, 'total': 850212, 'AUC': 0.9698038974874897, 'precision': 0.7587345475095862, 'recall': 0.7282022198098141, 'F1 Score': 0.7424065292285185, 'OA': 0.967695116041646, 'AA': 0.7282022198098141}, {'dataset': 'Total Dataset', 'correct_0': 808930, 'correct_1': 13816, 'class0_total': 820876, 'class1_total': 29336, 'correct_total': 822746, 'total': 850212}], 'performance': {'AUC': 0.9698038974874897, 'precision': 0.7587345475095862, 'recall': 0.7282022198098141, 'F1 Score': 0.7424065292285185, 'OA': 0.967695116041646, 'AA': 0.7282022198098141}}\n",
      "JSON saved to results.json\n"
     ]
    }
   ],
   "source": [
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "print(result_json)\n",
    "\n",
    "with open(f\"performance/MyMethod {timestamp}_results.json\", \"w\") as f:\n",
    "    json.dump(result_json, f, indent=2)\n",
    "\n",
    "print(\"JSON saved to results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "901b6440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 89.8517 seconds\n",
      "predicting time: 502.9056 seconds\n",
      "Run time: 592.7573 seconds\n",
      "mode used: full\n",
      "finetune Parameter 15455618\n",
      "Pretrain Parameter 17819648\n",
      "saved_model for testing Parameter 15455618\n",
      "20250726_115034\n",
      "seet used: 10\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Train time: {train_time - start_time:.4f} seconds\")\n",
    "print(f\"predicting time: {end_time - train_time:.4f} seconds\")\n",
    "print(f\"Run time: {end_time - start_time:.4f} seconds\")\n",
    "print(f\"mode used: {mode}\")\n",
    "print(f\"finetune Parameter {finetune_parameter}\")\n",
    "print(f\"Pretrain Parameter {pretrain_parameters}\")\n",
    "print(f\"saved_model for testing Parameter {saved_model_parameters}\")\n",
    "print(timestamp)\n",
    "print(f\"seet used: {seed}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_repo_ta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

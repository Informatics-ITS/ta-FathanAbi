{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a5a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "GPU Name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from HSI_class import HSI\n",
    "import createSample as CS\n",
    "import augmentation as aug\n",
    "\n",
    "import simsiam.loader\n",
    "import random\n",
    "import zeroPadding\n",
    "start_time = time.time()\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "\n",
    "# If available, print the GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    \n",
    "sample_per_class = 5\n",
    "num_per_category_augment_1 = 10\n",
    "num_per_category_augment_2 = 10\n",
    "patch_size = 9\n",
    "n_category = 2\n",
    "band_size = 224\n",
    "base_encoder = 'vgg16'\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "batch_size = 20\n",
    "test_size = 0.5\n",
    "\n",
    "random_indices = 1\n",
    "\n",
    "seeded_run = True\n",
    "seed = 10\n",
    "\n",
    "mode = \"full\"\n",
    "project_path = r\"C:\\Users\\Asus TUF\\Documents\\code\\TA\"\n",
    "# project_path = r\"D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25da8a0f-8f90-4f9e-9a04-991692e9ebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed has been set\n",
      "seet used: 10\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # PyTorch determinism\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "if seeded_run:\n",
    "    set_seed(seed)\n",
    "    print(\"seed has been set\")\n",
    "    print(f\"seet used: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578786fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM01.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM02.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM03.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM04.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM05.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM06.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM07.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM08.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM09.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM10.mat\n",
      "random: 1\n",
      "generating random indices\n",
      "hsi shape\n",
      "(1243, 684, 224)\n",
      "creating 5 Randomly chosen 0 indices:\n",
      "creating 5 Randomly chosen 1 indices:\n",
      "indices 0 used: [(np.int64(448), np.int64(229)), (np.int64(1040), np.int64(173)), (np.int64(261), np.int64(95)), (np.int64(54), np.int64(186)), (np.int64(831), np.int64(289))]\n",
      "indices 1 used: [(np.int64(468), np.int64(213)), (np.int64(264), np.int64(165)), (np.int64(107), np.int64(81)), (np.int64(202), np.int64(127)), (np.int64(960), np.int64(630))]\n",
      "number of element equal 0 5\n",
      "number of element equal 1 5\n",
      "x_train shape: (10, 9, 9, 224)\n",
      "y_train shape: (10,)\n",
      "hasil augmentasi 1 shape: (20, 9, 9, 224)\n",
      "label augmentai 1 shape: (20,)\n",
      "hasil augmentasi 2 shape: (20, 9, 9, 224)\n",
      "label augmentasi 2 shape: (20,)\n",
      "label augment:\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "hasil augmentasi gabungan untuk training: (40, 9, 9, 224)\n",
      "label augmentasi gabungan: (40,)\n",
      "Element 0 occurs 20 times.\n",
      "Element 1 occurs 20 times.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = rf\"{project_path}\\Hyperspectral oil spill detection datasets\"\n",
    "\n",
    "dataset = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if i > 9:\n",
    "        break\n",
    "    file_path = os.path.join(dataset_path, filename)\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        hsi = HSI(file_path)\n",
    "        dataset.append(hsi)\n",
    "    i += 1\n",
    "\n",
    "train_hsi = dataset[0]\n",
    "patch_size = patch_size\n",
    "half_patch = patch_size // 2\n",
    "sample_per_class = sample_per_class\n",
    "\n",
    "train_indices_0 = []\n",
    "train_indices_1 = []\n",
    "\n",
    "print(f\"random: {random_indices}\")\n",
    "\n",
    "if random_indices:\n",
    "    print(\"generating random indices\")\n",
    "    selected_patches_0, selected_patches_1, train_indices_0, train_indices_1 = CS.createSample(train_hsi, patch_size, sample_per_class)\n",
    "else:\n",
    "    print(\"using generated indices\")\n",
    "    train_indices_0 = [(np.int64(188), np.int64(124)), (np.int64(523), np.int64(150)), (np.int64(1003), np.int64(474)), (np.int64(616), np.int64(508)), (np.int64(905), np.int64(552))]\n",
    "    train_indices_1 = [(np.int64(106), np.int64(606)), (np.int64(297), np.int64(468)), (np.int64(926), np.int64(35)), (np.int64(536), np.int64(519)), (np.int64(508), np.int64(442))]\n",
    "\n",
    "    selected_patches_0, selected_patches_1 = CS.getSample(train_hsi, patch_size, sample_per_class, train_indices_0, train_indices_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_indices = train_indices_0 +  train_indices_1\n",
    "\n",
    "# Concatenating along axis 0\n",
    "x_train = np.concatenate((selected_patches_0, selected_patches_1), )\n",
    "\n",
    "y_train = np.array([])\n",
    "\n",
    "gt = train_hsi.gt\n",
    "for indice in train_indices:\n",
    "    # print(gt[indice[0]][indice[1]])\n",
    "    y_train = np.append(y_train, gt[indice[0]][indice[1]])\n",
    "\n",
    "count = np.count_nonzero(y_train == 0)  # Count elements equal to 0\n",
    "print(f'number of element equal 0 {count}')\n",
    "\n",
    "count = np.count_nonzero(y_train == 1)  # Count elements equal to 1\n",
    "print(f'number of element equal 1 {count}')\n",
    "\n",
    "# Print shape to verify\n",
    "print(f\"x_train shape: {x_train.shape}\")  # Expected output: (10, 9, 9, 224)\n",
    "print(f\"y_train shape: {y_train.shape}\") \n",
    "\n",
    "\n",
    "n_category = n_category\n",
    "band_size = band_size\n",
    "num_per_category_augment_1 = num_per_category_augment_1\n",
    "num_per_category_augment_2 = num_per_category_augment_2\n",
    "\n",
    "data_augment1, label_augment1 = aug.Augment_data(x_train, y_train, n_category, patch_size, band_size, num_per_category_augment_1)\n",
    "\n",
    "data_augment2, label_augment2 = aug.Augment_data2(x_train, y_train, n_category, patch_size, band_size, num_per_category_augment_2)\n",
    "\n",
    "print(f\"hasil augmentasi 1 shape: {data_augment1.shape}\")\n",
    "print(f\"label augmentai 1 shape: {label_augment1.shape}\")\n",
    "\n",
    "print(f\"hasil augmentasi 2 shape: {data_augment2.shape}\")\n",
    "print(f\"label augmentasi 2 shape: {label_augment2.shape}\")\n",
    "\n",
    "print(\"label augment:\")\n",
    "print(label_augment1)\n",
    "print(label_augment2)\n",
    "\n",
    "data_augment = np.concatenate((data_augment1, data_augment2))\n",
    "label_augment = np.concatenate((label_augment1, label_augment2))\n",
    "\n",
    "print(f\"hasil augmentasi gabungan untuk training: {data_augment.shape}\")\n",
    "print(f\"label augmentasi gabungan: {label_augment.shape}\")\n",
    "\n",
    "\n",
    "# Count occurrences of each unique element\n",
    "counts = np.bincount(label_augment)\n",
    "\n",
    "# Print results\n",
    "for i, count in enumerate(counts):\n",
    "    print(f\"Element {i} occurs {count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cab1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    \"\"\"\n",
    "    Build a SimSiam model.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_encoder, spectral_band, dim=2048, pred_dim=512):\n",
    "        \"\"\"\n",
    "        dim: feature dimension (default: 2048)\n",
    "        pred_dim: hidden dimension of the predictor (default: 512)\n",
    "        \"\"\"\n",
    "        super(SimSiam, self).__init__()\n",
    "    \n",
    "        self.encoder = base_encoder(pretrained=True)\n",
    "\n",
    "        self.encoder.features = nn.Sequential(*list(self.encoder.features.children())[28:])\n",
    "        self.encoder.features[0] = nn.Conv2d(spectral_band, 512, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.encoder.features[1] = nn.ReLU(inplace=True)\n",
    "        self.encoder.features[2] = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.encoder.classifier[0] = nn.Linear(in_features=25088, out_features=512, bias=True)\n",
    "        self.encoder.classifier[1] = nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.encoder.classifier[3] = nn.Linear(in_features=512, out_features=512, bias=False)\n",
    "        self.encoder.classifier[4] = nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        # Modify the classifier to match the desired output dimensions\n",
    "        # self.encoder.classifier[0] = nn.Linear(512, 4096, bias=True)\n",
    "        self.encoder.classifier[6] = nn.Linear(512, dim)\n",
    "\n",
    "        # # Fix: Get the correct input dimension from VGG16 classifier\n",
    "        prev_dim = self.encoder.classifier[3].out_features\n",
    "\n",
    "        # Fix: Assign modified layers to classifier instead of non-existing 'fc'\n",
    "        self.encoder.classifier[6] = nn.Sequential(\n",
    "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(prev_dim),\n",
    "                                        nn.ReLU(inplace=True), # first layer\n",
    "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(prev_dim),\n",
    "                                        nn.ReLU(inplace=True), # second layer\n",
    "                                        self.encoder.classifier[6],\n",
    "                                        nn.BatchNorm1d(dim, affine=False)) # output layer# output layer\n",
    "                                        \n",
    "        self.encoder.classifier[6][6].bias.requires_grad = False\n",
    "        # self.projector[6].bias.requires_grad = False\n",
    "\n",
    "        # build a 3-layer projector\n",
    "        # prev_dim = self.encoder.fc.weight.shape[1]\n",
    "        # self.encoder.fc = nn.Sequential(nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "        #                                 nn.BatchNorm1d(prev_dim),\n",
    "        #                                 nn.ReLU(inplace=True), # first layer\n",
    "        #                                 nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "        #                                 nn.BatchNorm1d(prev_dim),\n",
    "        #                                 nn.ReLU(inplace=True), # second layer\n",
    "        #                                 self.encoder.fc,\n",
    "        #                                 nn.BatchNorm1d(dim, affine=False)) # output layer\n",
    "        # self.encoder.fc[6].bias.requires_grad = False # hack: not use bias as it is followed by BN\n",
    "\n",
    "        # build a 2-layer predictor\n",
    "        self.predictor = nn.Sequential(nn.Linear(dim, pred_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(pred_dim),\n",
    "                                        nn.ReLU(inplace=True), # hidden layer\n",
    "                                        nn.Linear(pred_dim, dim)) # output layer\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            x1: first views of images\n",
    "            x2: second views of images\n",
    "        Output:\n",
    "            p1, p2, z1, z2: predictors and targets of the network\n",
    "            See Sec. 3 of https://arxiv.org/abs/2011.10566 for detailed notations\n",
    "        \"\"\"\n",
    "\n",
    "       \n",
    "        z1 = self.encoder.features(x1) # NxC\n",
    "        z2 = self.encoder.features(x2) # NxC\n",
    "      \n",
    "\n",
    "        z1 = self.encoder.avgpool(z1)\n",
    "        z2 = self.encoder.avgpool(z2)\n",
    "\n",
    "\n",
    "        z1 = torch.flatten(z1, 1)\n",
    "        z2 = torch.flatten(z2, 1)\n",
    "   \n",
    "        z1 = self.encoder.classifier(z1)\n",
    "        z2 = self.encoder.classifier(z2)\n",
    "\n",
    "\n",
    "\n",
    "        p1 = self.predictor(z1) # NxC\n",
    "        p2 = self.predictor(z2) # NxC\n",
    "\n",
    "        return p1, p2, z1.detach(), z2.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4613ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'vgg16'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimSiam(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (7): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (predictor): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=512, bias=False)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  )\n",
      ")\n",
      "parameter 17819648\n"
     ]
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "\n",
    "# create model\n",
    "base_encoder = base_encoder\n",
    "print(\"=> creating model '{}'\".format(base_encoder))\n",
    "pretrain_model = SimSiam(models.__dict__[base_encoder],224)\n",
    "\n",
    "\n",
    "lr = 0.01\n",
    "init_lr = lr * batch_size / 256\n",
    "gpu = 0\n",
    "\n",
    "print(pretrain_model)\n",
    "pretrain_parameters = sum(p.numel() for p in pretrain_model.parameters())\n",
    "print(f\"parameter {pretrain_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ffc071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 224, 9, 9])\n",
      "input2 shape: torch.Size([1, 224, 9, 9])\n",
      "p1 shape torch.Size([1, 2048]), p2 shape torch.Size([1, 2048])\n",
      "z1 shape torch.Size([1, 2048]), z2 shape torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "test = data_augment[0]\n",
    "input = torch.tensor(test).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "test2 = data_augment[1]\n",
    "test2 = torch.tensor(test2).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "input2 = test2\n",
    "\n",
    "\n",
    "print(f\"input shape: {input.shape}\")\n",
    "print(f\"input2 shape: {input2.shape}\")\n",
    "\n",
    "# Pass the input through the model\n",
    "pretrain_model.eval()\n",
    "p1, p2, z1, z2  = pretrain_model(input, input2)\n",
    "\n",
    "print(f\"p1 shape {p1.shape}, p2 shape {p2.shape}\")\n",
    "print(f\"z1 shape {z1.shape}, z2 shape {z2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0224d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(40, 9, 9, 224)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CosineSimilarity(dim=1).cuda(gpu)\n",
    "print(gpu)\n",
    "optim_params = pretrain_model.parameters()\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "optimizer = torch.optim.SGD(optim_params, init_lr,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "augmentation = [\n",
    "    transforms.RandomHorizontalFlip(),  # Flip along width\n",
    "    transforms.RandomVerticalFlip(),    # Flip along height\n",
    "    transforms.RandomRotation(20),      # Rotate image slightly\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize hyperspectral data\n",
    "]\n",
    "\n",
    "transform = simsiam.loader.TwoCropsTransform(transforms.Compose(augmentation))\n",
    "\n",
    "print(data_augment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd6786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([40, 224, 9, 9])\n",
      "generate data loader using seed\n",
      "bacth size: torch.Size([20, 224, 9, 9])\n",
      "length batch: 20\n",
      "Train loader size: 2\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (Tensor or list of Tensors): Preloaded images of shape (N, 9, 9, 224)\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.images = images  # Assuming it's a list or tensor\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img1 = self.transform(img)  # First augmentation\n",
    "            img2 = self.transform(img)  # Second augmentation\n",
    "        \n",
    "            return img1, img2  # Return both augmented versions\n",
    "        \n",
    "        return img, img  # If no transform is provided, return the original image twice\n",
    "\n",
    "\n",
    "# Example usage\n",
    "pretrain_preloaded_image = data_augment \n",
    "\n",
    "pretrain_X_train = torch.tensor(pretrain_preloaded_image)\n",
    "pretrain_X_train = pretrain_X_train.to(torch.float32)\n",
    "pretrain_X_train = pretrain_X_train.permute(0, 3, 1, 2)\n",
    "print(f\"X_train shape: {pretrain_X_train.shape}\")\n",
    "\n",
    "# Define transformations if needed\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),  # Example normalization\n",
    "])\n",
    "\n",
    "pretrain_train_dataset = CustomDataset(pretrain_X_train, transform=transform)\n",
    "\n",
    "train_sampler = None\n",
    "\n",
    "if seeded_run:\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    \n",
    "    pretrain_train_loader = DataLoader(\n",
    "        pretrain_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    print(\"generate data loader using seed\")\n",
    "else:\n",
    "    pretrain_train_loader = DataLoader(\n",
    "        pretrain_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(train_sampler is None),\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 7. Check Output\n",
    "\n",
    "batch1, batch2 = next(iter(pretrain_train_loader))\n",
    "\n",
    "print(f\"bacth size: {batch1.size()}\")\n",
    "print(f\"length batch: {len(batch1)}\")  # Should print 2 (Two transformed views per image)\n",
    "print(f\"Train loader size: {len(pretrain_train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33c59999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if 'fix_lr' in param_group and param_group['fix_lr']:\n",
    "            param_group['lr'] = init_lr\n",
    "        else:\n",
    "            param_group['lr'] = cur_lr\n",
    "\n",
    "class Pretrain_AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "    \n",
    "\n",
    "class Pretrain_ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "    \n",
    "def pretrain_save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6abedcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_train(train_loader, model, criterion, optimizer, epoch, device):\n",
    "    batch_time = Pretrain_AverageMeter('Time', ':6.3f')\n",
    "    data_time = Pretrain_AverageMeter('Data', ':6.3f')\n",
    "    losses = Pretrain_AverageMeter('Loss', ':.4f')\n",
    "    progress = Pretrain_ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    for i, (images1, images2) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input1 = images1.to(device, non_blocking=True)\n",
    "        input2 = images2.to(device, non_blocking=True)\n",
    "\n",
    "        p1, p2, z1, z2 = model(x1=input1, x2=input2) \n",
    "        loss = -(criterion(p1, z2).mean() + criterion(p2, z1).mean()) * 0.5\n",
    "\n",
    "        losses.update(loss.item(), input1.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "    # Return average training loss for early stopping\n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1714672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch: [0][0/2]\tTime  0.082 ( 0.082)\tData  0.029 ( 0.029)\tLoss -0.0031 (-0.0031)\n",
      "Epoch 1: Average Training Loss: -0.003189\n",
      "✅ New best model saved with loss -0.003189\n",
      "Epoch: [1][0/2]\tTime  0.084 ( 0.084)\tData  0.019 ( 0.019)\tLoss -0.0015 (-0.0015)\n",
      "Epoch 2: Average Training Loss: -0.001248\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [2][0/2]\tTime  0.083 ( 0.083)\tData  0.029 ( 0.029)\tLoss -0.0067 (-0.0067)\n",
      "Epoch 3: Average Training Loss: -0.006046\n",
      "✅ New best model saved with loss -0.006046\n",
      "Epoch: [3][0/2]\tTime  0.074 ( 0.074)\tData  0.021 ( 0.021)\tLoss -0.0045 (-0.0045)\n",
      "Epoch 4: Average Training Loss: -0.000886\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [4][0/2]\tTime  0.096 ( 0.096)\tData  0.037 ( 0.037)\tLoss -0.0034 (-0.0034)\n",
      "Epoch 5: Average Training Loss: -0.003082\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [5][0/2]\tTime  0.063 ( 0.063)\tData  0.020 ( 0.020)\tLoss -0.0038 (-0.0038)\n",
      "Epoch 6: Average Training Loss: -0.003682\n",
      "❌ No improvement. Patience: 3/50\n",
      "Epoch: [6][0/2]\tTime  0.078 ( 0.078)\tData  0.024 ( 0.024)\tLoss -0.0077 (-0.0077)\n",
      "Epoch 7: Average Training Loss: -0.008204\n",
      "✅ New best model saved with loss -0.008204\n",
      "Epoch: [7][0/2]\tTime  0.057 ( 0.057)\tData  0.014 ( 0.014)\tLoss -0.0088 (-0.0088)\n",
      "Epoch 8: Average Training Loss: -0.005958\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [8][0/2]\tTime  0.074 ( 0.074)\tData  0.022 ( 0.022)\tLoss 0.0008 (0.0008)\n",
      "Epoch 9: Average Training Loss: -0.001593\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [9][0/2]\tTime  0.082 ( 0.082)\tData  0.023 ( 0.023)\tLoss -0.0109 (-0.0109)\n",
      "Epoch 10: Average Training Loss: -0.007814\n",
      "❌ No improvement. Patience: 3/50\n",
      "Epoch: [10][0/2]\tTime  0.070 ( 0.070)\tData  0.021 ( 0.021)\tLoss -0.0087 (-0.0087)\n",
      "Epoch 11: Average Training Loss: -0.006515\n",
      "❌ No improvement. Patience: 4/50\n",
      "Epoch: [11][0/2]\tTime  0.063 ( 0.063)\tData  0.021 ( 0.021)\tLoss -0.0106 (-0.0106)\n",
      "Epoch 12: Average Training Loss: -0.010628\n",
      "✅ New best model saved with loss -0.010628\n",
      "Epoch: [12][0/2]\tTime  0.053 ( 0.053)\tData  0.014 ( 0.014)\tLoss -0.0076 (-0.0076)\n",
      "Epoch 13: Average Training Loss: -0.006711\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [13][0/2]\tTime  0.064 ( 0.064)\tData  0.019 ( 0.019)\tLoss -0.0081 (-0.0081)\n",
      "Epoch 14: Average Training Loss: -0.007066\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [14][0/2]\tTime  0.066 ( 0.066)\tData  0.022 ( 0.022)\tLoss -0.0075 (-0.0075)\n",
      "Epoch 15: Average Training Loss: -0.007373\n",
      "❌ No improvement. Patience: 3/50\n",
      "Epoch: [15][0/2]\tTime  0.072 ( 0.072)\tData  0.027 ( 0.027)\tLoss -0.0113 (-0.0113)\n",
      "Epoch 16: Average Training Loss: -0.010020\n",
      "❌ No improvement. Patience: 4/50\n",
      "Epoch: [16][0/2]\tTime  0.067 ( 0.067)\tData  0.020 ( 0.020)\tLoss -0.0047 (-0.0047)\n",
      "Epoch 17: Average Training Loss: -0.005584\n",
      "❌ No improvement. Patience: 5/50\n",
      "Epoch: [17][0/2]\tTime  0.071 ( 0.071)\tData  0.021 ( 0.021)\tLoss -0.0036 (-0.0036)\n",
      "Epoch 18: Average Training Loss: -0.003327\n",
      "❌ No improvement. Patience: 6/50\n",
      "Epoch: [18][0/2]\tTime  0.065 ( 0.065)\tData  0.019 ( 0.019)\tLoss -0.0108 (-0.0108)\n",
      "Epoch 19: Average Training Loss: -0.009094\n",
      "❌ No improvement. Patience: 7/50\n",
      "Epoch: [19][0/2]\tTime  0.076 ( 0.076)\tData  0.022 ( 0.022)\tLoss -0.0082 (-0.0082)\n",
      "Epoch 20: Average Training Loss: -0.008088\n",
      "❌ No improvement. Patience: 8/50\n"
     ]
    }
   ],
   "source": [
    "# Early stopping parameters\n",
    "best_loss = float('inf')\n",
    "patience = 50  # Number of epochs to wait for improvement\n",
    "patience_counter = 0\n",
    "\n",
    "start_epoch = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "pretrain_model.to(device)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "filename = f\"{timestamp}_model.pth.tar\"\n",
    "filepath = f\"models/pretrain/{filename}\"\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    pretrain_adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "\n",
    "    # Train and get average loss\n",
    "    avg_loss = pretrain_train(pretrain_train_loader, pretrain_model, criterion, optimizer, epoch, device)\n",
    "    print(f\"Epoch {epoch + 1}: Average Training Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': 'vgg16',\n",
    "            'state_dict': pretrain_model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'best_loss': best_loss\n",
    "        }, filepath)\n",
    "\n",
    "        print(f\"✅ New best model saved with loss {best_loss:.6f}\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"❌ No improvement. Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d5f40d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain Parameter 17819648\n",
      "models\\pretrain\\20250725_225802_model.pth.tar\n"
     ]
    }
   ],
   "source": [
    "pretrain_parameters = sum(p.numel() for p in pretrain_model.parameters())\n",
    "print(f\"pretrain Parameter {pretrain_parameters}\")\n",
    "\n",
    "pretrained = rf'models\\pretrain\\{filename}'\n",
    "print(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32ba8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "\n",
    "class VGG16_HSI(nn.Module):\n",
    "    def __init__(self, num_classes=2, spectral_band=224):\n",
    "        super(VGG16_HSI, self).__init__()\n",
    "\n",
    "        self.encoder =  vgg16(pretrained=True)\n",
    "\n",
    "        self.encoder.features = nn.Sequential(*list(self.encoder.features.children())[28:])\n",
    "        self.encoder.features[0] = nn.Conv2d(spectral_band, 512, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.encoder.features[1] = nn.ReLU(inplace=True)\n",
    "        self.encoder.features[2] = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.encoder.classifier[0] = nn.Linear(in_features=25088, out_features=512, bias=True)\n",
    "        self.encoder.classifier[1] = nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.encoder.classifier[3] = nn.Linear(in_features=512, out_features=512, bias=False)\n",
    "        self.encoder.classifier[4] = nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        # Modify the classifier to match the desired output dimensions\n",
    "        # self.encoder.classifier[0] = nn.Linear(512, 4096, bias=True)\n",
    "        self.encoder.classifier[6] = nn.Linear(512, 2048)\n",
    "        self.encoder.added_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=128, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3, inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=2, bias=True)\n",
    "        )   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder.features(x)  # Pass to VGG-16\n",
    "        x = self.encoder.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.encoder.classifier(x)  # Final classification layer\n",
    "        x = self.encoder.added_classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee42b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: 0 for training\n",
      "=> creating model\n",
      "finetune_parameter 15455618\n",
      "VGG16_HSI(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gpu = 0\n",
    "\n",
    "print(\"Use GPU: {} for training\".format(gpu))\n",
    "\n",
    "print(\"=> creating model\")\n",
    "\n",
    "model_finetune = VGG16_HSI()\n",
    "finetune_parameter = sum(p.numel() for p in model_finetune.parameters())\n",
    "print(f\"finetune_parameter {finetune_parameter}\")\n",
    "\n",
    "print(model_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9fa84ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'models\\pretrain\\20250725_225802_model.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_16496\\2432251866.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_16496\\2432251866.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually loading parameters with remapping:\n",
      "\n",
      "✓ Loaded: encoder.features.0.weight → encoder.features.0.weight\n",
      "✓ Loaded: encoder.features.0.bias → encoder.features.0.bias\n",
      "✓ Loaded: encoder.classifier.0.weight → encoder.classifier.0.weight\n",
      "✓ Loaded: encoder.classifier.0.bias → encoder.classifier.0.bias\n",
      "✓ Loaded: encoder.classifier.1.weight → encoder.classifier.1.weight\n",
      "✓ Loaded: encoder.classifier.1.bias → encoder.classifier.1.bias\n",
      "✓ Loaded: encoder.classifier.1.running_mean → encoder.classifier.1.running_mean\n",
      "✓ Loaded: encoder.classifier.1.running_var → encoder.classifier.1.running_var\n",
      "✓ Loaded: encoder.classifier.1.num_batches_tracked → encoder.classifier.1.num_batches_tracked\n",
      "✓ Loaded: encoder.classifier.3.weight → encoder.classifier.3.weight\n",
      "✓ Loaded: encoder.classifier.4.weight → encoder.classifier.4.weight\n",
      "✓ Loaded: encoder.classifier.4.bias → encoder.classifier.4.bias\n",
      "✓ Loaded: encoder.classifier.4.running_mean → encoder.classifier.4.running_mean\n",
      "✓ Loaded: encoder.classifier.4.running_var → encoder.classifier.4.running_var\n",
      "✓ Loaded: encoder.classifier.4.num_batches_tracked → encoder.classifier.4.num_batches_tracked\n",
      "❌ Key not found in model: encoder.classifier.6.0.weight\n",
      "❌ Key not found in model: encoder.classifier.6.1.weight\n",
      "❌ Key not found in model: encoder.classifier.6.1.bias\n",
      "❌ Key not found in model: encoder.classifier.6.1.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.1.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.1.num_batches_tracked\n",
      "❌ Key not found in model: encoder.classifier.6.3.weight\n",
      "❌ Key not found in model: encoder.classifier.6.4.weight\n",
      "❌ Key not found in model: encoder.classifier.6.4.bias\n",
      "❌ Key not found in model: encoder.classifier.6.4.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.4.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.4.num_batches_tracked\n",
      "✓ Loaded: encoder.classifier.6.6.weight → encoder.classifier.6.weight\n",
      "✓ Loaded: encoder.classifier.6.6.bias → encoder.classifier.6.bias\n",
      "❌ Key not found in model: encoder.classifier.6.7.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.7.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.7.num_batches_tracked\n",
      "❌ Key not found in model: predictor.0.weight\n",
      "❌ Key not found in model: predictor.1.weight\n",
      "❌ Key not found in model: predictor.1.bias\n",
      "❌ Key not found in model: predictor.1.running_mean\n",
      "❌ Key not found in model: predictor.1.running_var\n",
      "❌ Key not found in model: predictor.1.num_batches_tracked\n",
      "❌ Key not found in model: predictor.3.weight\n",
      "❌ Key not found in model: predictor.3.bias\n",
      "\n",
      "=== Summary ===\n",
      "Total checkpoint keys: 40\n",
      "Successfully loaded: 17\n",
      "Missing keys in model: 23\n",
      "Shape mismatches: 0\n",
      "\n",
      "Missing keys:\n",
      "  encoder.classifier.6.0.weight\n",
      "  encoder.classifier.6.1.weight\n",
      "  encoder.classifier.6.1.bias\n",
      "  encoder.classifier.6.1.running_mean\n",
      "  encoder.classifier.6.1.running_var\n",
      "  encoder.classifier.6.1.num_batches_tracked\n",
      "  encoder.classifier.6.3.weight\n",
      "  encoder.classifier.6.4.weight\n",
      "  encoder.classifier.6.4.bias\n",
      "  encoder.classifier.6.4.running_mean\n",
      "  encoder.classifier.6.4.running_var\n",
      "  encoder.classifier.6.4.num_batches_tracked\n",
      "  encoder.classifier.6.7.running_mean\n",
      "  encoder.classifier.6.7.running_var\n",
      "  encoder.classifier.6.7.num_batches_tracked\n",
      "  predictor.0.weight\n",
      "  predictor.1.weight\n",
      "  predictor.1.bias\n",
      "  predictor.1.running_mean\n",
      "  predictor.1.running_var\n",
      "  predictor.1.num_batches_tracked\n",
      "  predictor.3.weight\n",
      "  predictor.3.bias\n",
      "=> loaded pre-trained model 'models\\pretrain\\20250725_225802_model.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "if pretrained:\n",
    "    if os.path.isfile(pretrained):\n",
    "        print(\"=> loading checkpoint '{}'\".format(pretrained))\n",
    "        checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
    "\n",
    "        checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
    "        pretrained_dict = checkpoint['state_dict']\n",
    "        finetune_model_dict = model_finetune.state_dict()\n",
    "\n",
    "        # Key remapping: map .6.6.weight → .6.weight and .6.6.bias → .6.bias\n",
    "        key_mapping = {\n",
    "            'encoder.classifier.6.6.weight': 'encoder.classifier.6.weight',\n",
    "            'encoder.classifier.6.6.bias': 'encoder.classifier.6.bias',\n",
    "        }\n",
    "\n",
    "        # Prepare containers\n",
    "        remapped_dict = {}\n",
    "        loaded_keys = []\n",
    "        shape_mismatches = []\n",
    "        missing_keys = []\n",
    "\n",
    "        print(\"Manually loading parameters with remapping:\\n\")\n",
    "\n",
    "        for k, v in pretrained_dict.items():\n",
    "            new_k = key_mapping.get(k, k)  # Remap if necessary\n",
    "            if new_k in finetune_model_dict:\n",
    "                if finetune_model_dict[new_k].shape == v.shape:\n",
    "                    remapped_dict[new_k] = v\n",
    "                    loaded_keys.append((k, new_k))\n",
    "                    print(f\"✓ Loaded: {k} → {new_k}\")\n",
    "                else:\n",
    "                    shape_mismatches.append((new_k, finetune_model_dict[new_k].shape, v.shape))\n",
    "                    print(f\"⚠️ Shape mismatch: {new_k} | model: {finetune_model_dict[new_k].shape} vs checkpoint: {v.shape}\")\n",
    "            else:\n",
    "                missing_keys.append(new_k)\n",
    "                print(f\"❌ Key not found in model: {new_k}\")\n",
    "\n",
    "        # Load state dict\n",
    "        model_finetune.load_state_dict(remapped_dict, strict=False)\n",
    "\n",
    "        # Summary\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(f\"Total checkpoint keys: {len(pretrained_dict)}\")\n",
    "        print(f\"Successfully loaded: {len(loaded_keys)}\")\n",
    "        print(f\"Missing keys in model: {len(missing_keys)}\")\n",
    "        print(f\"Shape mismatches: {len(shape_mismatches)}\")\n",
    "\n",
    "        if missing_keys:\n",
    "            print(\"\\nMissing keys:\")\n",
    "            for key in missing_keys:\n",
    "                print(f\"  {key}\")\n",
    "\n",
    "        if shape_mismatches:\n",
    "            print(\"\\nShape mismatches:\")\n",
    "            for key, model_shape, ckpt_shape in shape_mismatches:\n",
    "                print(f\"  {key} | model: {model_shape}, checkpoint: {ckpt_shape}\")\n",
    "\n",
    "  \n",
    "     \n",
    "\n",
    "        print(\"=> loaded pre-trained model '{}'\".format(pretrained))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(pretrained))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28417fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16_HSI(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "encoder.features.0.weight: requires_grad=False\n",
      "encoder.features.0.bias: requires_grad=False\n",
      "encoder.classifier.0.weight: requires_grad=False\n",
      "encoder.classifier.0.bias: requires_grad=False\n",
      "encoder.classifier.1.weight: requires_grad=False\n",
      "encoder.classifier.1.bias: requires_grad=False\n",
      "encoder.classifier.3.weight: requires_grad=False\n",
      "encoder.classifier.4.weight: requires_grad=False\n",
      "encoder.classifier.4.bias: requires_grad=False\n",
      "encoder.classifier.6.weight: requires_grad=False\n",
      "encoder.classifier.6.bias: requires_grad=False\n",
      "encoder.added_classifier.0.weight: requires_grad=True\n",
      "encoder.added_classifier.0.bias: requires_grad=True\n",
      "encoder.added_classifier.3.weight: requires_grad=True\n",
      "encoder.added_classifier.3.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for param in model_finetune.encoder.features.parameters():\n",
    "    param.requires_grad = False  # Freeze convolutional layers\n",
    "\n",
    "for param in model_finetune.encoder.classifier.parameters():\n",
    "    param.requires_grad = False  # Freeze all but the last FC layer\n",
    "\n",
    "\n",
    "print(model_finetune)\n",
    "# Check which layers are trainable\n",
    "for name, param in model_finetune.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5f67fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 224, 9, 9])\n",
      "input2 shape: torch.Size([1, 224, 9, 9])\n",
      "output shape torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "test = data_augment[0]\n",
    "test = torch.tensor(test).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "input = test\n",
    "\n",
    "\n",
    "test2 = data_augment[1]\n",
    "test2 = torch.tensor(test2).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "input2 = test2\n",
    "\n",
    "\n",
    "print(f\"input shape: {input.shape}\")\n",
    "print(f\"input2 shape: {input2.shape}\")\n",
    "\n",
    "# Pass the input through the model\n",
    "model_finetune.eval()\n",
    "output = model_finetune(input)\n",
    "\n",
    "print(f\"output shape {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7321178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_augment shape (40, 9, 9, 224)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 0\n",
    "\n",
    "init_lr = lr * batch_size / 256\n",
    "\n",
    "torch.cuda.set_device(gpu)\n",
    "model_finetune = model_finetune.cuda(gpu)\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "\n",
    "# optimize only the linear classifier\n",
    "parameters = list(filter(lambda p: p.requires_grad, model_finetune.parameters()))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(parameters, init_lr,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=weight_decay)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "\n",
    "print(f\"data_augment shape {data_augment.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d915ed95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune_X_train shape: torch.Size([40, 224, 9, 9])\n",
      "Train shape: torch.Size([20, 224, 9, 9]), Validation shape: torch.Size([20, 224, 9, 9])\n",
      "generate data loader using seed\n",
      "torch.Size([20])\n",
      "Train loader size: 1, Validation loader size: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Example usage\n",
    "class CustomDatasetFinetune(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (Tensor or list of Tensors): Preloaded images of shape (N, 9, 9, 224)\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.images = images  # Assuming it's a list or tensor\n",
    "        self.transform = transform\n",
    "        self.label = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img1 = self.transform(img)  # First augmentation\n",
    "        \n",
    "            return img1, label  # Return both augmented versions\n",
    "        \n",
    "        return img, label  # If no transform is provided, return the original image twice\n",
    "    \n",
    "finetune_preloaded_images = data_augment  \n",
    "finetune_X = torch.tensor(finetune_preloaded_images)\n",
    "finetune_X= finetune_X.to(torch.float32)\n",
    "finetune_X = finetune_X.permute(0, 3, 1, 2)\n",
    "print(f\"finetune_X_train shape: {finetune_X.shape}\")\n",
    "\n",
    "finetune_y = torch.tensor(label_augment)\n",
    "#\n",
    "# Define transformations if needed\n",
    "\n",
    "testSize = test_size\n",
    "finetune_X_train, finetune_X_val, finetune_y_train, finetune_y_val = train_test_split(finetune_X, finetune_y, test_size = testSize, random_state=seed, stratify=finetune_y)\n",
    "print(f\"Train shape: {finetune_X_train.shape}, Validation shape: {finetune_X_val.shape}\")\n",
    "\n",
    "finetune_train_dataset = CustomDatasetFinetune(finetune_X_train, finetune_y_train)\n",
    "finetune_val_dataset = CustomDatasetFinetune(finetune_X_val, finetune_y_val)\n",
    "\n",
    "train_sampler = None\n",
    "\n",
    "if seeded_run:\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    \n",
    "    finetune_train_loader = DataLoader(\n",
    "        finetune_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    finetune_val_loader = DataLoader(\n",
    "        finetune_val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    \n",
    "    print(\"generate data loader using seed\")\n",
    "else:\n",
    "    finetune_train_loader = DataLoader(finetune_train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=False)\n",
    "    finetune_val_loader = DataLoader(finetune_val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "# 7. Check Output\n",
    "\n",
    "batch1 = next(iter(finetune_train_loader))\n",
    "\n",
    "print(batch1[1].size())\n",
    "print(f\"Train loader size: {len(finetune_train_loader)}, Validation loader size: {len(finetune_val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b237e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = FinetuneAverageMeter('Time', ':6.3f')\n",
    "    data_time = FinetuneAverageMeter('Data', ':6.3f')\n",
    "    losses = FinetuneAverageMeter('Loss', ':.4e')\n",
    "    top1 = FinetuneAverageMeter('Acc@1', ':6.2f')\n",
    "    progress = FinetuneProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    \"\"\"\n",
    "    Switch to eval mode:\n",
    "    Under the protocol of linear classification on frozen features/models,\n",
    "    it is not legitimate to change any part of the pre-trained model.\n",
    "    BatchNorm in train mode may revise running mean/std (even if it receives\n",
    "    no gradient), which are part of the model parameters too.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        gpu = 0\n",
    "        images = images.cuda(gpu, non_blocking=True)\n",
    "        target = target.cuda(gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, = finetune_accuracy(output, target, topk=(1,))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        print_freq = 10\n",
    "        if i % print_freq == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "\n",
    "def finetune_validate(val_loader, model, criterion):\n",
    "    batch_time = FinetuneAverageMeter('Time', ':6.3f')\n",
    "    losses = FinetuneAverageMeter('Loss', ':.4e')\n",
    "    top1 = FinetuneAverageMeter('Acc@1', ':6.2f')\n",
    "  \n",
    "    progress = FinetuneProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "       \n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "      \n",
    "            gpu = 0\n",
    "            images = images.cuda(gpu, non_blocking=True)\n",
    "            target = target.cuda(gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, = finetune_accuracy(output, target, topk=(1,))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            # top5.update(acc5[0], images.size(0))\n",
    "            print(f\"in validation finction {acc1}\")\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            print_freq = 10\n",
    "            if i % print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def finetune_save_checkpoint(timestamp, epoch, state, is_best, filename='models/checkpoint.pth.tar'):\n",
    "    filename='models/finetune/{}_model.pth.tar'.format(timestamp)\n",
    "    torch.save(state, filename)\n",
    "    # if is_best:\n",
    "    #     shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "def finetune_sanity_check(state_dict, pretrained_weights):\n",
    "    \"\"\"\n",
    "    Linear classifier should not change any weights other than the linear layer.\n",
    "    This sanity check asserts nothing wrong happens (e.g., BN stats updated).\n",
    "    \"\"\"\n",
    "    print(\"=> loading '{}' for sanity check\".format(pretrained_weights))\n",
    "    checkpoint = torch.load(pretrained_weights, map_location=\"cpu\")\n",
    "    state_dict_pre = checkpoint['state_dict']\n",
    "\n",
    "    for k in list(state_dict.keys()):\n",
    "        # Ignore fc layer\n",
    "        if 'fc.weight' in k or 'fc.bias' in k:\n",
    "            continue\n",
    "\n",
    "        # Adjust key mapping to match checkpoint format\n",
    "        k_pre = k.replace('module.encoder.', '')  # Remove unnecessary prefix\n",
    "\n",
    "        # Skip missing keys\n",
    "        if k_pre not in state_dict_pre:\n",
    "            print(f\"Warning: {k_pre} not found in pretrained model. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Check if tensor shapes match before comparing values\n",
    "        if state_dict[k].shape != state_dict_pre[k_pre].shape:\n",
    "            print(f\"Warning: Shape mismatch for {k}: {state_dict[k].shape} vs {state_dict_pre[k_pre].shape}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Assert that the weights remain unchanged\n",
    "        assert ((state_dict[k].cpu() == state_dict_pre[k_pre]).all()), \\\n",
    "            '{} is changed in linear classifier training.'.format(k)\n",
    "\n",
    "    print(\"=> sanity check passed.\")\n",
    "\n",
    "\n",
    "\n",
    "class FinetuneAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class FinetuneProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def finetune_adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = cur_lr\n",
    "\n",
    "\n",
    "def finetune_accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff8982a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.features.0.weight: requires_grad=False\n",
      "encoder.features.0.bias: requires_grad=False\n",
      "encoder.classifier.0.weight: requires_grad=False\n",
      "encoder.classifier.0.bias: requires_grad=False\n",
      "encoder.classifier.1.weight: requires_grad=False\n",
      "encoder.classifier.1.bias: requires_grad=False\n",
      "encoder.classifier.3.weight: requires_grad=False\n",
      "encoder.classifier.4.weight: requires_grad=False\n",
      "encoder.classifier.4.bias: requires_grad=False\n",
      "encoder.classifier.6.weight: requires_grad=False\n",
      "encoder.classifier.6.bias: requires_grad=False\n",
      "encoder.added_classifier.0.weight: requires_grad=True\n",
      "encoder.added_classifier.0.bias: requires_grad=True\n",
      "encoder.added_classifier.3.weight: requires_grad=True\n",
      "encoder.added_classifier.3.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_finetune.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa72c1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/1]\tTime  0.166 ( 0.166)\tData  0.001 ( 0.001)\tLoss 7.0878e-01 (7.0878e-01)\tAcc@1  50.00 ( 50.00)\n",
      "in validation finction tensor([50.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.304 ( 0.304)\tLoss 6.8712e-01 (6.8712e-01)\tAcc@1  50.00 ( 50.00)\n",
      " * Acc@1 50.000\n",
      "✅ Epoch 1: New best Acc@1: 50.00. Model saved.\n",
      "Epoch: [1][0/1]\tTime  0.018 ( 0.018)\tData  0.000 ( 0.000)\tLoss 6.8732e-01 (6.8732e-01)\tAcc@1  50.00 ( 50.00)\n",
      "in validation finction tensor([70.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.004 ( 0.004)\tLoss 6.5744e-01 (6.5744e-01)\tAcc@1  70.00 ( 70.00)\n",
      " * Acc@1 70.000\n",
      "✅ Epoch 2: New best Acc@1: 70.00. Model saved.\n",
      "Epoch: [2][0/1]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tLoss 6.5853e-01 (6.5853e-01)\tAcc@1  55.00 ( 55.00)\n",
      "in validation finction tensor([90.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.025 ( 0.025)\tLoss 6.2557e-01 (6.2557e-01)\tAcc@1  90.00 ( 90.00)\n",
      " * Acc@1 90.000\n",
      "✅ Epoch 3: New best Acc@1: 90.00. Model saved.\n",
      "Epoch: [3][0/1]\tTime  0.014 ( 0.014)\tData  0.003 ( 0.003)\tLoss 6.2665e-01 (6.2665e-01)\tAcc@1  90.00 ( 90.00)\n",
      "in validation finction tensor([90.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.012 ( 0.012)\tLoss 5.9175e-01 (5.9175e-01)\tAcc@1  90.00 ( 90.00)\n",
      " * Acc@1 90.000\n",
      "❌ Epoch 4: No improvement. Patience counter: 1/50\n",
      "Epoch: [4][0/1]\tTime  0.010 ( 0.010)\tData  0.002 ( 0.002)\tLoss 5.9263e-01 (5.9263e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([100.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.012 ( 0.012)\tLoss 5.5543e-01 (5.5543e-01)\tAcc@1 100.00 (100.00)\n",
      " * Acc@1 100.000\n",
      "✅ Epoch 5: New best Acc@1: 100.00. Model saved.\n",
      "Epoch: [5][0/1]\tTime  0.006 ( 0.006)\tData  0.002 ( 0.002)\tLoss 5.5761e-01 (5.5761e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([95.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.010 ( 0.010)\tLoss 5.1625e-01 (5.1625e-01)\tAcc@1  95.00 ( 95.00)\n",
      " * Acc@1 95.000\n",
      "❌ Epoch 6: No improvement. Patience counter: 1/50\n",
      "Epoch: [6][0/1]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tLoss 5.2068e-01 (5.2068e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([90.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.016 ( 0.016)\tLoss 4.7718e-01 (4.7718e-01)\tAcc@1  90.00 ( 90.00)\n",
      " * Acc@1 90.000\n",
      "❌ Epoch 7: No improvement. Patience counter: 2/50\n",
      "Epoch: [7][0/1]\tTime  0.012 ( 0.012)\tData  0.000 ( 0.000)\tLoss 4.8388e-01 (4.8388e-01)\tAcc@1  95.00 ( 95.00)\n",
      "in validation finction tensor([90.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.012 ( 0.012)\tLoss 4.4140e-01 (4.4140e-01)\tAcc@1  90.00 ( 90.00)\n",
      " * Acc@1 90.000\n",
      "❌ Epoch 8: No improvement. Patience counter: 3/50\n",
      "Epoch: [8][0/1]\tTime  0.012 ( 0.012)\tData  0.002 ( 0.002)\tLoss 4.4992e-01 (4.4992e-01)\tAcc@1  90.00 ( 90.00)\n",
      "in validation finction tensor([90.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.013 ( 0.013)\tLoss 4.0985e-01 (4.0985e-01)\tAcc@1  90.00 ( 90.00)\n",
      " * Acc@1 90.000\n",
      "❌ Epoch 9: No improvement. Patience counter: 4/50\n",
      "Epoch: [9][0/1]\tTime  0.011 ( 0.011)\tData  0.003 ( 0.003)\tLoss 4.1912e-01 (4.1912e-01)\tAcc@1  95.00 ( 95.00)\n",
      "in validation finction tensor([95.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.013 ( 0.013)\tLoss 3.8203e-01 (3.8203e-01)\tAcc@1  95.00 ( 95.00)\n",
      " * Acc@1 95.000\n",
      "❌ Epoch 10: No improvement. Patience counter: 5/50\n",
      "Epoch: [10][0/1]\tTime  0.010 ( 0.010)\tData  0.002 ( 0.002)\tLoss 3.9060e-01 (3.9060e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([100.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.010 ( 0.010)\tLoss 3.5802e-01 (3.5802e-01)\tAcc@1 100.00 (100.00)\n",
      " * Acc@1 100.000\n",
      "❌ Epoch 11: No improvement. Patience counter: 6/50\n",
      "Epoch: [11][0/1]\tTime  0.011 ( 0.011)\tData  0.000 ( 0.000)\tLoss 3.6515e-01 (3.6515e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([100.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.009 ( 0.009)\tLoss 3.3831e-01 (3.3831e-01)\tAcc@1 100.00 (100.00)\n",
      " * Acc@1 100.000\n",
      "❌ Epoch 12: No improvement. Patience counter: 7/50\n",
      "Epoch: [12][0/1]\tTime  0.017 ( 0.017)\tData  0.007 ( 0.007)\tLoss 3.4378e-01 (3.4378e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([100.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.013 ( 0.013)\tLoss 3.2244e-01 (3.2244e-01)\tAcc@1 100.00 (100.00)\n",
      " * Acc@1 100.000\n",
      "❌ Epoch 13: No improvement. Patience counter: 8/50\n",
      "Epoch: [13][0/1]\tTime  0.008 ( 0.008)\tData  0.002 ( 0.002)\tLoss 3.2660e-01 (3.2660e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([100.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.019 ( 0.019)\tLoss 3.0988e-01 (3.0988e-01)\tAcc@1 100.00 (100.00)\n",
      " * Acc@1 100.000\n",
      "❌ Epoch 14: No improvement. Patience counter: 9/50\n",
      "Epoch: [14][0/1]\tTime  0.015 ( 0.015)\tData  0.003 ( 0.003)\tLoss 3.1316e-01 (3.1316e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([100.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.014 ( 0.014)\tLoss 3.0031e-01 (3.0031e-01)\tAcc@1 100.00 (100.00)\n",
      " * Acc@1 100.000\n",
      "❌ Epoch 15: No improvement. Patience counter: 10/50\n",
      "Epoch: [15][0/1]\tTime  0.012 ( 0.012)\tData  0.003 ( 0.003)\tLoss 3.0304e-01 (3.0304e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([100.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.014 ( 0.014)\tLoss 2.9343e-01 (2.9343e-01)\tAcc@1 100.00 (100.00)\n",
      " * Acc@1 100.000\n",
      "❌ Epoch 16: No improvement. Patience counter: 11/50\n",
      "Epoch: [16][0/1]\tTime  0.012 ( 0.012)\tData  0.002 ( 0.002)\tLoss 2.9584e-01 (2.9584e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([100.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.013 ( 0.013)\tLoss 2.8888e-01 (2.8888e-01)\tAcc@1 100.00 (100.00)\n",
      " * Acc@1 100.000\n",
      "❌ Epoch 17: No improvement. Patience counter: 12/50\n",
      "Epoch: [17][0/1]\tTime  0.011 ( 0.011)\tData  0.003 ( 0.003)\tLoss 2.9112e-01 (2.9112e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([100.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.015 ( 0.015)\tLoss 2.8625e-01 (2.8625e-01)\tAcc@1 100.00 (100.00)\n",
      " * Acc@1 100.000\n",
      "❌ Epoch 18: No improvement. Patience counter: 13/50\n",
      "Epoch: [18][0/1]\tTime  0.013 ( 0.013)\tData  0.003 ( 0.003)\tLoss 2.8841e-01 (2.8841e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([100.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.017 ( 0.017)\tLoss 2.8505e-01 (2.8505e-01)\tAcc@1 100.00 (100.00)\n",
      " * Acc@1 100.000\n",
      "❌ Epoch 19: No improvement. Patience counter: 14/50\n",
      "Epoch: [19][0/1]\tTime  0.017 ( 0.017)\tData  0.002 ( 0.002)\tLoss 2.8719e-01 (2.8719e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([100.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.020 ( 0.020)\tLoss 2.8475e-01 (2.8475e-01)\tAcc@1 100.00 (100.00)\n",
      " * Acc@1 100.000\n",
      "❌ Epoch 20: No improvement. Patience counter: 15/50\n"
     ]
    }
   ],
   "source": [
    "best_acc1 = 0.0\n",
    "patience = 50  # Adjust as needed\n",
    "patience_counter = 0\n",
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "start_epoch = 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_finetune.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    finetune_adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "\n",
    "    # Train for one epoch\n",
    "    finetune_train(finetune_train_loader, model_finetune, criterion, optimizer, epoch)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    acc1 = finetune_validate(finetune_val_loader, model_finetune, criterion)\n",
    "\n",
    "    # Check if current accuracy is the best\n",
    "    is_best = acc1 > best_acc1\n",
    "\n",
    "    if is_best:\n",
    "        best_acc1 = acc1\n",
    "        patience_counter = 0\n",
    "\n",
    "        # Save best model only\n",
    "        finetune_save_checkpoint(timestamp, epoch, {\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': 'vgg16',\n",
    "            'state_dict': model_finetune.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best=True)\n",
    "\n",
    "        print(f\"✅ Epoch {epoch+1}: New best Acc@1: {best_acc1:.2f}. Model saved.\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"❌ Epoch {epoch+1}: No improvement. Patience counter: {patience_counter}/{patience}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"⏹️ Early stopping triggered at epoch {epoch+1}. Best Acc@1: {best_acc1:.2f}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "828ce5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250725_225802\n"
     ]
    }
   ],
   "source": [
    "train_time = time.time()\n",
    "\n",
    "\n",
    "print(timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c42bbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9859cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWithDataset(n): \n",
    "    hsi_test = dataset[n]\n",
    "\n",
    "    test_img = hsi_test.img\n",
    "    test_gt = hsi_test.gt\n",
    "\n",
    "    patch_size = 9\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    height = test_img.shape[0]\n",
    "    width = test_img.shape[1]\n",
    "\n",
    "    matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "    print(f\"img shape: {test_img.shape}\")\n",
    "    print(f\"img shape after padding {matrix.shape}\")\n",
    "    print(f\"number of pixel {width * height}\")\n",
    "\n",
    "    print(f\"ground truth shape: {test_gt.shape}\")\n",
    "\n",
    "    indices0 = np.argwhere(test_gt == 0)\n",
    "    indices1 = np.argwhere(test_gt == 1)\n",
    "\n",
    "    print(f\"indices = 0 shape: {indices0.shape}\")\n",
    "    print(f\"indices = 1 shape: {indices1.shape}\")\n",
    "\n",
    "    num_samples = 5000\n",
    "\n",
    "    random_indices0 = indices0[np.random.choice(len(indices0), num_samples, replace=False)]\n",
    "    random_indices1 = indices1[np.random.choice(len(indices1), num_samples, replace=False)]\n",
    "\n",
    "    test_indices = np.vstack((random_indices0, random_indices1))\n",
    "\n",
    "    print(test_indices.shape)\n",
    "\n",
    "    return test_indices, test_gt, matrix, random_indices0.shape, random_indices1.shape\n",
    "\n",
    "\n",
    "def testWithWholeDataset(n): \n",
    "    hsi_test = dataset[n]\n",
    "\n",
    "    test_img = hsi_test.img\n",
    "    gt= hsi_test.gt\n",
    "\n",
    "    patch_size = 9\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    height = test_img.shape[0]\n",
    "    width = test_img.shape[1]\n",
    "\n",
    "    matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "    print(f\"img shape: {test_img.shape}\")\n",
    "    print(f\"img shape after padding {matrix.shape}\")\n",
    "    print(f\"number of pixel {width * height}\")\n",
    "\n",
    "    print(f\"ground truth shape: {gt.shape}\")\n",
    "\n",
    "    indices0 = np.argwhere(gt == 0)\n",
    "    indices1 = np.argwhere(gt == 1)\n",
    "\n",
    "    print(f\"indices = 0 shape: {indices0.shape}\")\n",
    "    print(f\"indices = 1 shape: {indices1.shape}\")\n",
    "\n",
    "    return matrix, gt, indices0.shape, indices1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a0cfff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(model, batch_input, device):\n",
    "    model.eval()\n",
    "    batch_input = batch_input.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_input)\n",
    "        # Apply softmax to get class probabilities\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "        # Get predicted class (0 or 1)\n",
    "        predicted_classes = torch.argmax(probabilities, dim=1).cpu().numpy()\n",
    "\n",
    "        # Get probability of class 1 (positive class) — required for ROC\n",
    "        positive_class_probs = probabilities[:, 1].cpu().numpy()\n",
    "\n",
    "    \n",
    "\n",
    "    return predicted_classes, positive_class_probs\n",
    "\n",
    "\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, matrix, gt, half_patch, expected_shape):\n",
    "        self.matrix = matrix\n",
    "        self.gt = gt\n",
    "        self.half_patch = half_patch\n",
    "        self.expected_shape = expected_shape\n",
    "        self.size_x, self.size_y = matrix.shape[0], matrix.shape[1]\n",
    "        self.valid_coords = [\n",
    "            (x, y)\n",
    "            for x in range(half_patch, self.size_x - half_patch)\n",
    "            for y in range(half_patch, self.size_y - half_patch)\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.valid_coords[idx]\n",
    "        true_label = self.gt[x - self.half_patch, y - self.half_patch]\n",
    "\n",
    "        selected_rows = self.matrix[x- self.half_patch:x + 2 * self.half_patch + 1 - self.half_patch, :]\n",
    "        testing_patch = selected_rows[:, y - self.half_patch:y + 2 * self.half_patch + 1 - self.half_patch]\n",
    "\n",
    "        # Verify patch size\n",
    "        if testing_patch.shape != self.expected_shape:\n",
    "            raise ValueError(f\"Patch at ({x},{y}) has wrong shape {testing_patch.shape}\")\n",
    "\n",
    "        patch_tensor = torch.tensor(testing_patch, dtype=torch.float32)\n",
    "        patch_tensor = patch_tensor.permute(2, 0, 1)  # (C, H, W)\n",
    "\n",
    "        return patch_tensor, true_label, x, y  # Also return (x, y) for positioning later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "575b807c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\finetune\\20250725_225802_model.pth.tar\n",
      "Creating model 20250725_225802_model.pth.tar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and moved to device\n",
      "saved_model for testing Parameter 15455618\n",
      "VGG16_HSI(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_16496\\3084895309.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 64  # You can change this depending on your GPU capacity\n",
    "\n",
    "model_path = rf\"models\\finetune\\{timestamp}_model.pth.tar\"\n",
    "model_name = model_path.split('\\\\')[-1]\n",
    "print(model_path)\n",
    "\n",
    "print(f\"Creating model {model_name}...\")\n",
    "saved_model = VGG16_HSI().to(device)\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "saved_model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Model loaded and moved to device\")\n",
    "\n",
    "saved_model_parameters = sum(p.numel() for p in saved_model.parameters())\n",
    "print(f\"saved_model for testing Parameter {saved_model_parameters}\")\n",
    "print(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13871a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScoreTest(prediction, y_probs, groundtruth):\n",
    "    groundtruths = groundtruth\n",
    "    groundtruth_in = []\n",
    "\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "    predictions = prediction\n",
    "    prediction_in = []\n",
    "\n",
    "    for x in predictions:\n",
    "        for y in x:\n",
    "            prediction_in.append(y)\n",
    "\n",
    "\n",
    "    y_prob_in = []\n",
    "\n",
    "    for x in y_probs:\n",
    "        for y in x:\n",
    "            y_prob_in.append(y)\n",
    "\n",
    "    print(len(groundtruth_in))\n",
    "    print(len(prediction_in))\n",
    "    print(len(y_prob_in))\n",
    "\n",
    "    y_test = groundtruth_in\n",
    "    y_pred = prediction_in\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in zip(y_test, y_pred):\n",
    "        total += 1\n",
    "        if x == y:\n",
    "            correct += 1\n",
    "    \n",
    "    print(f'{correct}/{total}')\n",
    "\n",
    "    y_test_np = np.array([label.item() for label in y_test])\n",
    "    # Ensure labels are binary (0 and 1)\n",
    "    # print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "    # # Check if y_pred is probability (float) or hard prediction (int)\n",
    "    # print(\"Sample y_pred values:\", y_pred[:5])\n",
    "\n",
    "    test_df = pd.DataFrame(\n",
    "        {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Two Models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "    y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "    # Precision, Recall, F1\n",
    "    precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Overall Accuracy (OA)\n",
    "    oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Average Accuracy (AA) — mean of per-class accuracies\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    aa = per_class_acc.mean()\n",
    "\n",
    "    # Print all metrics\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"OA:        {oa:.4f}\")\n",
    "    print(f\"AA:        {aa:.4f}\")\n",
    "\n",
    "    performance = {\n",
    "        'AUC': float(roc_auc),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'F1 Score': float(f1),\n",
    "        'OA': float(oa),\n",
    "        'AA': float(aa),\n",
    "    }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a467139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(prediction, y_probs, groundtruth):\n",
    "    groundtruths = groundtruth\n",
    "    groundtruth_in = []\n",
    "\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "    predictions = prediction\n",
    "    prediction_in = []\n",
    "\n",
    "    for x in predictions:\n",
    "        for y in x:\n",
    "            prediction_in.append(y)\n",
    "\n",
    "\n",
    "    y_prob_in = []\n",
    "\n",
    "    for x in y_probs:\n",
    "        for y in x:\n",
    "            y_prob_in.append(y)\n",
    "\n",
    "    # print(len(groundtruth_in))\n",
    "    # print(len(prediction_in))\n",
    "    # print(len(y_prob_in))\n",
    "\n",
    "    y_test = groundtruth_in\n",
    "    y_pred = prediction_in\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in zip(y_test, y_pred):\n",
    "        total += 1\n",
    "        if x == y:\n",
    "            correct += 1\n",
    "    \n",
    "    print(f'{correct}/{total}')\n",
    "\n",
    "    y_test_np = np.array([label.item() for label in y_test])\n",
    "    # Ensure labels are binary (0 and 1)\n",
    "    # print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "    # # Check if y_pred is probability (float) or hard prediction (int)\n",
    "    # print(\"Sample y_pred values:\", y_pred[:5])\n",
    "\n",
    "    test_df = pd.DataFrame(\n",
    "        {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Two Models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "    y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "    # Precision, Recall, F1\n",
    "    precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Overall Accuracy (OA)\n",
    "    oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Average Accuracy (AA) — mean of per-class accuracies\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    aa = per_class_acc.mean()\n",
    "\n",
    "    # Print all metrics\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"OA:        {oa:.4f}\")\n",
    "    print(f\"AA:        {aa:.4f}\")\n",
    "\n",
    "    performance = {\n",
    "        'AUC': float(roc_auc),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'F1 Score': float(f1),\n",
    "        'OA': float(oa),\n",
    "        'AA': float(aa),\n",
    "    }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9ae6c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tes: 0\n",
      "dataset: 1\n",
      "img shape: (1243, 684, 224)\n",
      "img shape after padding (1251, 692, 224)\n",
      "number of pixel 850212\n",
      "ground truth shape: (1243, 684)\n",
      "indices = 0 shape: (820876, 2)\n",
      "indices = 1 shape: (29336, 2)\n",
      "820876\n",
      "29336\n",
      "generate data loader using seed\n",
      "torch.Size([64, 224, 9, 9])\n",
      "torch.Size([64])\n",
      "data loader size: 13285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 13285/13285 [06:54<00:00, 32.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787025/850212\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAHWCAYAAAA2Of5hAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhCRJREFUeJzt3Xd8zPcfB/DX5ZLLkkVkEUKsUHukdpEKWjVLUWIUNapWa1TNokVVa5YiZq0fqrVq71EjtlixJQQZsi65+/z++LrjJCFHLt/L5fV8PO7R+37u8/1+33eXyLufqRBCCBARERGRrKzkDoCIiIiImJQRERERmQUmZURERERmgEkZERERkRlgUkZERERkBpiUEREREZkBJmVEREREZoBJGREREZEZYFJGREREZAaYlBERveTZs2f44osv4OXlBYVCgYEDB8odUp6hUCgwduxYo8+7efMmFAoFQkNDsz0mopzEpIwoB4WGhkKhUOgf1tbWKFSoELp27Yp79+5leI4QAsuWLUO9evXg6uoKBwcHlC9fHuPHj0dCQkKm99qwYQOaNm0Kd3d3qFQq+Pj4oF27dti9e3eWYk1OTsYvv/yCwMBAuLi4wM7ODqVKlUL//v1x5cqVt3r/ucGkSZMQGhqKPn36YNmyZejcubNJ7jN27FiDn4XMHh988IFJ7p+Zl39GDx48mO51IQR8fX2hUCjw8ccf52hsRJbOWu4AiPKi8ePHo1ixYkhOTsbRo0cRGhqKgwcP4vz587Czs9PX02g06NixI9asWYO6deti7NixcHBwwIEDBzBu3DisXbsWO3fuhKenp/4cIQS6d++O0NBQVK5cGYMHD4aXlxcePHiADRs2oFGjRjh06BBq1aqVaXzR0dFo0qQJTp48iY8//hgdO3ZEvnz5EB4ejlWrVmH+/PlQq9Um/Yzksnv3brz//vsYM2aMSe/TunVrlChRQn/87Nkz9OnTB61atULr1q315S9/tznJzs4OK1euRJ06dQzK9+3bh7t378LW1laWuIgsmiCiHLN48WIBQPz3338G5cOGDRMAxOrVqw3KJ02aJACIoUOHprvWpk2bhJWVlWjSpIlB+dSpUwUAMXDgQKHVatOdt3TpUnHs2LHXxvnRRx8JKysrsW7dunSvJScniyFDhrz2/KxKTU0VKSkp2XKt7FKsWDHx0UcfZdv1svoeHz16JACIMWPGZNu934buZ7R169bC3d1dpKamGrzes2dPUbVqVVG0aNFs/ZyEEG/9/iMiIgQAsXjx4myNhyinsfuSyAzUrVsXAHD9+nV9WVJSEqZOnYpSpUph8uTJ6c5p3rw5QkJCsG3bNhw9elR/zuTJk1GmTBlMmzYNCoUi3XmdO3dGjRo1Mo3l2LFj2Lx5M3r06IE2bdqke93W1hbTpk3TH3/wwQcZdrF17doVfn5++mPduJ9p06ZhxowZ8Pf3h62tLU6fPg1ra2uMGzcu3TXCw8OhUCgwa9YsfVlMTAwGDhwIX19f2NraokSJEvjpp5+g1WoNzl21ahWqVq0KJycnODs7o3z58vj1118zfd979+6FQqFAREQENm/erO/Cu3nzJgDg4cOH6NGjBzw9PWFnZ4eKFStiyZIlBtfI7D1evHgx0/tm5uzZs1AoFNi0aZO+7OTJk1AoFKhSpYpB3aZNmyIwMNCgbM6cOShXrhxsbW3h4+ODfv36ISYmJsv379ChAx4/fowdO3boy9RqNdatW4eOHTtmeE5CQgKGDBmi/25Kly6NadOmQQhhUC8lJQWDBg1CwYIF4eTkhE8++QR3797N8Jr37t1D9+7d4enpCVtbW5QrVw6LFi16Y/yRkZHo1q0bChcuDFtbW3h7e6NFixb675PIHLH7ksgM6P5QuLm56csOHjyIp0+f4uuvv4a1dca/ql26dMHixYvxzz//4P3338fBgwfx5MkTDBw4EEql8q1i0SUBphpLtXjxYiQnJ6NXr176P5b169fHmjVr0nUZrl69GkqlEp9++ikAIDExEfXr18e9e/fQu3dvFClSBIcPH8aIESPw4MEDzJgxAwCwY8cOdOjQAY0aNcJPP/0EALh06RIOHTqEr7/+OsO4AgICsGzZMgwaNAiFCxfGkCFDAAAFCxZEUlISPvjgA1y7dg39+/dHsWLFsHbtWnTt2hUxMTHprvnqe8yfP7/Rn9N7770HV1dX7N+/H5988gkA4MCBA7CyssKZM2cQFxcHZ2dnaLVaHD58GL169dKfO3bsWIwbNw5BQUHo06cPwsPDMXfuXPz33384dOgQbGxs3nh/Pz8/1KxZE3/++SeaNm0KANi6dStiY2Px2Wef4bfffjOoL4TAJ598gj179qBHjx6oVKkStm/fjm+++Qb37t3DL7/8oq/7xRdfYPny5ejYsSNq1aqF3bt346OPPkoXQ1RUFN5//30oFAr0798fBQsWxNatW9GjRw/ExcW9dhJGmzZtcOHCBXz11Vfw8/PDw4cPsWPHDty+fdvgfxaIzIrcTXVEeYmua2jnzp3i0aNH4s6dO2LdunWiYMGCwtbWVty5c0dfd8aMGQKA2LBhQ6bXe/Lkib6rSQghfv311zee8yatWrUSAMTTp0+zVL9+/fqifv366cpDQkJE0aJF9ce6LiZnZ2fx8OFDg7q///67ACDOnTtnUF62bFnRsGFD/fGECROEo6OjuHLlikG94cOHC6VSKW7fvi2EEOLrr78Wzs7OIi0tLUvv4WUZdcvpvovly5fry9RqtahZs6bIly+fiIuLe+N7fJOMui8/+ugjUaNGDf1x69atRevWrYVSqRRbt24VQghx6tQpAUD89ddfQgghHj58KFQqlWjcuLHQaDT6c2fNmiUAiEWLFr02jpe72GfNmiWcnJxEYmKiEEKITz/9VDRo0CDDz2njxo0CgPjhhx8Mrte2bVuhUCjEtWvXhBBChIWFCQCib9++BvU6duyY7v336NFDeHt7i+joaIO6n332mXBxcdHH9Wr35dOnTwUAMXXq1Ne+VyJzw+5LIhkEBQWhYMGC8PX1Rdu2beHo6IhNmzahcOHC+jrx8fEAACcnp0yvo3stLi7O4L+vO+dNsuMar9OmTRsULFjQoKx169awtrbG6tWr9WXnz5/HxYsX0b59e33Z2rVrUbduXbi5uSE6Olr/CAoKgkajwf79+wEArq6uSEhIMOh6exdbtmyBl5cXOnTooC+zsbHBgAED8OzZM+zbt++N7/Ft1K1bF6dOndLPsj148CCaNWuGSpUq4cCBAwCk1jOFQqEfkL9z506o1WoMHDgQVlYv/onv2bMnnJ2dsXnz5izfv127dkhKSsI///yD+Ph4/PPPP5l2XW7ZsgVKpRIDBgwwKB8yZAiEENi6dau+HoB09V5t9RJC4H//+x+aN28OIYTB9x0cHIzY2FicOnUqw1js7e2hUqmwd+9ePH36NMvvl0hu7L4kksHs2bNRqlQpxMbGYtGiRdi/f3+62Wy6pEiXnGXk1cTN2dn5jee8ycvXcHV1fevrZKZYsWLpytzd3dGoUSOsWbMGEyZMACB1XVpbWxvMRLx69SrOnj2bacLz8OFDAEDfvn2xZs0aNG3aFIUKFULjxo3Rrl07NGnS5K1ivnXrFkqWLGmQ5ABSl6fu9Te9x7dRt25dpKWl4ciRI/D19cXDhw9Rt25dXLhwwSApK1u2rL6LVBdL6dKlDa6lUqlQvHjxdLG+TsGCBREUFISVK1ciMTERGo0Gbdu2zbDurVu34OPjky6Zf/UzunXrFqysrODv729Q79V4Hz16hJiYGMyfPx/z58/P8J667/tVtra2+OmnnzBkyBB4enri/fffx8cff4wuXbrAy8vrzW+cSCZMyohkUKNGDVSrVg0A0LJlS9SpUwcdO3ZEeHg48uXLB+DFH7OzZ8+iZcuWGV7n7NmzAICyZcsCAMqUKQMAOHfuXKbnvMnL19BNQHgdhUKRbiA3IC3nkRF7e/sMyz/77DN069YNYWFhqFSpEtasWYNGjRrB3d1dX0er1eLDDz/Et99+m+E1SpUqBQDw8PBAWFgYtm/fjq1bt2Lr1q1YvHgxunTpkm5wvilk9h6NVa1aNdjZ2WH//v0oUqQIPDw8UKpUKdStWxdz5sxBSkoKDhw4gFatWmXL/TLSsWNH9OzZE5GRkWjatKlJEvWM6CZufP755wgJCcmwToUKFTI9f+DAgWjevDk2btyI7du34/vvv8fkyZOxe/duVK5c2SQxE70rdl8SyUypVGLy5Mm4f/++wSzDOnXqwNXVFStXrsw0wVm6dCkA6BfxrFOnDtzc3PDnn39mes6bNG/eHACwfPnyLNV3c3PLcFafMS0ygJScqlQqrF69GmFhYbhy5Qo+++wzgzr+/v549uwZgoKCMnwUKVJEX1elUqF58+aYM2cOrl+/jt69e2Pp0qW4du2aUXEBQNGiRXH16tV0MzwvX76sf90UVCoVatSogQMHDuDAgQP6JLlu3bpISUnBihUrEBUVhXr16hnECkgzV1+mVqsRERFhdKytWrWClZUVjh49mmnXpe6+9+/fT9dK++pnVLRoUWi1WoOZxhnFq5uZqdFoMv2+PTw8Xhu7v78/hgwZgn///Rfnz5+HWq3Gzz//nOX3TpTTmJQRmYEPPvgANWrUwIwZM5CcnAwAcHBwwNChQxEeHo7vvvsu3TmbN29GaGgogoOD8f777+vPGTZsGC5duoRhw4Zl2IK1fPlyHD9+PNNYatasiSZNmuCPP/7Axo0b072uVqsxdOhQ/bG/vz8uX76MR48e6cvOnDmDQ4cOZfn9A9I4sODgYKxZswarVq2CSqVK19rXrl07HDlyBNu3b093fkxMDNLS0gAAjx8/NnjNyspK36qSkpJiVFwA0KxZM0RGRhqMeUtLS8PMmTORL18+1K9f3+hrZlXdunVx7Ngx7NmzR5+Uubu7IyAgQD+z9OUWzaCgIKhUKvz2228G3//ChQsRGxub4SzH18mXLx/mzp2LsWPH6hP2jDRr1gwajcbgfywA4JdffoFCodDP4NT999XZm7qZszpKpRJt2rTB//73P5w/fz7d/V7+eXtVYmKi/vdIx9/fH05OTm/1/RPlFHZfEpmJb775Bp9++ilCQ0Px5ZdfAgCGDx+O06dP46effsKRI0fQpk0b2Nvb4+DBg1i+fDkCAgLSdcd98803uHDhAn7++Wfs2bMHbdu2hZeXFyIjI7Fx40YcP34chw8ffm0sS5cuRePGjdG6dWs0b94cjRo1gqOjI65evYpVq1bhwYMH+rXKunfvjunTpyM4OBg9evTAw4cPMW/ePJQrV04/aSCr2rdvj88//xxz5sxBcHBwuq6yb775Bps2bcLHH3+Mrl27omrVqkhISMC5c+ewbt063Lx5E+7u7vjiiy/w5MkTNGzYEIULF8atW7cwc+ZMVKpUSd8tbIxevXrh999/R9euXXHy5En4+flh3bp1OHToEGbMmGGySRGAlHBNnDgRd+7cMUi+6tWrh99//x1+fn4GE0QKFiyIESNGYNy4cWjSpAk++eQThIeHY86cOahevTo+//xzo2PIrPvwZc2bN0eDBg3w3Xff4ebNm6hYsSL+/fdf/PXXXxg4cKB+DFmlSpXQoUMHzJkzB7GxsahVqxZ27dqVYQvmjz/+iD179iAwMBA9e/ZE2bJl8eTJE5w6dQo7d+7EkydPMozlypUraNSoEdq1a4eyZcvC2toaGzZsQFRUVLrWVyKzIufUT6K8JrMV/YUQQqPRCH9/f+Hv72+wlINGoxGLFy8WtWvXFs7OzsLOzk6UK1dOjBs3Tjx79izTe61bt040btxY5M+fX1hbWwtvb2/Rvn17sXfv3izFmpiYKKZNmyaqV68u8uXLJ1QqlShZsqT46quv9Msb6CxfvlwUL15cqFQqUalSJbF9+/ZMl8R43TIFcXFxwt7ePt3yEy+Lj48XI0aMECVKlBAqlUq4u7uLWrVqiWnTpgm1Wm3w3j08PIRKpRJFihQRvXv3Fg8ePHjj+85spfqoqCjRrVs34e7uLlQqlShfvny6FeSz8h4zk9mK/nFxcUKpVAonJyeDn4vly5cLAKJz584ZXm/WrFmiTJkywsbGRnh6eoo+ffpkaZmT1/2Mviyjzyk+Pl4MGjRI+Pj4CBsbG1GyZEkxderUdDtLJCUliQEDBogCBQoIR0dH0bx5c3Hnzp0M339UVJTo16+f8PX1FTY2NsLLy0s0atRIzJ8/X1/n1SUxoqOjRb9+/USZMmWEo6OjcHFxEYGBgWLNmjVvfP9EclIIkUH/BhERERHlKI4pIyIiIjIDTMqIiIiIzACTMiIiIiIzwKSMiIiIyAwwKSMiIiIyA0zKiIiIiMxAnls8VqvV4v79+3BycoJCoZA7HCIiIrJwQgjEx8fDx8cHVlaZt4fluaTs/v378PX1lTsMIiIiymPu3LljsAPHq/JcUqbbDuXOnTtwdnaWORoiIiKydHFxcfD19X3jlmx5LinTdVk6OzszKSMiIqIc86ZhUxzoT0RERGQGmJQRERERmQEmZURERERmgEkZERERkRlgUkZERERkBpiUEREREZkBJmVEREREZoBJGREREZEZYFJGREREZAaYlBERERGZAVmTsv3796N58+bw8fGBQqHAxo0b33jO3r17UaVKFdja2qJEiRIIDQ01eZxEREREpiZrUpaQkICKFSti9uzZWaofERGBjz76CA0aNEBYWBgGDhyIL774Atu3bzdxpERERESmJeuG5E2bNkXTpk2zXH/evHkoVqwYfv75ZwBAQEAADh48iF9++QXBwcGmCpOIiIjI5GRNyox15MgRBAUFGZQFBwdj4MCBmZ6TkpKClJQU/XFcXJypwiPKNYQQ0ApAoxXQaAW0QvcwfE33XPe6EEBKmlZ/DQFAPH9d91/gxbF4+XkG9VM1WiSnamBro3xeJqDVIl0sL99f99qDmCS4O9nqj/HKOUIXo+5+r8YioL+2RisgYBgzXrqGdF28qPPSexF48Trw4n43HiXA09kOKmurdJ+XVPNFma5Ad33A8H4v6uueQR+reF5BvFSGl8ufF0Q/S0GiWgNvF7us/YxkqZYxFaX3k6V6Rl0zi/WMuGjWr5nlSxrxecodpwm+oyzWNeKSRn2fr2OTmoJUG1sAwPzO1VCkgEO2XPdt5aqkLDIyEp6engZlnp6eiIuLQ1JSEuzt7dOdM3nyZIwbNy6nQqQ8SqsVSErVICElDXHJaUjVaJ8/BFI1WiSlapCYogEAJKdqkJSqQapGC41WIE0rkKbRIk0rcPXhMxRytYc6TTpfnabFg9hk2KuU+gRKOkcLrRY4ey8GfgUcoRUC6jQtbj5OhEppBQdbJbRaYZh06J4LYdQ/qGRZbj9JlDsEIrNQ+d5lzPhnGqbW64J/AupBrdHIHVLuSsrexogRIzB48GD9cVxcHHx9fWWMiMxVSpoG954m4WliKu4+TUSiWoMHMUm4G5MEB5USiSkaxCWnIVGdhmcpaYhNSkVCivQ8OVUrW9yXI+MNjtUaLdSJ2ROPlQKwUihgpVBAoX8OJKg1cLG3gdJKAQUAxfPXFYBBXQCwsgIUkM57uZ7i+bUiY5Nho7SCj6u9vs7L94Ui4zgAIDwyHhUKu+jLFPrzFc9jefmeL66reKncSgFYW0mtWfrrPH/+8rmvvj/F8xOsXn3dSqG/VlRsMrxc7GGjVOg/U8Xz6+vq6D6Ll4+hO9aXKV6p//x8SAWKV66tf/2l2AAgSa2BlZUCjqqs/dOvULy5ji7OrMrqNY25qmnizFptU7z3rH9GL342slDRiGtmsZ4RgWb9mlm+ZJbfe7prpqXBd+4M+P45DQqNBj9e3YIOU4fAxzV9w05Oy1VJmZeXF6KiogzKoqKi4OzsnGErGQDY2trC1tY2J8IjM5WQkoaouGTcepKIsNsxsLZS4MzdWNgoFXiaqMbxiCfwcLJDZFxyttzPUaVEgloDDydb2NkoYaNUwEZphehnajiolChawAH2NkqorK1gbaWAtVL3XwWUCgVuP0lEWR9n2CitYKO0gtJKgTSNFgWdbKG0kuoqrRSwtlLAykqBRHUaPJ3sYGNtBZXSCgJAPlslFArperokQmklPbeykhIL5fNylbXVK0nXiwSKiMiiREQAIZ8Dhw9Lxx07It+cOajt4iJvXM/lqqSsZs2a2LJli0HZjh07ULNmTZkiInORkJKGU7ef4trDZ7j1OBE3Hyfg7tMkXHv4LEvn6xIyOxsrJKdqUSS/A54kqFG5iCsUCgWc7KxR1tsZrg42yGdrjXy21nCxt4Hj8+f2KiUcVErY2yiZzBARmRshgOXLgX79gPh4wNkZmDMH6NRJ7sgMyJqUPXv2DNeuXdMfR0REICwsDPnz50eRIkUwYsQI3Lt3D0uXLgUAfPnll5g1axa+/fZbdO/eHbt378aaNWuwefNmud4CyeBJghphd57ixqME/HfzCW49TsT1R8+Qqnn9QKkSHvngV8ABD2KTEVisAFI1WtQolh8OKiVsrZUo5ZUPBfPZMqkiIrI0Z84AXbpIz+vUAZYtA/z8ZA0pI7ImZSdOnECDBg30x7qxXyEhIQgNDcWDBw9w+/Zt/evFihXD5s2bMWjQIPz6668oXLgw/vjjDy6HYcFiE1Nx8UEcTt1+iosP4vBfxBM8jE/JsK5vfnsEeDmjaAEH+OZ3gF8BR+R3VME3vwNc7G1yOHIiIjIblSoBQ4YAbm7A8OGAUil3RBlSiOyaV5pLxMXFwcXFBbGxsXB2dpY7HHqJRisQHhmPHRejcCP6GQ5de4zoZxknYIVc7eGeT4WSnk6oUNgFDUp7wDe/vFOZiYjITKjVwMSJQPfuQNGickeT5dwjV40pI8sTn5yKrecisfX8Axy+/li/BtarGpf1RKUirqhQyBUVfV3gZMeWLyIiykB4uDRW7ORJYM8eYO9eaRp4LsCkjHJcojoNe8MfYd3Ju9h35RE02heNtY4qJSr6usLORonO7xdFRV9X5HdUyRgtERHlCkIAf/wBDBwIJCZKXZVff51rEjKASRnlEK1W4PD1x9h+IRJ/n72PmMRU/WveLnb4tGphNHnPG6W9nKC04kB7IiIyQnQ08MUXwF9/SccNGwJLlgCFC8sbl5GYlJFJqdO02H4hEnP3XsfFBy+2uPJwskXDMh74tJovqjxfdoKIiMhoFy4AQUFAZCRgYwNMngwMGpSrWsh0mJSRSdx49AxrT97FymO3EZsktYopFECrSoXQtLw3GpXx0K98TkRE9Nb8/YGCBaXuypUrpZmWuRSTMspWEdEJmLn7KjaevgfdULECjiq0rVoYPesVh3s+7q5ARETv6MoVoHhxwNoasLMD/v5bSswccvcsfCZl9M6EEDh07TEWHryBPeGP9OWlPPPhi7rF0aZKYY4TIyKidycEMHMm8O23wKhR0gMwi2UvsgOTMnonB69G4/u/ziMiOkFfVrN4AQxoVBI1/QvIGBkREVmUyEigWzdg2zbp+L//AK02V44dywyTMnord54k4vu/zmPv85YxlbUVmlfwQZ8P/FHCI5/M0RERkUX5+29pIdjoaKm7cupUaR9LC5skxqSMjKLVCiw8GIHpO64gKVUDAGhRyQfff1yW48WIiCh7JSZK2yPNmycdV6ggDeYvV07euEyESRllWUJKGsZuuoC1J+8CAKoWdcOkVuVR2stJ5siIiMgi3boFhIZKz4cMkbZOsrXcBgAmZZQlEdEJCFl0HLefJMJKAYxoGoAv6hbj+mJERGQ6AQFSK1mhQtJaZBbOckbHkclcuB+LlrMP4faTRDiolFjUtTp61ivOhIyIiLLXnTtA48bAkSMvykJC8kRCBrCljN7g0LVofLnsJOJT0lDa0wnLetSAh7Od3GEREZGlWbsW6N0bePpUmml55ozFDeR/E7aUUab2XXmEkEXHEZ+Shoq+rlj+RSATMiIiyl7x8dJSF+3aSQlZ9erA//6X5xIygEkZZWLnxSj0XHoCaVqBBqULYm3vmijoZLmDK4mISAZHj0rbIoWGSknYd98Bhw4BJUvKHZks2H1J6aw/dReD15wBAFQr6oYFXarBWsn8nYiIstHJk0CdOoBGAxQpAixfDtStK3dUsmJSRgb2hj/E8PXnAABNynlhZsfKTMiIiCj7VakCNG0KODkBc+YArq5yRyQ7JmWk9/hZCgb8eRrqNC0KOtliWruKsGFCRkRE2UEIYM0aoEkTwMVF6q5cu1ZaoZ8AcEwZPZeQkobey04iLjkNNkoF9n3zAfLZMmcnIqJsEBMDdOwIfPYZ8NVXL8qZkBngX12CEAJdFh3HyVtPkc/WGmu/rAkHFX80iIgoG+zbB3TuLK1BplQCpUpJrWZ5cHblm/AvL2Huvus4eespACC0W3UEeDvLHBEREeV6ajUwdizw449SEubvD6xYAQQGyh2Z2WJSlscdj3iCX3deBQD0rlcc1fzyyxwRERHlejdvAp9+Cpw4IR137w7MmCEN6qdMMSnLw+48ScSXy08iJU2LakXdMKxJGblDIiIiS+DoCNy9C7i5AfPnA23byh1RrsCkLI9K1WjRPfQ/PElQwze/PRZ3qw4rK/bvExHRW4qPf9ESVrAgsGEDULiw9KAs4ezLPGrmrqu4+vAZHFVKrPzifTjZ2cgdEhER5Vb//guULg2sXPmi7P33mZAZiUlZHrTn8kPM3HMNADCsaRn45neQOSIiIsqVkpOBwYOB4GDgwQNg5kxpUD+9FSZleUxsYiq6hf4HIYCPK3ij8/tF5Q6JiIhyowsXpJmUv/wiHfftC+zaxaUu3gGTsjxm4paL+ueTW5eHgr88RERkDCGkFrGqVYGzZ6XxY3//DcyeDTiw5+VdcKB/HrLn8kOsOXEXADChRTmOIyMiIuOdOAEMGCA9b9oUWLwY8PSUNyYLwaQsj0hUp+GbdWcAAO2qFUbnmn7yBkRERLlT9erAiBGAjw/Qrx+7K7MRuy/ziKnbwxH9TA0AGNksQOZoiIgo10hMBAYNAiIiXpRNmgT078+ELJuxpSwPOH8vFosP3QQA/NSmPFwdVPIGREREucPp09JG4pcvS92W+/czETMhtpTlASPWnwMA+Bd0RPvqRWSOhoiIzJ5WC0ydKs2uvHwZ8PYGxoxhQmZibCmzcJvPPsC5e7EAgMmtK8gcDRERmb27d4GQEGD3bum4VStgwQKgQAF548oDmJRZsPjkVAxcfRoA8GnVwqhRjJuNExHRa4SFAQ0bAk+fSstb/PabtJk4W8hyBJMyCzZ562WkaqSVlce1KCdzNEREZPYCAoAiRYASJYAVK4CSJeWOKE9hUmahzt+LxcpjtwEAC7pUg4OKXzUREWUgLAx47z3A2hqwtQW2bJEWhLXhWpY5jQP9LdSEf6SV+yv6uuLDslzUj4iIXpGWBowfD1SrBkyc+KLcx4cJmUzYfGKBzt2NxbGIJwCAbxqXljkaIiIyOxERwOefA4cPS8fXr0vbJ3HsmKzYUmaBft11BQBQwiMf6pR0lzkaIiIyG0IAy5YBFStKCZmzM7B8ObB0KRMyM8CWMgtzJSoeOy89BACM+ogr9xMR0XMxMUCfPsCqVdJx7dpSQubnJ2dU9BK2lFmYiZsvAQDqlnTHB6U9ZI6GiIjMxoMHwMaNgFIJTJgA7N3LhMzMsKXMgtyLScK+K48AACHccJyIiF4eJxYQACxaBBQvLq3UT2aHLWUW5M/nS2AAQKMAtpIREeVp4eFAzZovBvMDQIcOTMjMGJMyC6HVCvx15h4A4Mv6/lBwwCYRUd4khLQtUpUqwLFjwIABUhmZPSZlFmL35Ye48yQJ+WytMaBRCbnDISIiOURHA61bA716AYmJ0pZJGzdyZmUuwaTMQkz7NxwA0KpyIa7eT0SUF/37L1ChgpSE2dgAU6cCO3YAhQvLHRllEf96W4BrD5/hcmQ8AKBzzaIyR0NERDnuyBEgOFh6HhAg7VtZubK8MZHRmJRZgKVHbgIAyng5oZSnk7zBEBFRznv/faBFC6BQIamFzMFB7ojoLTApy+W0WoGdF6MAsJWMiCjPEAL44w+gXTvAxUUaM7ZunbSpOOVaHFOWy227EIn7scnIZ2uNNlU4boCIyOJFRgLNmkmD+fv1e1HOhCzXY1KWy+2+LG2p1Ky8F+xslDJHQ0REJvXPP9Jg/m3bAFtbqduSy11YDKbVuVhyqgbrTt4FAASX85I5GiIiMpnERGDoUGDuXOm4QgVg5UqgXDl546JsxaQsF/v3+Viy/I4qNOA+l0RElik8HGjZErh8WToePBiYNElqKSOLwqQsF1t+9BYAILicJ6ysuDAgEZFFKlAAiI0FvL2BJUuADz+UOyIyESZluVREdAKORzwBAPSoU0zmaIiIKFs9fgzkzy/NqnR3B/7+GyhaVHpOFosD/XOp/z0fS1avVEGU8ODaZEREFmPtWqBkSWkBWJ2qVZmQ5QFMynIhIQQ2nJY2H29V2UfmaIiIKFvExwPdu0trjz19CoSGcmZlHiN7UjZ79mz4+fnBzs4OgYGBOH78+Gvrz5gxA6VLl4a9vT18fX0xaNAgJCcn51C05uHcvVjci0mCjVKBhmU85Q6HiIje1dGj0rZIixdLXZYjRwJbt3Ij8TxG1qRs9erVGDx4MMaMGYNTp06hYsWKCA4OxsOHDzOsv3LlSgwfPhxjxozBpUuXsHDhQqxevRojR47M4cjlteuS9Pk4qKzhYm8jczRERPTW0tKA8eOBOnWA69eBIkWAvXuBiROlTcUpT5E1KZs+fTp69uyJbt26oWzZspg3bx4cHBywaNGiDOsfPnwYtWvXRseOHeHn54fGjRujQ4cOb2xdsyRCCCw8GAEA6FrLT95giIjo3Zw4AYwZA2g0wGefAWfOAPXqyR0VyUS2pEytVuPkyZMICgp6EYyVFYKCgnDkyJEMz6lVqxZOnjypT8Ju3LiBLVu2oFmzZpneJyUlBXFxcQaP3OzU7Rg8S0kDAHSr7SdvMERE9G7efx8YOxZYtkxaDNbVVe6ISEayLYkRHR0NjUYDT0/DMVGenp64rFsg7xUdO3ZEdHQ06tSpAyEE0tLS8OWXX762+3Ly5MkYN25ctsYup/WnpFmXH1XwhquDSuZoiIjIKDExwJAh0pgxf3+pbMwYWUMi8yH7QH9j7N27F5MmTcKcOXNw6tQprF+/Hps3b8aECRMyPWfEiBGIjY3VP+7cuZODEWe/tc+Xwqjs6ypvIEREZJz9+4GKFYFFi4CuXTmzktKRraXM3d0dSqUSUVFRBuVRUVHw8sp4H8fvv/8enTt3xhdffAEAKF++PBISEtCrVy989913sLJKn2Pa2trC1kK2orgfkwR1mhYA0LZqYZmjISKiLElNlbooJ0+WEjF/f2DaNM6spHRkaylTqVSoWrUqdu3apS/TarXYtWsXatasmeE5iYmJ6RIvpVIJQBoAb+nWnpBayQq52rPrkogoN7hyBahVS9qrUgigWzfg9GkgMFDuyMgMybrN0uDBgxESEoJq1aqhRo0amDFjBhISEtCtWzcAQJcuXVCoUCFMnjwZANC8eXNMnz4dlStXRmBgIK5du4bvv/8ezZs31ydnluzU7acAgJZcMJaIyPwdOwY0bAgkJgJubsD8+UDbtnJHRWZM1qSsffv2ePToEUaPHo3IyEhUqlQJ27Zt0w/+v337tkHL2KhRo6BQKDBq1Cjcu3cPBQsWRPPmzTFx4kS53kKOSdNo8d9Naa/Lpu95yxwNERG9UeXKQOnSUkK2ZAlQmMNO6PUUIi/0+70kLi4OLi4uiI2NhbOzs9zhZNn5e7H4eOZBOKqUODc2GFZWHItARGR2Dh0CatR4sfDro0dAgQJABmOeKe/Iau7Bn5JcYvO5BwCAGsXyMyEjIjI3KSnSUhd16gAvrwhQsCATMsoyWbsvKev+PH4bANCgjIfMkRARkYELF4COHYGzZ6Xj2FhpUD9nV5KRmL7nArGJqYhPllbxr+XvLnM0REQEQEq8Zs4EqlWTErKCBYG//wZ+/ZUJGb0VtpTlArsuR0GjFShawAElPPLJHQ4REUVFSctbbN0qHTdtCixeDLyySw2RMdhSlgvsuvwQAFfxJyIyGzExwL59gJ2d1Fq2eTMTMnpnbCnLBSIeJQAAnO1tZI6EiCgP02gA3ZqYpUsDS5cCZcoA5crJGxdZDLaUmTl1mhYR0VJS1roK17ghIpLFqVPSvpX7978oa9OGCRllKyZlZu7cvRgkpWqQ31GFCoVc5A6HiChv0WqBqVOB99+XZlkOH86NxMlk2H1p5o5HSFsrVS3qxvXJiIhy0t27QEgIsHu3dNyqFbBgAWdWksmwpczMHYt4DACoWbyAzJEQEeUha9cCFSpICZmDA/DHH8D//ietzk9kImwpM2NCCJy/FwsAqOjLrksiohyxbx/Qrp30vHp1YMUKoGRJeWOiPIFJmRmLiktB9DM1lFYKBHjnnn06iYhytXr1gLZtpRmWY8a82MeSyMSYlJmxIzeiAQAarYCDil8VEZFJpKVJq/B37w64uUljxlav5p6VlOP4E2fGjkc8AQDULcmtlYiITOLGDaB+fWDoUKBPnxczK5mQkQz4U2fGrkQ9AwAEFssvcyRERBZGCGDZMqBSJeDwYcDZGWjenDMrSVbsEzNTqRotLtyXBvk3Le8tczRERBYkJkZqFVu1SjquXRtYvhzw85MzKiK2lJmri/fjkJyqhauDDYoVcJQ7HCIiy3DmjLTUxapV0pZJEyYAe/cyISOzwJYyM3XwmjTIP8DLmYvGEhFlF19faZV+f39pqYvAQLkjItJjUmam7sckAQC8XOxkjoSIKJe7dw/w8ZHGi+XPD2zdChQrBuTLJ3dkRAbYfWmmzt+PAwB8ULqgzJEQEeVSQkjbIpUqBSxd+qK8fHkmZGSWmJSZoVSNFlci4wEAZbloLBGR8aKjpb0qe/UCEhOBjRu5kTiZPSZlZuj2k0QkpWpgZ2MF/4L8vzkiIqP8+6/UGvbXX9Jq/NOmSftWcrkLMnMcU2aGdK1kJT2cOMifiCirkpOBESOAGTOk44AAaTB/5cqyhkWUVWwpM0O6RWNLeznJHAkRUS5y6pS0XRIA9O0LnDjBhIxyFbaUmaHzzxeNLe3JpIyIKMtq1QImTQLeew/4+GO5oyEyGlvKzND5e1JSVqmIq7yBEBGZs8hIoG1b4OrVF2XDhzMho1yLLWVm5kmCGg9ikwEApdhSRkSUsb//Brp3l2ZZRkdLq/IT5XJsKTMz5563khV3d4SLvY3M0RARmZnERGnfyk8+kZKxChWA2bPljoooWzApMzNXo6SZl2W82UpGRGTg1CmgalVg3jzpePBg4PhxoFw5eeMiyibsvjQzF56v5F/Sg0kZEZHe/v1AUBCQmgp4ewNLlgAffih3VETZikmZmdlw+h4AoEpRN5kjISIyI++/D1SsKG0ovmABUKCA3BERZTsmZWYkUZ0GhULaCSSA3ZdElNdt2wY0aiStyq9SATt2AC4uXJmfLBbHlJmRSw/iIQRQwFEFDyc7ucMhIpJHfDzQrRvQtCkwduyLcldXJmRk0dhSZkYuPpDGk71XyEXmSIiIZHL0KNCpE3DjhpSAKZVyR0SUY5iUmZGLzwf5l/NxljkSIqIclpYmrcY/fjyg0QBFigDLlwN168odGVGOYVJmRq4/5J6XRJQH3bwptY4dPiwdd+worT3m6ipnVEQ5jkmZmRBC4PojKSkr7p5P5miIiHJQaipw5gzg7AzMmSMlaER5EJMyM/EwPgWPE9RQWilQwoNJGRFZOLVamlEJACVLAqtWSRuJ+/nJGhaRnN5p9mVycnJ2xZHnXY6UVvIvmt8B9ioObCUiC7Z/P1C6tOF+lR9/zISM8jyjkzKtVosJEyagUKFCyJcvH27cuAEA+P7777Fw4cJsDzCvuPR85mUAB/kTkaVSq4GRI4EPPpDGkY0fL3dERGbF6KTshx9+QGhoKKZMmQKVrukZwHvvvYc//vgjW4PLS8Kft5QFcJA/EVmiK1eA2rWByZOlFbK7dwc2bZI7KiKzYnRStnTpUsyfPx+dOnWC8qX1YypWrIjLly9na3B5SUR0AgCgeEGOJyMiCyKEtC1S5crAiROAmxuwbh2wcCGQj//eEb3M6IH+9+7dQ4kSJdKVa7VapKamZktQedHNx1JS5lfAUeZIiIiy0a5dQK9e0vOGDaWNxAsXljcmIjNldFJWtmxZHDhwAEWLFjUoX7duHSpXrpxtgeUlTxPUiEmUElo/dweZoyEiykaNGklLXFSuDAwaBFhxdz+izBidlI0ePRohISG4d+8etFot1q9fj/DwcCxduhT//POPKWK0eLpWMk9nWziouEoJEeViycnSuLGvvwby55e2Slq2jHtWEmWB0f/L0qJFC/z999/YuXMnHB0dMXr0aFy6dAl///03PvzwQ1PEaPHO3YsFAHg6cxNyIsrFLlwAAgOlWZVffvminAkZUZa8VbNM3bp1sWPHjuyOJc+6+zQJAKAVQuZIiIjeghDArFnAN98AKSlAwYJAly5yR0WU6xjdUla8eHE8fvw4XXlMTAyKFy+eLUHlNTGJagBA+UIuMkdCRGSkyEigWTNgwAApIWvaFDh3TloMloiMYnRL2c2bN6HRaNKVp6Sk4N69e9kSVF5z/ZE0puz94gVkjoSIyAjHjwMffQRERwN2dsDUqUC/fuyuJHpLWU7KNr20yN/27dvh4vKiVUej0WDXrl3w4xYZb+Xm8zXK/LlGGRHlJiVLSslYhQrAypVAuXJyR0SUq2U5KWvZsiUAQKFQICQkxOA1Gxsb+Pn54eeff87W4PKClDQNHidI3ZfeLhzoT0Rm7vp1oHhxqTXMzQ3YuVPas9LWVu7IiHK9LI8p02q10Gq1KFKkCB4+fKg/1mq1SElJQXh4OD7mGAKj3Xs+yN/eRon8jqo31CYikolWC0yZAgQEAIsXvygvXZoJGVE2MXqgf0REBNzd3U0RS56km3npm98eCo7DICJzdPcuEBQEDBsGpKYCe/fKHRGRRXqrJTESEhKwb98+3L59G2q12uC1AQMGZEtgeUVkXDIAwMvFXuZIiIgysHYt0Ls38PQp4OAA/PabtJk4EWU7o5Oy06dPo1mzZkhMTERCQgLy58+P6OhoODg4wMPDg0mZkXTdlz4cT0ZE5iQ+XlrmIjRUOq5WDVixAihVStawiCyZ0d2XgwYNQvPmzfH06VPY29vj6NGjuHXrFqpWrYpp06aZIkaLdudJIgDANz/3vCQiM3L2rLR5uEIBfPcdcPgwEzIiEzO6pSwsLAy///47rKysoFQqkZKSguLFi2PKlCkICQlB69atTRGnxdLte1m0AJMyIjIjtWsDP/8MVK0K1KsndzREeYLRLWU2NjawspJO8/DwwO3btwEALi4uuHPnTvZGlwfci5G6L4uwpYyI5BQRAQQHA1euvCgbNIgJGVEOMrqlrHLlyvjvv/9QsmRJ1K9fH6NHj0Z0dDSWLVuG9957zxQxWqzkVA2i4lIAAIXdmJQRkQyEAJYvl1bij48H+vQBdu2SOyqiPMnolrJJkybB29sbADBx4kS4ubmhT58+ePToEX7//XejA5g9ezb8/PxgZ2eHwMBAHD9+/LX1Y2Ji0K9fP3h7e8PW1halSpXCli1bjL6vOYh6PvOSa5QRkSxiYoCOHaXNw+PjpS7LP/6QOyqiPMvolrJq1arpn3t4eGDbtm1vffPVq1dj8ODBmDdvHgIDAzFjxgwEBwcjPDwcHh4e6eqr1Wp8+OGH8PDwwLp161CoUCHcunULrq6ubx2DnO7H6JbD4MxLIsph+/cDnTsDt28DSiUwZgwwYgRg/VYrJRFRNjC6pSwzp06dMnpF/+nTp6Nnz57o1q0bypYti3nz5sHBwQGLFi3KsP6iRYvw5MkTbNy4EbVr14afnx/q16+PihUrZsdbyHH3n48n83FlUkZEOWjnTuCDD6SEzN8fOHQI+P57JmREMjMqKdu+fTuGDh2KkSNH4saNGwCAy5cvo2XLlqhevTq0Wm2Wr6VWq3Hy5EkEBQW9CMbKCkFBQThy5EiG52zatAk1a9ZEv3794Onpiffeew+TJk2CRqPJ9D4pKSmIi4szeJiLqHippczTiUkZEeWg+vWB6tWlRWBPnwYCA+WOiIhgRFK2cOFCNG3aFKGhofjpp5/w/vvvY/ny5ahZsya8vLxw/vx5o8Z2RUdHQ6PRwNPT06Dc09MTkZGRGZ5z48YNrFu3DhqNBlu2bMH333+Pn3/+GT/88EOm95k8eTJcXFz0D19f3yzHaGp3nuhayriaPxGZkBDAmjWAbgcWGxtgzx5g4ULAyUne2IhIL8tJ2a+//oqffvoJ0dHRWLNmDaKjozFnzhycO3cO8+bNQ0BAgCnjBCBtiu7h4YH58+ejatWqaN++Pb777jvMmzcv03NGjBiB2NhY/cOclu0IuxMDACjoxM18ichEoqOB1q2B9u2B0aNflDtwxjeRucnyAILr16/j008/BQC0bt0a1tbWmDp1KgoXLvxWN3Z3d4dSqURUVJRBeVRUFLy8vDI8x9vbGzY2NlAqlfqygIAAREZGQq1WQ6VKP4PR1tYWtrbmmfSolNIG5HY22Ta0j4johR07gJAQ4MEDqXWsYEG5IyKi18hyNpCUlASH5/9npVAoYGtrq18a422oVCpUrVoVu15aD0er1WLXrl2oWbNmhufUrl0b165dMxi7duXKFXh7e2eYkJkzIQQioqXV/Cv6usobDBFZluRkYPBgoHFjKSErUwY4dgwYMkTuyIjoNYyaavPHH38gX758AIC0tDSEhobC3d3doI4xG5IPHjwYISEhqFatGmrUqIEZM2YgISEB3bp1AwB06dIFhQoVwuTJkwEAffr0waxZs/D111/jq6++wtWrVzFp0qRcuQn608RUxCWnAQD8CjjKHA0RWYzLl6WuyrNnpeO+fYGpU9ldSZQLZDkpK1KkCBYsWKA/9vLywrJlywzqKBQKoxKk9u3b49GjRxg9ejQiIyNRqVIlbNu2TT/4//bt2/otnQDA19cX27dvx6BBg1ChQgUUKlQIX3/9NYYNG5ble5oL3XIY7vlsYWejfENtIqIssrEBbtyQuioXLQKMXKqIiOSjEEIIuYPISXFxcXBxcUFsbCycnZ1li2P35Sh0Dz2Bcj7O2DygrmxxEJEFSEw0bAnbsQOoUAF4ZXY7Eckjq7kHR5jLJDJW2vPSgzMviehd/PMPULw4sHv3i7IPP2RCRpQLMSmTia77spAb1ygjoreQmCiNF2veHIiKAn7+We6IiOgdMSmTyanbTwEAXs5czZ+IjHT6NFC1KjB3rnQ8eDCwfr28MRHRO2NSJhOllbRGmbWSXwERZZFWK82kDAyUZll6ewP//iu1kpnpeoxElHXMCGQSl5QKACian9PUiSiLtm0Dvv0WSE0FWrUCzp2Txo8RkUV4q6Ts+vXrGDVqFDp06ICHDx8CALZu3YoLFy5ka3CWLPqZtAedpwu7L4koi5o2lTYRX7AA+N//gAIF5I6IiLKR0UnZvn37UL58eRw7dgzr16/Hs2fPAABnzpzBmDFjsj1ASySEwKNn0uzLgvnY5UBEmYiPl8aLPX4sHSsU0ibiX3whPScii2J0UjZ8+HD88MMP2LFjh8HWRg0bNsTRo0ezNThLFZuUCnWatFUUNyMnogwdPQpUrgz88gvw5ZdyR0NEOcDopOzcuXNo1apVunIPDw9ER0dnS1CWLipOaiVzsbfhav5EZCgtDZgwAahTB7h+HShSBPjqK7mjIqIcYHRS5urqigcPHqQrP336NAoVKpQtQVm6qLhkAIA3x5MR0csiIoAPPgBGjwY0GqBDB+DMGaBePbkjI6IcYHRS9tlnn2HYsGGIjIyEQqGAVqvFoUOHMHToUHTp0sUUMVqcyOdJmQfXKCMinQMHgIoVgUOHAGdnYPlyYOVKwNVV7siIKIcYnZRNmjQJZcqUga+vL549e4ayZcuiXr16qFWrFkaNGmWKGC1ONAf5E9GrypcH3NyA2rWBsDCgUye5IyKiHGZt7AkqlQoLFizA999/j/Pnz+PZs2eoXLkySpYsaYr4LNKT58thFMinekNNIrJo584B770nzaR0dQX27gV8fQFro/9pJiILYHRL2cGDBwEARYoUQbNmzdCuXTsmZEZ6kiAlZfkdmZQR5UmpqcB330ndlX/88aK8WDEmZER5mNFJWcOGDVGsWDGMHDkSFy9eNEVMFi/m+Wr+bg42MkdCRDnuyhWgVi1g0iRACKm1jIgIb5GU3b9/H0OGDMG+ffvw3nvvoVKlSpg6dSru3r1rivgs0tNEqaXMxZ4tZUR5hhDSSvyVKwMnTkjjx9atA377Te7IiMhMGJ2Uubu7o3///jh06BCuX7+OTz/9FEuWLIGfnx8aNmxoihgtTkwiW8qI8pToaKB1a6BXLyAxEWjYEDh7FmjTRu7IiMiMvNOG5MWKFcPw4cPx448/onz58ti3b192xWXRYp63lLk6sKWMKE8IDwc2bQJsbICpU4EdO4DCheWOiojMzFuPKD106BBWrFiBdevWITk5GS1atMDkyZOzMzaLlKrR4unzljJ3zr4kslxCvNifsnZtYOZMoGZNqfuSiCgDRreUjRgxAsWKFUPDhg1x+/Zt/Prrr4iMjMSyZcvQpEkTU8RoUXTjyawUbCkjsljnz0uD+S9fflHWty8TMiJ6LaNbyvbv349vvvkG7dq1g7u7uylismi65TBcHVRQWilkjoaIspUQwKxZwDffACkpwMCBwLZtckdFRLmE0UnZoUOHTBFHnqEb5O9qz0H+RBYlMhLo1u1FEtasGbBokbwxEVGukqWkbNOmTWjatClsbGywadOm19b95JNPsiUwSxX3fI0yZyZlRJbj77+B7t2lWZZ2dsC0aVJ3pYKt4USUdVlKylq2bInIyEh4eHigZcuWmdZTKBTQaDTZFZtF0i0c68KkjMgy/PMPoPuf0QoVpE3Ey5WTNyYiypWylJRptdoMn5PxdMthcIslIgvRpIk0qL9mTWDiRMDWVu6IiCiXMnr25dKlS5GSkpKuXK1WY+nSpdkSlCXTLYfBljKiXEqrlfar1P07aG0N7NkjdVkyISOid2B0UtatWzfExsamK4+Pj0e3bt2yJShL9pSbkRPlXnfuAEFBQM+ewKhRL8pV/H0mondndFImhIAig8Grd+/ehYuLS7YEZckeMykjyp3WrpXGjO3ZAzg4AGXKyB0REVmYLC+JUblyZSgUCigUCjRq1AjW1i9O1Wg0iIiI4OKxWaAbU+bGhWOJcof4eGDAACA0VDquXh1YsQIoWVLWsIjI8mQ5KdPNugwLC0NwcDDy5cunf02lUsHPzw9tuLnuGz3lZuREuUdYmLRp+I0b0vIWI0cCY8ZIe1gSEWWzLCdlY8aMAQD4+fmhffv2sLOzM1lQloybkRPlIi4uwKNHQJEiwPLlQN26ckdERBbM6BX9Q0JCTBFHniCEQFxSGgDAhS1lROYpJgZwdZWeFysmrUNWocKLMiIiE8nSQP/8+fMjOjoaAODm5ob8+fNn+qDMpaRpodZI67w52xmdDxORKQkBLFsG+PkBO3a8KK9XjwkZEeWILGUGv/zyC5ycnPTPM5p9SW+m22LJSgE4qpiUEZmNmBigTx9g1SrpeP584MMPZQ2JiPKeLGUGL3dZdu3a1VSxWDzdFkuuDipYWTGxJTIL+/YBnTtLa5AplcDYscDw4XJHRUR5kNHrlJ06dQrnzp3TH//1119o2bIlRo4cCbVana3BWRrdwrGuXM2fSH5qtTSbskEDKSHz9wcOHZIWhbVmSzYR5Tyjk7LevXvjypUrAIAbN26gffv2cHBwwNq1a/Htt99me4CWRL8ZOQf5E8lv+3Zg8mRpLFn37sDp00BgoNxREVEeZnRSduXKFVSqVAkAsHbtWtSvXx8rV65EaGgo/ve//2V3fBYllvteEpmP5s2Bfv2klfoXLgSej5slIpLLW22zpNVKMwh37tyJZs2aAQB8fX31MzQpY3HJTMqIZBMdDXzxhbTumM6sWUDbtvLFRET0EqMHTlSrVg0//PADgoKCsG/fPsydOxcAEBERAU9Pz2wP0JLoZl862zEpI8pR//4LdO0KPHgAxMZKrWNERGbG6JayGTNm4NSpU+jfvz++++47lChRAgCwbt061KpVK9sDtCRxydLCsc72HERMlCOSk4FBg4DgYCkhCwiQBvcTEZkho7ODChUqGMy+1Jk6dSqUSmW2BGWpdN2XTmwpIzK98+eBjh0B3b9XffsCU6cCDg7yxkVElIm3brI5efIkLl26BAAoW7YsqlSpkm1BWar45y1lTlzNn8i0duyQBvKnpAAFCwKLFgEffyx3VEREr2V0dvDw4UO0b98e+/btg+vzrUdiYmLQoEEDrFq1CgULFszuGC3GM31SxpYyIpMKDAS8vYGyZaWEjONdiSgXMHpM2VdffYVnz57hwoULePLkCZ48eYLz588jLi4OAwYMMEWMFiM+Req+zGfLbl6ibHfkiLTmGAA4O0sLwf7zDxMyIso1jE7Ktm3bhjlz5iAgIEBfVrZsWcyePRtbt27N1uAsDVvKiEwgMVEaL1arFvD77y/KfXwA7tNLRLmI0d2XWq0WNjbpkwobGxv9+mWUsWcpUlKWz5ZjyoiyxalTQKdOwOXL0vHdu/LGQ0T0DoxuKWvYsCG+/vpr3L9/X1927949DBo0CI0aNcrW4CxN9DNp70tnLh5L9G60Wmkm5fvvSwmZj480uP+HH+SOjIjorRmdlM2aNQtxcXHw8/ODv78//P39UaxYMcTFxWHmzJmmiNEiJKdq9M85+5LoHdy9C3z4IfDtt0BqKtCqFXD2LBAUJHdkRETvxOjswNfXF6dOncKuXbv0S2IEBAQgiP8gvlbM830vAcCJ3ZdEb+/OHWDfPmm9sd9+kzYT59gxIrIARmUHq1evxqZNm6BWq9GoUSN89dVXporL4sQkSV2X+R1VUPAPCJFxtFrA6nnDfs2awIIFQJ06QMmS8sZFRJSNstx9OXfuXHTo0AEnTpzA1atX0a9fP3zzzTemjM2ixCVJg/y5GTmRkY4eBSpWBC5efFHWrRsTMiKyOFlOymbNmoUxY8YgPDwcYWFhWLJkCebMmWPK2CxKvH6LJXZdEmVJWhowfrzUInb+PDB8uNwRERGZVJaTshs3biAkJER/3LFjR6SlpeHBgwcmCczScIslIiNERAD16wNjxgAajbSH5dKlckdFRGRSWU7KUlJS4Ojo+OJEKyuoVCokJSWZJDBLo28ps2X3JVGmhACWLZO6Kw8fllbmX74cWLECeL6tGxGRpTKq2eb777+Hg4OD/litVmPixIlwcXHRl02fPj37orMg8SlsKSN6o/XrgS5dpOe1a0sJmZ+frCEREeWULGcI9erVQ3h4uEFZrVq1cOPGDf0xZxVmTtd9mY9JGVHmWrSQui2DgqQxZNb8fSGivCPL/+Lt3bvXhGFYvhcD/dl9SaSnVgNz5gB9+gC2tlIStmsXoFTKHRkRUY7j/4bmEP1m5Fw4lkgSHi7tW3nypLQg7M8/S+VMyIgojzJ6myVTmD17Nvz8/GBnZ4fAwEAcP348S+etWrUKCoUCLVu2NG2A2eAZx5QRSYSQFn+tUkVKyNzcgFq15I6KiEh2sidlq1evxuDBgzFmzBicOnUKFStWRHBwMB4+fPja827evImhQ4eibt26ORTpu+GYMiIA0dFA69ZAr15AYiLQsKG0b2WbNnJHRkQkO9mTsunTp6Nnz57o1q0bypYti3nz5sHBwQGLFi3K9ByNRoNOnTph3LhxKF68eA5G+/Z0LWX52H1JedWRI0CFCsDGjYCNDTB1KrBjB1C4sNyRERGZBVmTMrVajZMnTxpsZm5lZYWgoCAcOXIk0/PGjx8PDw8P9OjR4433SElJQVxcnMFDDrqkzJFJGeVVPj5AQgIQEAAcOwYMHfpiP0siInq7pOzAgQP4/PPPUbNmTdy7dw8AsGzZMhw8eNCo60RHR0Oj0cDT09Og3NPTE5GRkRmec/DgQSxcuBALFizI0j0mT54MFxcX/cPX19eoGLNLbJI0+9KVe19SXvLyMISiRYF//wVOnAAqV5YvJiIiM2V0Uva///0PwcHBsLe3x+nTp5GSkgIAiI2NxaRJk7I9wJfFx8ejc+fOWLBgAdzd3bN0zogRIxAbG6t/3Llzx6QxZkSrFYh7npRxQ3LKE4QAZs6UFn7dvv1FeWAg8NIC1ERE9ILRfWk//PAD5s2bhy5dumDVqlX68tq1a+OHH34w6lru7u5QKpWIiooyKI+KioKXl1e6+tevX8fNmzfRvHlzfZlWqwUAWFtbIzw8HP7+/gbn2NrawtbW1qi4slt8Shq0Qnru4sCkjCxcZCTQrRuwbZt0vGoVEBwsb0xERLmA0S1l4eHhqFevXrpyFxcXxMTEGHUtlUqFqlWrYteuXfoyrVaLXbt2oWbNmunqlylTBufOnUNYWJj+8cknn6BBgwYICwuTrWvyTWITpVYyOxsr2FpzDSayYH//DZQvLyVkdnZSa9lrJu0QEdELRreUeXl54dq1a/B7ZT+6gwcPvtVMyMGDByMkJATVqlVDjRo1MGPGDCQkJKBbt24AgC5duqBQoUKYPHky7Ozs8N577xmc7/p8k+JXy81JHFfzJ0uXmCgN3J87VzquUAFYuRIoV07euIiIchGjk7KePXvi66+/xqJFi6BQKHD//n0cOXIEQ4cOxffff290AO3bt8ejR48wevRoREZGolKlSti2bZt+8P/t27dhlctnaOmSMmeuUUaWaseOFwnZ4MHApEnStklERJRlCiGEMOYEIQQmTZqEyZMnIzExEYA0bmvo0KGYMGGCSYLMTnFxcXBxcUFsbCycnZ1z5J7bzkfiy+UnUaWIK9b3rZ0j9yTKcUOHSmPHPvxQ7kiIiMxKVnMPo5ugFAoFvvvuOzx58gTnz5/H0aNH8ejRo1yRkMklQbdwLLsvyVLcvQu0b2+45MW0aUzIiIjewVv3p6lUKpQtWzY7Y7FYCWrdav4c5E8WYO1aoHdv4OlT6Xj1annjISKyEEYnZQ0aNIBCocj09d27d79TQJZIv+8lV/On3Cw+HhgwAAgNlY6rVQPYQk5ElG2MzhIqVapkcJyamoqwsDCcP38eISEh2RWXRdEtHOvM7kvKrY4eBTp1Am7cABQKYMQIYOxYaQ9LIiLKFkYnZb/88kuG5WPHjsWzZ8/eOSBLFPe8pYxLYlCu9PffQKtWgEYDFCkCLFsGZLBWIRERvZtsW2vi888/xyIuEpmheP06Zey+pFyofn1p38oOHYAzZ5iQERGZSLZlCUeOHIGdnV12Xc6iPNPPvmRSRrmAEMDOnUBQkNRV6ewMHD8OFCggd2RERBbN6CyhdevWBsdCCDx48AAnTpx4q8Vj8wL9khgc6E/mLiYG6NNH2q9y1iygXz+pnAkZEZHJGZ0luLi4GBxbWVmhdOnSGD9+PBo3bpxtgVmSZykaAIAjkzIyZ/v3A507A7dvA0olkJAgd0RERHmKUVmCRqNBt27dUL58ebi5uZkqJovzLIVjysiMpaZKMyknT5a6Lv39gRUrgMBAuSMjIspTjBror1Qq0bhxY8TExJgoHMukW6fMiS1lZG6uXgVq1ZL2qhQC6N4dOH2aCRkRkQyMnn353nvv4caNG6aIxWIlsvuSzNWTJ1IS5uYGrFsHLFwIODnJHRURUZ5kdFL2ww8/YOjQofjnn3/w4MEDxMXFGTzIUKpGC7VGCwBwUHGbJTIDaWkvngcGAkuXAmfPAm3ayBcTERFlPSkbP348EhIS0KxZM5w5cwaffPIJChcuDDc3N7i5ucHV1ZXjzDKgm3kJAA4qtpSRzHbsAEqXBs6ff1HWsSNQuLB8MREREQAjBvqPGzcOX375Jfbs2WPKeCxOXJKUlNnbKKGyzra1eomMk5wMjBwJ6HbkGD8eWLNG3piIiMhAlpMyIQQAoH79+iYLxhLFP595yYVjSTYXLkitYWfPSsd9+wJTp8obExERpWNU041CoTBVHBYrUf18kD/Hk1FOEwKYOROoVk1KyAoWlPaxnD0bcHCQOzoiInqFUc03pUqVemNi9uTJk3cKyNLokjJ7jiejnLZqFTBggPS8aVNg8WLA01PemIiIKFNGZQrjxo1Lt6I/vV6SWhpTxpYyynHt2gGhoUDz5tJ2SWzpJiIya0YlZZ999hk8PDxMFYtFetFSxqSMTCwxEfj5Z+CbbwA7O2mrpG3bmIwREeUSWU7KOJ7s7SSlSkmZnQ2TMjKh06elwfyXLwOPHwMzZkjl/L0lIso1sjzQXzf7koyT9LyljAvHkklotdJMysBAKSHz9gY++kjuqIiI6C1kuaVMq9WaMg6LlaxrKbNmUkbZ7O5dICQE2L1bOm7VCliwAChQQN64iIjorXBKoIkl6FrKbJmUUTbavRto2xZ4+lRa3uLXX4EePdhdSUSUizEpM7HEFN3sS37UlI1KlJC6LqtVA1asAEqVkjsiIiJ6R8wUTIyzLynb3L4NFCkiPS9SBNi3DyhbFrCxkTcuIiLKFtyM0cQSUznQn95RWpq0V6W/P7Bly4vyihWZkBERWRAmZSaW8jwps+eSGPQ2IiKA+vWBMWOk5Gz7drkjIiIiE2FSZmJcp4zeihDA8uVSa9jhw4Czs3T8669yR0ZERCbCMWUmxjFlZLSYGKBPH2nvSgCoXVtKyPz85IyKiIhMjC1lJpacKq3vxu5LyrI9e6SETKkEJkwA9u5lQkZElAewpczEktl9ScZq1QoYNQr4+GNppX4iIsoT2FJmYskc6E9vEh4ONGsGREW9KJswgQkZEVEew6TMxHQD/e1V/KjpFUJI2yJVqQJs3QoMHCh3REREJCN2X5qYrqXMlntf0suio4GePYGNG6Xjhg2ljcWJiCjPYvONCQkhXgz05+xL0tmxA6hQQUrIbGyAadOkssKF5Y6MiIhkxJYyE0pJ0+qfc6A/AQDWrAHat5eeBwQAK1cClSrJGhIREZkHJmUmpOu6BAA7azZKEqQB/SVKAI0bS92VDg5yR0RERGaCSZkJ6Qb52ygVsFYyKcuThAA2bABatgSsrIB8+YBTpwAnJ7kjIyIiM8NMwYR048nsOMg/b4qMlFrG2rQBZs16Uc6EjIiIMsCkzISSnm+xZMvxZHnP338D5csD27YBdnaAra3cERERkZlj96UJcY2yPCgxERgyBJg3TzquUEEazF+unLxxERGR2WO2YEIpui2W2H2ZN5w5Iy0Eq0vIhgwBjh9nQkZERFnCljITSk7jvpd5SmoqcP064O0NLFkCfPih3BEREVEuwqTMhJLUzxeOZVJmuZKTpTFjAFCtmrQOWb16QIEC8sZFRES5DrsvTShRnQaAq/lbrLVrgWLFgLNnX5S1asWEjIiI3gqTMhPSDfR3YFJmWeLjgW7dgHbtpGUvpk2TOyIiIrIATMpMSLckBlvKLMjRo9K2SKGhgEIBfPcdsHCh3FEREZEF4JgyE0rUJWUcU5b7paUBkyYB48cDGg1QpAiwfDlQt67ckRERkYVgS5kJsfvSgqxYAYwZIyVkHTtKy18wISMiomzEljITSmJLmeX4/HNpD8tPPwU6dZI7GiIiskBsKTOh5FRus5RrxcQA334rrdAPAEolsHEjEzIiIjIZtpSZUHLa8w3JmZTlLvv3A507A7dvA0lJwMyZckdERER5AFvKTIjdl7mMWg2MHAl88IGUkPn7S92WREREOYAtZSaUksYNyXON8HCpa/LkSem4Rw9gxgwgXz5ZwyIioryDSZkJ6ceUcUNy87Z5s7QQbGIi4OYGLFgAtGkjd1RERJTHMCkzoRT9mDK2lJm1ihUBW1vg/feljcQLF5Y7IiIiyoOYlJmQbkwZB/qbocuXgTJlpOeFCwNHjgAlSwJWTKCJiEge/AtkQslpTMrMTnIyMGgQULYs8PffL8pLl2ZCRkREsjKLv0KzZ8+Gn58f7OzsEBgYiOPHj2dad8GCBahbty7c3Nzg5uaGoKCg19aXU0qq1H1pa20WHzOdPw/UqCEN4BcCMNOfGyIiyptkzxZWr16NwYMHY8yYMTh16hQqVqyI4OBgPHz4MMP6e/fuRYcOHbBnzx4cOXIEvr6+aNy4Me7du5fDkb+ZWsOkzCwIIa01Vq0acO4cULCg1Eo2YYLckREREekphBBCzgACAwNRvXp1zJo1CwCg1Wrh6+uLr776CsOHD3/j+RqNBm5ubpg1axa6dOnyxvpxcXFwcXFBbGwsnJ2d3zn+1yk7ehsS1Roc+LYBfPM7mPRelInISKBbN2DbNum4aVNg8WLA01PeuIiIKM/Iau4haxOOWq3GyZMnERQUpC+zsrJCUFAQjhw5kqVrJCYmIjU1Ffnz58/w9ZSUFMTFxRk8cor6+exLFVvK5HPkiJSQ2dlJrWWbNzMhIyIisyRrthAdHQ2NRgPPV/5Ienp6IjIyMkvXGDZsGHx8fAwSu5dNnjwZLi4u+oevr+87x50VqRot0rRSI6Qd1ymTT6tWwMSJwIkTQP/+gEIhd0REREQZytVNOD/++CNWrVqFDRs2wM7OLsM6I0aMQGxsrP5x586dHIlNt3AsANhynbKcc+oUUK8e8ODBi7KRI4Fy5eSLiYiIKAtkzRbc3d2hVCoRFRVlUB4VFQUvL6/Xnjtt2jT8+OOP+Pfff1GhQoVM69na2sLZ2dngkROSn8+8VCg40D9HaLXAlCnSArAHDgDDhskdERERkVFkzRZUKhWqVq2KXbt26cu0Wi127dqFmjVrZnrelClTMGHCBGzbtg3VqlXLiVCN9mKLJSso2GVmWnfuAEFBUiKWmip1Wf7yi9xRERERGUX2Ff0HDx6MkJAQVKtWDTVq1MCMGTOQkJCAbt26AQC6dOmCQoUKYfLkyQCAn376CaNHj8bKlSvh5+enH3uWL18+5DOjzaN1SZk9F441rbVrgd69gadPAQcH4LffgO7dOXaMiIhyHdmTsvbt2+PRo0cYPXo0IiMjUalSJWzbtk0/+P/27duwemml9blz50KtVqNt27YG1xkzZgzGjh2bk6G/lq77kqv5m9CSJUDXrtLz6tWBFSukrZKIiIhyIdnXKctpObVO2X83n+DTeUfgV8ABe79pYLL75GkJCVIy1ro1MGYMYGMjd0RERETpZDX3kL2lzFKlsKUs+6WlAStXAp9/Lu1T6egozbbMZOYtERFRbsJpgSaSkvZioD9lg4gIoH59ICQE+PXXF+VMyIiIyEIwYzAR3Zgyrub/joQAli0DKlYEDh8GnJ2BNyyXQkRElBux+9JEdLMv2X35DmJigD59gFWrpOPatYHlywE/PzmjIiIiMgk245hIShrHlL2TI0eAChWkhEypBCZMAPbuZUJGREQWiy1lJsKWsndkawtERgL+/tJSF4GBckdERERkUkzKTCRJv3gsGyOzLD4ecHKSnlepAvz1F1CnzosyIiIiC8aMwUTYfWkEIYAFC4CiRYGwsBflTZsyISMiojyDSZmJpKRySYwsiY6WFn/t1UvaKmnePLkjIiIikgUzBhPRtZRxSYzX+PdfaTD/xo3SavxTpwJz5sgdFRERkSw4psxEdEmZrTW7L9NJTgZGjgR++UU6LlNGWqm/cmV54yIiIpIRm3FMRM2WssytWPEiIevbFzh5kgkZERHleWwpMxHdNksqJZOydLp1A3buBDp1Aj7+WO5oiIiIzAIzBhNhS9lLIiOlFrHEROnYygr4808mZERERC9hS5mJJHNJDMk//wDduwOPHknJ2KxZckdERERkltiMYyIvVvTPox9xYqLUOta8uZSQVagg7WNJREREGcqjGYPp6dYps8uLsy9PnwaqVgXmzpWOBw8Gjh8HypWTNy4iIiIzxu5LE0lOlbov7VV5LClbtw7o2BFITQW8vYElS4APP5Q7KiIiIrPHpMxE9LMv89pA/1q1pK2R6teXtk4qUEDuiIiIiHIFJmUmotYvHpsHkrJTp6QNxAHAx0c6LlIEUCjkjYuIiCgXyQMZgzzyxDZL8fHSzMqqVYG//npRXrQoEzIiIiIjsaXMRHRJmcUO9D96FPj8c+D6dSkBCw+XOyIiIqJczYKbceT1YkkMC0vK0tKA8eOBOnWkhKxIEWDfPuDbb+WOjIiIKFdjS5kJaLQCaVoBwMLGlEVESK1jhw9Lxx06AHPmAK6usoZFRERkCZiUmUDS81YywMKWxDh7VkrInJ2lZKxTJ7kjIiIishhMykwg+aWkLNe3lAnxYtB+ixbA9OlAy5ZAsWKyhkVERGRpcnnGYJ6S1FJSZmttBUVunoW4f780s/LevRdlgwYxISMiIjIBtpSZQEpu34w8NRUYOxaYPFlqKRs9Gli4UO6oiCgX02g0SE1NlTsMIpOwsbGBUvnuf/OZlJlArt6M/MoVaazYiRPScffuwIwZsoZERLmXEAKRkZGIiYmROxQik3J1dYWXl9c79ZAxKTOBFP1q/rmopUwI4I8/gIEDgcREwM0NmD8faNtW7siIKBfTJWQeHh5wcHDI3UM6iDIghEBiYiIePnwIAPD29n7razEpM4GU1BdjynKN+fOBL7+UnjdsKG0kXriwvDERUa6m0Wj0CVkB7oNLFsze3h4A8PDhQ3h4eLx1V2Yuyhpyj1w5pqxzZ6BCBWDqVGDHDiZkRPTOdGPIHBwcZI6EyPR0P+fvMnaSLWUmkJKWC1rKkpOBRYuk1jErK8DBATh5ErDmjwQRZS92WVJekB0/5/wLbAJm31J24QLQsaO0GGxSEjBkiFTOhIyIiEg2ZtyUk3vpZl+qzK2lTAhg5kxp7bGzZ4GCBYHSpeWOiogoT9q7dy8UCoVRM1P9/Pww4w0z4tVqNUqUKIHDui3x6J0NHz4cX331lcnvY2ZZg2V40VJmRh9vZCTQrBkwYACQkgI0bQqcOwd8/LHckRERmZ2uXbtCoVDgS90EqJf069cPCoUCXbt2zfnAsmDevHkoVqwYatWqle613r17Q6lUYu3atele69q1K1q2bJmuPKPkUa1WY8qUKahYsSIcHBzg7u6O2rVrY/HixSZdj+7s2bOoW7cu7Ozs4OvriylTprzxnF27dqFWrVpwcnKCl5cXhg0bhrS0NP3rY8eOhUKhSPdwdHTU1xk6dCiWLFmCGzdumOR96ZhR1mA5UlLNbEmMXbukQfzbtgG2tlJr2ebNgKen3JEREZktX19frFq1CklJSfqy5ORkrFy5EkWKFJExsswJITBr1iz06NEj3WuJiYlYtWoVvv32WyxatOit76FWqxEcHIwff/wRvXr1wuHDh3H8+HH069cPM2fOxIULF97lLWQqLi4OjRs3RtGiRXHy5ElMnToVY8eOxfz58zM958yZM2jWrBmaNGmC06dPY/Xq1di0aROGDx+urzN06FA8ePDA4FG2bFl8+umn+jru7u4IDg7G3LlzTfLedJiUmYBuoL9KaSYfb4ECQEyMlJidPAn07/9iP0siohwkhECiOk2WhxDCqFirVKkCX19frF+/Xl+2fv16FClSBJUrVzaom5KSggEDBsDDwwN2dnaoU6cO/vvvP4M6W7ZsQalSpWBvb48GDRrg5s2b6e558OBB1K1bF/b29vD19cWAAQOQkJCQ5ZhPnjyJ69ev46OPPkr32tq1a1G2bFkMHz4c+/fvx507d7J83ZfNmDED+/fvx65du9CvXz9UqlQJxYsXR8eOHXHs2DGULFnyra77JitWrIBarcaiRYtQrlw5fPbZZxgwYACmT5+e6TmrV69GhQoVMHr0aJQoUQL169fHlClTMHv2bMTHxwMA8uXLBy8vL/0jKioKFy9eTJfYNm/eHKtWrTLJe9PhyG4T0C8eK2f35ZMnQP780vNKlYB//wVq1pRayoiIZJKUqkHZ0dtluffF8cFwUBn3Z6979+5YvHgxOnXqBABYtGgRunXrhr179xrU+/bbb/G///0PS5YsQdGiRTFlyhQEBwfj2rVryJ8/P+7cuYPWrVujX79+6NWrF06cOIEhuklWz12/fh1NmjTBDz/8gEWLFuHRo0fo378/+vfvj8WLF2cp3gMHDqBUqVJwcnJK99rChQvx+eefw8XFBU2bNkVoaCi+//57oz4PQEqOgoKC0iWmgLTdkI2NTYbn3b59G2XLln3ttUeOHImRI0dm+NqRI0dQr149qFQqfVlwcDB++uknPH36FG5ubunOSUlJgZ2dnUGZvb09kpOTcfLkSXzwwQfpzvnjjz9QqlQp1K1b16C8Ro0auHv3Lm7evAk/P7/Xvo+3ZSZNOZZFrV/RX4aPV6uV1horUgQ4depF+QcfMCEjIjLS559/joMHD+LWrVu4desWDh06hM8//9ygTkJCAubOnYupU6eiadOmKFu2LBYsWAB7e3ssfL5v8Ny5c+Hv74+ff/4ZpUuXRqdOndKNSZs8eTI6deqEgQMHomTJkqhVqxZ+++03LF26FMnJyVmK99atW/Dx8UlXfvXqVRw9ehTt27fXv6/Fixcb3Xqou1aZMmWMPs/HxwdhYWGvfWQ0hk8nMjISnq8Mu9EdR0ZGZnhOcHAwDh8+jD///BMajQb37t3D+PHjAQAPHjxIVz85ORkrVqzIsPtX97neunUra2/4LbClzAR0LWU5Pvvy7l0gJATYvVs6XrECqFIlZ2MgInoNexslLo4Plu3exipYsCA++ugjhIaGQgiBjz76CO7u7gZ1rl+/jtTUVNSuXVtfZmNjgxo1auDSpUsAgEuXLiEwMNDgvJo1axocnzlzBmfPnsWKFSv0ZUIIaLVaREREICAg4I3xJiUlpWsZAqQWvuDgYH3szZo1Q48ePbB79240atTojdd92dskcgBgbW2NEiVKvNW5b6tx48aYOnUqvvzyS3Tu3Bm2trb4/vvvceDAAVhZpf8bvWHDBsTHxyMkJCTda7pV+xMTE00WL5MyE1Brnidl2bBjfJatXQv07g08fSotBPvrr0AGmT4RkZwUCoXRXYhy6969O/r37w8AmD17tsnu8+zZM/Tu3RsDBgxI91pWJxa4u7vj3LlzBmUajQZLlixBZGQkrF9aj1Kj0WDRokX6pMzZ2TnDVqCYmBgolUr9bMRSpUrh8uXLWX5fOu/afakb7/Uy3bGXl1em1xw8eDAGDRqEBw8ewM3NDTdv3sSIESNQvHjxdHX/+OMPfPzxx+la5ADgyZMnAKRE3VRy129GLqGffZkTY8ri44GvvwZ04w2qVZNayEqVMv29iYjygCZNmkCtVkOhUCA4OH0rn7+/P1QqFQ4dOoSiRYsCkLba+e+//zBw4EAAQEBAADZt2mRw3tGjRw2Oq1SpgosXL75Ta1LlypUxd+5cCCH0K8xv2bIF8fHxOH36tMGejOfPn0e3bt0QExMDV1dXlC5dGqtWrUJKSgpsXxrucurUKRQrVkw/Vqxjx44YOXIkTp8+nW5cWWpqKtRqtcFyEjq67svXya8bC52BmjVr4rvvvkNqaqo+lh07dqB06dIZjid7mUKh0Hc//vnnn/D19UWVV3qSIiIisGfPnnTfk8758+dhY2ODcuXKvfZe70TkMbGxsQKAiI2NNdk9+q88JYoO+0csPHDDZPfQmzdPCEAIhUKIkSOFUKtNf08ioixISkoSFy9eFElJSXKHYrSQkBDRokUL/XFsbKzB340WLVqIkJAQ/fHXX38tfHx8xNatW8WFCxdESEiIcHNzE0+ePBFCCHHr1i2hUqnE0KFDxeXLl8WKFSuEl5eXACCePn0qhBDizJkzwt7eXvTr10+cPn1aXLlyRWzcuFH069dPf5+iRYuKX375JdO4o6OjhY2NjTh37pxBrO3bt09XV6PRCC8vLzFr1iwhhBBPnz4VHh4eol27duLEiRPi6tWrYuHChcLJyUnMnTtXf15ycrKoW7eucHNzE7NmzRJhYWHi+vXrYvXq1aJKlSri9OnTWfmIjRYTEyM8PT1F586dxfnz58WqVauEg4OD+P333/V11q9fL0qXLm1w3pQpU8TZs2fF+fPnxfjx44WNjY3YsGFDuuuPGjVK+Pj4iLS0tAzvP2bMGNGwYcNM43vdz3tWcw8mZSbQc8l/ouiwf8SyIzdNdg89jUaIbt2E2LfP9PciIjKCJSVlr3o1KUtKShJfffWVcHd3F7a2tqJ27dri+PHjBuf8/fffokSJEsLW1lbUrVtXLFq0yCApE0KI48ePiw8//FDky5dPODo6igoVKoiJEyfqX39TUiaEEO3atRPDhw8XQggRGRkprK2txZo1azKs26dPH1G5cmX9cXh4uGjVqpXw8fERjo6OomLFimLBggVCq9UanJecnCwmT54sypcvL+zs7ET+/PlF7dq1RWhoqEhNTX1tfO/izJkzok6dOsLW1lYUKlRI/PjjjwavL168WLza3tSgQQPh4uIi7OzsRGBgoNiyZUu662o0GlG4cGExcuTITO9dunRp8eeff2b6enYkZQoh3nLEXi4VFxcHFxcXxMbGwtnZ2ST36Lr4OPaGP8KUthXQrppv9l48IgIYMwaYOxfIoHmYiMhcJCcnIyIiAsWKFctw8DmZxtmzZ/Hhhx/i+vXryJcvn9zhWIStW7diyJAhOHv2rMG4vJe97uc9q7kHl8QwgRcr+mfjxysEsHw5ULEisGwZ8NJqxERERDoVKlTATz/9hIiICLlDsRgJCQlYvHhxpglZduFAfxNI1WRzUhYTA/TpA+hWEq5dG3hl0UEiIiIdc92XM7dq27ZtjtyHLWUmoF8SIzuSsv37pdaxVasApRKYMAHYuxcw0WrCREREJA+2lJmAbkX/d16nbNkyaTFYIQB/f2mpi1cWHyQiIiLLwJYyE9C1lFkr33HT76AgaTPx7t2B06eZkBEREVkwtpSZQJpGmtBqozQy5xVC6q6sX1869vYGzp0DXrNSMREREVkGtpSZgG6gv40xLWXR0UDr1tLG4f/734tyJmRERER5AlvKTCDV2Jayf/8FunYFHjwAbGyAV/b2IiIiIsvHljITSNNmsaUsORkYNAgIDpYSsoAA4NgxoG/fHIiSiIiIzAmTMhPQjSmztnrNx3v+PFCjBjBjhnTcty9w4gTwyuauRESU9ygUCmzcuFHuMCiHMSkzAV1L2WtnX968KQ3iL1gQ+PtvYPZswMEhZwIkIqLX6tq1KxQKBRQKBWxsbFCsWDF8++23SE5Oljs0k4uMjMTXX3+NEiVKwM7ODp6enqhduzbmzp2LxMREucOzaBxTZgIardRSprR6JSnTaKQFYAHg44+BefOAli0BT8+cDZCIiN6oSZMmWLx4MVJTU3Hy5EmEhIRAoVDgp59+kjs0k7lx4wZq164NV1dXTJo0CeXLl4etrS3OnTuH+fPno1ChQvjkk0/kDtNisaXMBNIySsr+/hsoWxa4e/dFWe/eTMiIKG9KSMj88Wpr1OvqJiVlre5bsLW1hZeXF3x9fdGyZUsEBQVhx44d+tcfP36MDh06oFChQnBwcED58uXx559/Glzjgw8+wIABA/Dtt98if/788PLywtixYw3qXL16FfXq1YOdnR3Kli1rcA+dc+fOoWHDhrC3t0eBAgXQq1cvPHv2TP96165d0bJlS0yaNAmenp5wdXXF+PHjkZaWhm+++Qb58+dH4cKFsXjx4te+5759+8La2honTpxAu3btEBAQgOLFi6NFixbYvHkzmjdvDgC4efMmFAoFwsLC9OfGxMRAoVBg7969+rLz58+jadOmyJcvHzw9PdG5c2dER0frX1+3bh3Kly+vf19BQUFIeP597d27FzVq1ICjoyNcXV1Ru3Zt3Lp167Xx53ZmkZTNnj0bfn5+sLOzQ2BgII4fP/7a+mvXrkWZMmVgZ2eH8uXLY8uWLTkU6ZtptQJCysmkMWWJidK+lZ98Aly5AkyaJG+ARETmIF++zB9t2hjW9fDIvG7TpoZ1/fwyrveOzp8/j8OHD0OlUunLkpOTUbVqVWzevBnnz59Hr1690Llz53R/w5YsWQJHR0ccO3YMU6ZMwfjx4/WJl1arRevWraFSqXDs2DHMmzcPw4YNMzg/ISEBwcHBcHNzw3///Ye1a9di586d6N+/v0G93bt34/79+9i/fz+mT5+OMWPG4OOPP4abmxuOHTuGL7/8Er1798bdlxsHXvL48WP8+++/6NevHxwdHTOso1BkfamnmJgYNGzYEJUrV8aJEyewbds2REVFoV27dgCABw8eoEOHDujevTsuXbqEvXv3onXr1hBCIC0tDS1btkT9+vVx9uxZHDlyBL169TLq/rmSkNmqVauESqUSixYtEhcuXBA9e/YUrq6uIioqKsP6hw4dEkqlUkyZMkVcvHhRjBo1StjY2Ihz585l6X6xsbECgIiNjc3Ot6GXkqoRRYf9I4oO+0fEHTwmRJkyQkjLwgoxZIgQyckmuS8RkblJSkoSFy9eFElJSelf1P27mNGjWTPDug4OmdetX9+wrrt7xvWMFBISIpRKpXB0dBS2trYCgLCyshLr1q177XkfffSRGDJkiP64fv36ok6dOgZ1qlevLoYNGyaEEGL79u3C2tpa3Lt3T//61q1bBQCxYcMGIYQQ8+fPF25ubuLZs2f6Ops3bxZWVlYiMjJSH2/RokWFRqPR1yldurSoW7eu/jgtLU04OjqKP//8M8PYjx49KgCI9evXG5QXKFBAODo6CkdHR/Htt98KIYSIiIgQAMTp06f19Z4+fSoAiD179gghhJgwYYJo3LixwbXu3LkjAIjw8HBx8uRJAUDcvHkzXSyPHz8WAMTevXszjNUcve7nPau5h+xjyqZPn46ePXuiW7duAIB58+Zh8+bNWLRoEYYPH56u/q+//oomTZrgm2++AQBMmDABO3bswKxZszBv3rwcjT0jWiGgEFr0Or4e+aavAFJTAR8fYMkSadskIiICXup6S+fVfYMfPsy87quz3G/efOuQXtWgQQPMnTsXCQkJ+OWXX2BtbY02L7XiaTQaTJo0CWvWrMG9e/egVquRkpICh1cmbVWoUMHg2NvbGw+fv6dLly7B19cXPj4++tdr1qxpUP/SpUuoWLGiQetV7dq1odVqER4eDs/nw2DKlSsHq5c+D09PT7z33nv6Y6VSiQIFCujvnVXHjx+HVqtFp06dkJKSkuXzzpw5gz179iBfBi2V169fR+PGjdGoUSOUL18ewcHBaNy4Mdq2bQs3Nzfkz58fXbt2RXBwMD788EMEBQWhXbt28Pb2Nir23EbW7ku1Wo2TJ08i6KVkxcrKCkFBQThy5EiG5xw5csSgPgAEBwdnWj8lJQVxcXEGD1NKSElDyMl/MGJvKBSpqUCrVsDZs0zIiIhe5uiY+cPOLut17e2zVvetQnREiRIlULFiRSxatAjHjh3DwoUL9a9PnToVv/76K4YNG4Y9e/YgLCwMwcHBUKvVBtexsbExOFYoFNA+n6WfnTK6jzH3LlGiBBQKBcLDww3KixcvjhIlSsD+pc9al/wJ3XgdAKmpqQbnPXv2DM2bN0dYWJjBQzeGTqlUYseOHdi6dSvKli2LmTNnonTp0oiIiAAALF68GEeOHEGtWrWwevVqlCpVCkePHjXyU8ldZE3KoqOjodFo9Fm+jqenJyIjIzM8JzIy0qj6kydPhouLi/7h6+ubPcFn4nJkPNZWboILhUpDO3+BtGVSgQImvScREZmWlZUVRo4ciVGjRiHp+eSCQ4cOoUWLFvj8889RsWJFFC9eHFeuXDHqugEBAbhz5w4ePHigL3s18QgICMCZM2f0A+B197ayskLp0qXf4V0ZKlCgAD788EPMmjXL4F4ZKViwIAAYxP3yoH8AqFKlCi5cuAA/Pz+UKFHC4KFr9VMoFKhduzbGjRuH06dPQ6VSYcOGDfprVK5cGSNGjMDhw4fx3nvvYeXKldn0bs2TWQz0N6URI0YgNjZW/7hz545J71e7hDtC+9VH7J79sOr5BWDpgxKJiPKITz/9FEqlErNnzwYAlCxZEjt27MDhw4dx6dIl9O7dG1FGbpMXFBSEUqVKISQkBGfOnMGBAwfw3XffGdTp1KkT7OzsEBISgvPnz2PPnj346quv0Llz53SNFO9qzpw5SEtLQ7Vq1bB69WpcunQJ4eHhWL58OS5fvgzl865le3t7vP/++/jxxx9x6dIl7Nu3D6NGjTK4Vr9+/fDkyRN06NAB//33H65fv47t27ejW7du0Gg0OHbsGCZNmoQTJ07g9u3bWL9+PR49eoSAgABERERgxIgROHLkCG7duoV///0XV69eRUBAQLa+X3Mja1Lm7u4OpVKZ7oc4KioKXplsxO3l5WVUfVtbWzg7Oxs8TK26X37UKulh8vsQEVHOsba2Rv/+/TFlyhQkJCRg1KhRqFKlCoKDg/HBBx/Ay8sLLVu2NOqaVlZW2LBhA5KSklCjRg188cUXmDhxokEdBwcHbN++HU+ePEH16tXRtm1bNGrUCLNmzcrGdyfx9/fH6dOnERQUhBEjRqBixYqoVq0aZs6ciaFDh2LChAn6uosWLUJaWhqqVq2KgQMH4ocffjC4lo+PDw4dOgSNRoPGjRujfPnyGDhwIFxdXWFlZQVnZ2fs378fzZo1Q6lSpTBq1Cj8/PPPaNq0KRwcHHD58mW0adMGpUqVQq9evdCvXz/07t0729+zOVGIlzuEZRAYGIgaNWpg5syZAKTpwUWKFEH//v0zHOjfvn17JCYm4u+//9aX1apVCxUqVMjSQP+4uDi4uLggNjY2RxI0IqK8Kjk5GREREShWrBjsXh0nRmRhXvfzntXcQ/bZl4MHD0ZISAiqVauGGjVqYMaMGUhISNDPxuzSpQsKFSqEyZMnAwC+/vpr1K9fHz///DM++ugjrFq1CidOnMD8+fPlfBtERERE70T2pKx9+/Z49OgRRo8ejcjISFSqVAnbtm3T95Pfvn3bYIpvrVq1sHLlSowaNQojR45EyZIlsXHjRoNpv0RERES5jezdlzmN3ZdERDmD3ZeUl2RH96XFz74kIiIiyg2YlBERkUnlsQ4ZyqOy4+ecSRkREZmEbjX5xMREmSMhMj3dz/mruygYQ/aB/kREZJmUSiVcXV31ey06ODhAwQW1ycIIIZCYmIiHDx/C1dVVv8Du22BSRkREJqNb2NvYTbCJchtXV9dMF7LPKiZlRERkMgqFAt7e3vDw8Ei3YTWRpbCxsXmnFjIdJmVERGRySqUyW/5oEVkyDvQnIiIiMgNMyoiIiIjMAJMyIiIiIjOQ58aU6RZ3i4uLkzkSIiIiygt0OcebFpjNc0lZfHw8AMDX11fmSIiIiCgviY+Ph4uLS6av57kNybVaLe7fvw8nJyeTLWIYFxcHX19f3Llzh5uey4zfhXng92A++F2YB34P5iMnvgshBOLj4+Hj4wMrq8xHjuW5ljIrKysULlw4R+7l7OzMXzYzwe/CPPB7MB/8LswDvwfzYerv4nUtZDoc6E9ERERkBpiUEREREZkBJmUmYGtrizFjxsDW1lbuUPI8fhfmgd+D+eB3YR74PZgPc/ou8txAfyIiIiJzxJYyIiIiIjPApIyIiIjIDDApIyIiIjIDTMqIiIiIzACTsrc0e/Zs+Pn5wc7ODoGBgTh+/Phr669duxZlypSBnZ0dypcvjy1btuRQpJbPmO9iwYIFqFu3Ltzc3ODm5oagoKA3fneUNcb+TuisWrUKCoUCLVu2NG2AeYix30VMTAz69esHb29v2NraolSpUvw3KhsY+z3MmDEDpUuXhr29PXx9fTFo0CAkJyfnULSWa//+/WjevDl8fHygUCiwcePGN56zd+9eVKlSBba2tihRogRCQ0NNHicAQJDRVq1aJVQqlVi0aJG4cOGC6Nmzp3B1dRVRUVEZ1j906JBQKpViypQp4uLFi2LUqFHCxsZGnDt3LocjtzzGfhcdO3YUs2fPFqdPnxaXLl0SXbt2FS4uLuLu3bs5HLllMfZ70ImIiBCFChUSdevWFS1atMiZYC2csd9FSkqKqFatmmjWrJk4ePCgiIiIEHv37hVhYWE5HLllMfZ7WLFihbC1tRUrVqwQERERYvv27cLb21sMGjQohyO3PFu2bBHfffedWL9+vQAgNmzY8Nr6N27cEA4ODmLw4MHi4sWLYubMmUKpVIpt27aZPFYmZW+hRo0aol+/fvpjjUYjfHx8xOTJkzOs365dO/HRRx8ZlAUGBorevXubNM68wNjv4lVpaWnCyclJLFmyxFQh5glv8z2kpaWJWrVqiT/++EOEhIQwKcsmxn4Xc+fOFcWLFxdqtTqnQswTjP0e+vXrJxo2bGhQNnjwYFG7dm2TxpnXZCUp+/bbb0W5cuUMytq3by+Cg4NNGJmE3ZdGUqvVOHnyJIKCgvRlVlZWCAoKwpEjRzI858iRIwb1ASA4ODjT+pQ1b/NdvCoxMRGpqanInz+/qcK0eG/7PYwfPx4eHh7o0aNHToSZJ7zNd7Fp0ybUrFkT/fr1g6enJ9577z1MmjQJGo0mp8K2OG/zPdSqVQsnT57Ud3HeuHEDW7ZsQbNmzXIkZnpBzr/ZeW5D8ncVHR0NjUYDT09Pg3JPT09cvnw5w3MiIyMzrB8ZGWmyOPOCt/kuXjVs2DD4+Pik+wWkrHub7+HgwYNYuHAhwsLCciDCvONtvosbN25g9+7d6NSpE7Zs2YJr166hb9++SE1NxZgxY3IibIvzNt9Dx44dER0djTp16kAIgbS0NHz55ZcYOXJkToRML8nsb3ZcXBySkpJgb29vsnuzpYzyrB9//BGrVq3Chg0bYGdnJ3c4eUZ8fDw6d+6MBQsWwN3dXe5w8jytVgsPDw/Mnz8fVatWRfv27fHdd99h3rx5coeWp+zduxeTJk3CnDlzcOrUKaxfvx6bN2/GhAkT5A6NchBbyozk7u4OpVKJqKgog/KoqCh4eXlleI6Xl5dR9Slr3ua70Jk2bRp+/PFH7Ny5ExUqVDBlmBbP2O/h+vXruHnzJpo3b64v02q1AABra2uEh4fD39/ftEFbqLf5nfD29oaNjQ2USqW+LCAgAJGRkVCr1VCpVCaN2RK9zffw/fffo3Pnzvjiiy8AAOXLl0dCQgJ69eqF7777DlZWbEPJKZn9zXZ2djZpKxnAljKjqVQqVK1aFbt27dKXabVa7Nq1CzVr1szwnJo1axrUB4AdO3ZkWp+y5m2+CwCYMmUKJkyYgG3btqFatWo5EapFM/Z7KFOmDM6dO4ewsDD945NPPkGDBg0QFhYGX1/fnAzforzN70Tt2rVx7do1fWIMAFeuXIG3tzcTsrf0Nt9DYmJiusRLlygLblGdo2T9m23yqQQWaNWqVcLW1laEhoaKixcvil69eglXV1cRGRkphBCic+fOYvjw4fr6hw4dEtbW1mLatGni0qVLYsyYMVwSI5sY+138+OOPQqVSiXXr1okHDx7oH/Hx8XK9BYtg7PfwKs6+zD7Gfhe3b98WTk5Oon///iI8PFz8888/wsPDQ/zwww9yvQWLYOz3MGbMGOHk5CT+/PNPcePGDfHvv/8Kf39/0a5dO7negsWIj48Xp0+fFqdPnxYAxPTp08Xp06fFrVu3hBBCDB8+XHTu3FlfX7ckxjfffCMuXbokZs+ezSUxzN3MmTNFkSJFhEqlEjVq1BBHjx7Vv1a/fn0REhJiUH/NmjWiVKlSQqVSiXLlyonNmzfncMSWy5jvomjRogJAuseYMWNyPnALY+zvxMuYlGUvY7+Lw4cPi8DAQGFrayuKFy8uJk6cKNLS0nI4astjzPeQmpoqxo4dK/z9/YWdnZ3w9fUVffv2FU+fPs35wC3Mnj17Mvx3X/f5h4SEiPr166c7p1KlSkKlUonixYuLxYsX50isCiHYLkpEREQkN44pIyIiIjIDTMqIiIiIzACTMiIiIiIzwKSMiIiIyAwwKSMiIiIyA0zKiIiIiMwAkzIiIiIiM8CkjIiIiMgMMCkjohwTGhoKV1dXucN4awqFAhs3bnxtna5du6Jly5Y5Eg8RWRYmZURklK5du0KhUKR7XLt2Te7QEBoaqo/HysoKhQsXRrdu3fDw4cNsuf6DBw/QtGlTAMDNmzehUCgQFhZmUOfXX39FaGhottwvM2PHjtW/T6VSCV9fX/Tq1QtPnjwx6jpMIInMi7XcARBR7tOkSRMsXrzYoKxgwYIyRWPI2dkZ4eHh0Gq1OHPmDLp164b79+9j+/bt73xtLy+vN9ZxcXF55/tkRbly5bBz505oNBpcunQJ3bt3R2xsLFavXp0j9yei7MeWMiIymq2tLby8vAweSqUS06dPR/ny5eHo6AhfX1/07dsXz549y/Q6Z86cQYMGDeDk5ARnZ2dUrVoVJ06c0L9+8OBB1K1bF/b29vD19cWAAQOQkJDw2tgUCgW8vLzg4+ODpk2bYsCAAdi5cyeSkpKg1Woxfvx4FC5cGLa2tqhUqRK2bdumP1etVqN///7w9vaGnZ0dihYtismTJxtcW9d9WaxYMQBA5cqVoVAo8MEHHwAwbH2aP38+fHx8oNVqDWJs0aIFunfvrj/+66+/UKVKFdjZ2aF48eIYN24c0tLSXvs+ra2t4eXlhUKFCiEoKAiffvopduzYoX9do9GgR48eKFasGOzt7VG6dGn8+uuv+tfHjh2LJUuW4K+//tK3uu3duxcAcOfOHbRr1w6urq7Inz8/WrRogZs3b742HiJ6d0zKiCjbWFlZ4bfffsOFCxewZMkS7N69G99++22m9Tt16oTChQvjv//+w8mTJzF8+HDY2NgAAK5fv44mTZqgTZs2OHv2LFavXo2DBw+if//+RsVkb28PrVaLtLQ0/Prrr/j5558xbdo0nD17FsHBwfjkk09w9epVAMBvv/2GTZs2Yc2aNQgPD8eKFSvg5+eX4XWPHz8OANi5cycePHiA9evXp6vz6aef4vHjx9izZ4++7MmTJ9i2bRs6deoEADhw4AC6dOmCr7/+GhcvXsTvv/+O0NBQTJw4Mcvv8ebNm9i+fTtUKpW+TKvVonDhwli7di0uXryI0aNHY+TIkVizZg0AYOjQoWjXrh2aNGmCBw8e4MGDB6hVqxZSU1MRHBwMJycnHDhwAIcOHUK+fPnQpEkTqNXqLMdERG9BEBEZISQkRCiVSuHo6Kh/tG3bNsO6a9euFQUKFNAfL168WLi4uOiPnZycRGhoaIbn9ujRQ/Tq1cug7MCBA8LKykokJSVleM6r179y5YooVaqUqFatmhBCCB8fHzFx4kSDc6pXry769u0rhBDiq6++Eg0bNhRarTbD6wMQGzZsEEIIERERIQCI06dPG9QJCQkRLVq00B+3aNFCdO/eXX/8+++/Cx8fH6HRaIQQQjRq1EhMmjTJ4BrLli0T3t7eGcYghBBjxowRVlZWwtHRUdjZ2QkAAoCYPn16pucIIUS/fv1EmzZtMo1Vd+/SpUsbfAYpKSnC3t5ebN++/bXXJ6J3wzFlRGS0Bg0aYO7cufpjR0dHAFKr0eTJk3H58mXExcUhLS0NycnJSExMhIODQ7rrDB48GF988QWWLVum74Lz9/cHIHVtnj17FitWrNDXF0JAq9UiIiICAQEBGcYWGxuLfPnyQavVIjk5GXXq1MEff/yBuLg43L9/H7Vr1zaoX7t2bZw5cwaA1PX44YcfonTp0mjSpAk+/vhjNG7c+J0+q06dOqFnz56YM2cObG1tsWLFCnz22WewsrLSv89Dhw4ZtIxpNJrXfm4AULp0aWzatAnJyclYvnw5wsLC8NVXXxnUmT17NhYtWoTbt28jKSkJarUalSpVem28Z86cwbVr1+Dk5GRQnpycjOvXr7/FJ0BEWcWkjIiM5ujoiBIlShiU3bx5Ex9//DH69OmDiRMnIn/+/Dh48CB69OgBtVqdYXIxduxYdOzYEZs3b8bWrVsxZswYrFq1Cq1atcKzZ8/Qu3dvDBgwIN15RYoUyTQ2JycnnDp1ClZWVvD29oa9vT0AIC4u7o3vq0qVKoiIiMDWrVuxc+dOtGvXDkFBQVi3bt0bz81M8+bNIYTA5s2bUb16dRw4cAC//PKL/vVnz55h3LhxaN26dbpz7ezsMr2uSqXSfwc//vgjPvroI4wbNw4TJkwAAKxatQpDhw7Fzz//jJo1a8LJyQlTp07FsWPHXhvvs2fPULVqVYNkWMdcJnMQWSomZUSULU6ePAmtVouff/5Z3wqkG7/0OqVKlUKpUqUwaNAgdOjQAYsXL0arVq1QpUoVXLx4MV3y9yZWVlYZnuPs7AwfHx8cOnQI9evX15cfOnQINWrUMKjXvn17tG/fHm3btkWTJk3w5MkT5M+f3+B6uvFbGo3mtfHY2dmhdevWWLFiBa5du4bSpUujSpUq+terVKmC8PBwo9/nq0aNGoWGDRuiT58++vdZq1Yt9O3bV1/n1ZYulUqVLv4qVapg9erV8PDwgLOz8zvFRETG4UB/IsoWJUqUQGpqKmbOnIkbN25g2bJlmDdvXqb1k5KS0L9/f+zduxe3bt3CoUOH8N9//+m7JYcNG4bDhw+jf//+CAsLw9WrV/HXX38ZPdD/Zd988w1++uknrF69GuHh4Rg+fDjCwsLw9ddfAwCmT5+OP//8E5cvX8aVK1ewdu1aeHl5ZbjgrYeHB+zt7bFt2zZERUUhNjY20/t26tQJmzdvxqJFi/QD/HVGjx6NpUuXYty4cbhw4QIuXbqEVatWYdSoUUa9t5o1a6JChQqYNGkSAKBkyZI4ceIEtm/fjitXruD777/Hf//9Z3COn58fzp49i/DwcERHRyM1NRWdOnWCu7s7WrRogQMHDiAiIgJ79+7FgAEDcPfuXaNiIiLjMCkjomxRsWJFTJ8+HT/99BPee+89rFixwmA5iVcplUo8fvwYXbp0QalSpdCuXTs0bdoU48aNAwBUqFAB+/btw5UrV1C3bl1UrlwZo0ePho+Pz1vHOGDAAAwePBhDhgxB+fLlsW3bNmzatAklS5YEIHV9TpkyBdWqVUP16tVx8+ZNbNmyRd/y9zJra2v89ttv+P333+Hj44MWLVpket+GDRsif/78CA8PR8eOHQ1eCw4Oxj///IN///0X1atXx/vvv49ffvkFRYsWNfr9DRo0CH/88Qfu3LmD3r17o3Xr1mjfvj0CAwPx+PFjg1YzAOjZsydKly6NatWqoWDBgjh06BAcHBywf/9+FClSBK1bt0ZAQAB69OiB5ORktpwRmZhCCCHkDoKIiIgor2NLGREREZEZYFJGREREZAaYlBERERGZASZlRERERGaASRkRERGRGWBSRkRERGQGmJQRERERmQEmZURERERmgEkZERERkRlgUkZERERkBpiUEREREZmB/wP3sxkckmSO3gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6488\n",
      "Recall:    0.9042\n",
      "F1 Score:  0.7051\n",
      "OA:        0.9257\n",
      "AA:        0.9042\n",
      "correct0 = 761176\n",
      "correct1 = 25849\n",
      "Score: 787025/850212\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "scores = []\n",
    "\n",
    "groundtruth = []\n",
    "prediction = []\n",
    "y_probs = []\n",
    "\n",
    "\n",
    "if mode == \"test\":\n",
    "    for hsi_test in range(len(dataset)):\n",
    "        print(f\"tes: {hsi_test + 1}\")\n",
    "\n",
    "        hsi_prediction = []\n",
    "        hsi_yprobs = []\n",
    "        hsi_groundtruth = []\n",
    "\n",
    "\n",
    "        test_indices, test_gt, matrix, indices_0_shape, indices_1_shape = testWithDataset(hsi_test)\n",
    "\n",
    "        total = len(test_indices)\n",
    "        correct0 = 0\n",
    "        correct1 = 0\n",
    "\n",
    "        input_patches = []\n",
    "        true_labels = []\n",
    "\n",
    "        # Prepare all patches\n",
    "        for x_pos, y_pos in test_indices:\n",
    "            true_label = test_gt[x_pos][y_pos]\n",
    "\n",
    "            selected_rows = matrix[x_pos:x_pos + 2*half_patch + 1, :]\n",
    "            testing_patch = selected_rows[:, y_pos:y_pos + 2*half_patch + 1]\n",
    "\n",
    "            patch_tensor = torch.tensor(testing_patch, dtype=torch.float32)\n",
    "            patch_tensor = patch_tensor.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "            input_patches.append(patch_tensor)\n",
    "            true_labels.append(true_label)\n",
    "\n",
    "        input_patches = torch.cat(input_patches, dim=0)  # Shape: (N, C, H, W)\n",
    "        true_labels = torch.tensor(true_labels)\n",
    "\n",
    "        # Process in batches\n",
    "        for i in tqdm(range(0, total, batch_size), desc=\"Predicting\"):\n",
    "            batch = input_patches[i:i+batch_size]\n",
    "            labels = true_labels[i:i+batch_size]\n",
    "\n",
    "            groundtruth.append(labels)\n",
    "            \n",
    "\n",
    "            preds, postive_class_probs = predict_batch(saved_model, batch, device)\n",
    "\n",
    "            prediction.append(preds)\n",
    "            hsi_prediction.append(preds)\n",
    "\n",
    "            hsi_yprobs.append(postive_class_probs)\n",
    "            y_probs.append(postive_class_probs)\n",
    "\n",
    "            for j in range(len(preds)):\n",
    "                index = i + j\n",
    "                hsi_groundtruth.append(labels[j])\n",
    "                # print(f\"{index+1}: prediction = {preds[j]}, confidence: {confs[j]:.4f}, expected: {labels[j].item()}\")\n",
    "                if preds[j] == labels[j].item():\n",
    "                    if labels[j].item() == 0:\n",
    "                        correct0 += 1\n",
    "                    elif labels[j] == 1:\n",
    "                        correct1 += 1\n",
    "\n",
    "        performance_metrics = getScoreTest(hsi_prediction, hsi_yprobs, hsi_groundtruth) \n",
    "        correct = correct0 + correct1\n",
    "        print(f\"Score: {correct}/{total}\")\n",
    "        \n",
    "        score = {\n",
    "            'dataset': hsi_test,\n",
    "            'class0_size': indices_0_shape[0],\n",
    "            'class1_size': indices_1_shape[0],\n",
    "            'correct_0': correct0,\n",
    "            'correct_1': correct1,\n",
    "            'correct_total': correct,\n",
    "            'total': total,\n",
    "            'AUC': float(performance_metrics['AUC']),\n",
    "            'precision': float(performance_metrics['precision']),\n",
    "            'recall': float(performance_metrics['recall']),\n",
    "            'F1 Score': float(performance_metrics['F1 Score']),\n",
    "            'OA': float(performance_metrics['OA']),\n",
    "            'AA': float(performance_metrics['AA']),\n",
    "        }\n",
    "        scores.append(score)\n",
    "\n",
    "if mode == \"full\":\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    os.makedirs(f\"predictions/{timestamp}\", exist_ok=True)\n",
    "    for hsi_full in range(len(dataset)):\n",
    "        if hsi_full > 0:\n",
    "            break\n",
    "        print(f\"tes: {hsi_full}\")\n",
    "        # if hsi_full > 2:\n",
    "        #     break\n",
    "        print(f\"dataset: {hsi_full + 1}\")\n",
    "        hsi_prediction = []\n",
    "        hsi_yprobs = []\n",
    "        hsi_groundtruth = []\n",
    "\n",
    "        score = []\n",
    "        patch_size = 9\n",
    "        half_patch = patch_size // 2\n",
    "\n",
    "        data_sampler = None\n",
    "        batch_size = 64\n",
    "\n",
    "        correct0 = 0\n",
    "        correct1 = 0\n",
    "        matrix = []\n",
    "        gt = []\n",
    "        expected_patch_shape = []\n",
    "        dataset_patches = []\n",
    "        data_loader = []\n",
    "        patch_tensor = []\n",
    "        true_label = [] \n",
    "        x = []\n",
    "        y = []\n",
    "        pred_matrix = []\n",
    "\n",
    "        matrix, gt, indices_0_shape, indices_1_shape = testWithWholeDataset(hsi_full)\n",
    "        print(indices_0_shape[0])\n",
    "        print(indices_1_shape[0])\n",
    "\n",
    "        expected_patch_shape = (2 * half_patch + 1, 2 * half_patch + 1, matrix.shape[2])\n",
    "        dataset_patches = PatchDataset(matrix, gt, half_patch, expected_patch_shape)\n",
    "\n",
    "        if seeded_run:\n",
    "            g = torch.Generator()\n",
    "            g.manual_seed(seed)\n",
    "\n",
    "            data_loader = DataLoader(\n",
    "                dataset_patches,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,  # set to True if needed\n",
    "                num_workers=0,\n",
    "                pin_memory=True,\n",
    "                drop_last=False,\n",
    "                generator=g\n",
    "            )\n",
    "            print(\"generate data loader using seed\")\n",
    "        else:\n",
    "            data_loader = DataLoader(dataset_patches, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        patch_tensor, true_label, x, y = next(iter(data_loader))\n",
    "\n",
    "        print(patch_tensor.size())\n",
    "        print(true_label.size())\n",
    "        print(f\"data loader size: {len(data_loader)}\")\n",
    "\n",
    "        pred_matrix = np.full(gt.shape, -1, dtype=np.int32)\n",
    "        correct = 0\n",
    "\n",
    "        for input_batch, label_batch, x_batch, y_batch in tqdm(data_loader, desc=\"Predicting\"):\n",
    "\n",
    "\n",
    "            preds, confs = predict_batch(saved_model, input_batch, device)\n",
    "\n",
    "            hsi_prediction.append(preds)\n",
    "            prediction.append(preds)\n",
    "            hsi_yprobs.append(confs)\n",
    "            y_probs.append(confs)\n",
    "            \n",
    "            label_batch = label_batch.numpy()\n",
    "            x_batch = x_batch.numpy()\n",
    "            y_batch = y_batch.numpy()\n",
    "\n",
    "            for pred, label, x, y in zip(preds, label_batch, x_batch, y_batch):\n",
    "                hsi_groundtruth.append(label)\n",
    "                groundtruth.append(label)\n",
    "                pred_matrix[x - half_patch, y - half_patch] = pred\n",
    "                if pred == label:\n",
    "                    if label == 0:\n",
    "                        correct0 += 1\n",
    "                    elif label == 1:\n",
    "                        correct1 += 1\n",
    "\n",
    "        performance_metrics = getScore(hsi_prediction, hsi_yprobs, hsi_groundtruth)      \n",
    "            \n",
    "        correct = correct0+correct1\n",
    "        print(f\"correct0 = {correct0}\")\n",
    "        print(f\"correct1 = {correct1}\")\n",
    "        total = gt.shape[0] * gt.shape[1]\n",
    "        print(f\"Score: {correct}/{total}\")\n",
    "\n",
    "        score = {\n",
    "            'dataset': hsi_full,\n",
    "            'class0_size': indices_0_shape[0],\n",
    "            'class1_size': indices_1_shape[0],\n",
    "            'correct_0': correct0,\n",
    "            'correct_1': correct1,\n",
    "            'correct_total': correct,\n",
    "            'total': total,\n",
    "            'AUC': float(performance_metrics['AUC']),\n",
    "            'precision': float(performance_metrics['precision']),\n",
    "            'recall': float(performance_metrics['recall']),\n",
    "            'F1 Score': float(performance_metrics['F1 Score']),\n",
    "            'OA': float(performance_metrics['OA']),\n",
    "            'AA': float(performance_metrics['AA']),\n",
    "        }\n",
    "        # print(score)\n",
    "        scores.append(score)\n",
    "        # Save prediction matrix\n",
    "        # timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        np.save(f\"predictions/{timestamp}/results {hsi_full} MyMethod.npy\", pred_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3802cccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: 0\t 761176/820876\t 25849/29336\t 787025/850212\t 0.9256808890018019 0.9042043108528544\n",
      "dataset: 0\t AUC: 0.9687181750528855 precission: 0.64879707105889 recall: 0.9042043108528544 F1 SCore0.7050728804923161\n",
      "total: \t\t 761176/410438.0 \t 25849/14668.0 \t 787025/850212\n",
      "acc: 0.9256808890018019\n"
     ]
    }
   ],
   "source": [
    "all_correct = 0\n",
    "all_total = 0\n",
    "all_correct0 = 0\n",
    "all_correct1 = 0\n",
    "class0_total = 0\n",
    "class1_total = 0\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    dataset = score['dataset']\n",
    "    correct0 = score['correct_0']\n",
    "    correct1 = score['correct_1']\n",
    "    class0_size = score['class0_size']\n",
    "    class1_size = score['class1_size']\n",
    "    correct = score['correct_total']\n",
    "    total = score['total']\n",
    "    auc_score = score['AUC']\n",
    "    precission = score['precision']\n",
    "    recall = score['recall']\n",
    "    f1 = score['F1 Score']\n",
    "    oa = score['OA']\n",
    "    aa = score['AA']\n",
    "    \n",
    "    print(f\"dataset: {dataset}\\t\", f'{correct0}/{class0_size}\\t', f'{correct1}/{class1_size}\\t', f'{correct}/{total}\\t', f\"{oa}\", f\"{aa}\")\n",
    "\n",
    "    all_correct += correct\n",
    "    all_total += total\n",
    "    all_correct0 += correct0\n",
    "    all_correct1 += correct1\n",
    "    class0_total += class0_size\n",
    "    class1_total += class1_size\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    dataset = score['dataset']\n",
    "    correct0 = score['correct_0']\n",
    "    correct1 = score['correct_1']\n",
    "    class0_size = score['class0_size']\n",
    "    class1_size = score['class1_size']\n",
    "    correct = score['correct_total']\n",
    "    total = score['total']\n",
    "    auc_score = score['AUC']\n",
    "    precission = score['precision']\n",
    "    recall = score['recall']\n",
    "    f1 = score['F1 Score']\n",
    "    oa = score['OA']\n",
    "    aa = score['AA']\n",
    "    print(f\"dataset: {dataset}\\t\", f\"AUC: {auc_score}\", f\"precission: {precission}\", f\"recall: {recall}\", f\"F1 SCore{f1}\")\n",
    "\n",
    "print(f\"total: \\t\\t {all_correct0}/{class0_total/2} \\t {all_correct1}/{class1_total/2} \\t {all_correct}/{all_total}\")\n",
    "\n",
    "print(f\"acc: {all_correct/all_total}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c74a969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_total_score = {\n",
    "    'dataset': 'Total Dataset',\n",
    "    'correct_0': all_correct0,\n",
    "    'correct_1': all_correct1,\n",
    "    'class0_total': class0_total,\n",
    "    'class1_total': class1_total,\n",
    "    'correct_total': all_correct,\n",
    "    'total': all_total\n",
    "}\n",
    "\n",
    "scores.append(all_total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddab0694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850212\n",
      "850212\n",
      "850212\n"
     ]
    }
   ],
   "source": [
    "groundtruths = groundtruth\n",
    "groundtruth_in = []\n",
    "\n",
    "if mode == \"test\":\n",
    "    for x in groundtruths:\n",
    "        for y in x:\n",
    "            groundtruth_in.append(y)    \n",
    "\n",
    "if mode == \"full\":\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "predictions = prediction\n",
    "prediction_in = []\n",
    "\n",
    "for x in predictions:\n",
    "    for y in x:\n",
    "        prediction_in.append(y)\n",
    "\n",
    "\n",
    "y_prob_in = []\n",
    "\n",
    "for x in y_probs:\n",
    "    for y in x:\n",
    "        y_prob_in.append(y)\n",
    "\n",
    "print(len(groundtruth_in))\n",
    "print(len(prediction_in))\n",
    "print(len(y_prob_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e85a806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787025/850212\n"
     ]
    }
   ],
   "source": [
    "y_test = groundtruth_in\n",
    "y_pred = prediction_in\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for x, y in zip(y_test, y_pred):\n",
    "    total += 1\n",
    "    if x == y:\n",
    "        correct += 1\n",
    "\n",
    "print(f'{correct}/{total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a4761e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_test: [0 1]\n",
      "Sample y_pred values: [np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1)]\n"
     ]
    }
   ],
   "source": [
    "y_test_np = np.array([label.item() for label in y_test])\n",
    "# Ensure labels are binary (0 and 1)\n",
    "print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "# Check if y_pred is probability (float) or hard prediction (int)\n",
    "print(\"Sample y_pred values:\", y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29515cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(\n",
    "    {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Two Models')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6a288ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6488\n",
      "Recall:    0.9042\n",
      "F1 Score:  0.7051\n",
      "OA:        0.9257\n",
      "AA:        0.9042\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "# Precision, Recall, F1\n",
    "precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "# Overall Accuracy (OA)\n",
    "oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Average Accuracy (AA) — mean of per-class accuracies\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "aa = per_class_acc.mean()\n",
    "\n",
    "# Print all metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"OA:        {oa:.4f}\")\n",
    "print(f\"AA:        {aa:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8abb93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {\n",
    "    'AUC': float(roc_auc),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'F1 Score': float(f1),\n",
    "    'OA': float(oa),\n",
    "    'AA': float(aa),\n",
    "}\n",
    "result_json = {\n",
    "    'prediction' : scores,\n",
    "    'performance' : performance,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c0c5d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [{'dataset': 0, 'class0_size': 820876, 'class1_size': 29336, 'correct_0': 761176, 'correct_1': 25849, 'correct_total': 787025, 'total': 850212, 'AUC': 0.9687181750528855, 'precision': 0.64879707105889, 'recall': 0.9042043108528544, 'F1 Score': 0.7050728804923161, 'OA': 0.9256808890018019, 'AA': 0.9042043108528544}, {'dataset': 'Total Dataset', 'correct_0': 761176, 'correct_1': 25849, 'class0_total': 820876, 'class1_total': 29336, 'correct_total': 787025, 'total': 850212}], 'performance': {'AUC': 0.9687181750528855, 'precision': 0.64879707105889, 'recall': 0.9042043108528544, 'F1 Score': 0.7050728804923161, 'OA': 0.9256808890018019, 'AA': 0.9042043108528544}}\n",
      "JSON saved to results.json\n"
     ]
    }
   ],
   "source": [
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "print(result_json)\n",
    "\n",
    "with open(f\"performance/MyMethod {timestamp}_results.json\", \"w\") as f:\n",
    "    json.dump(result_json, f, indent=2)\n",
    "\n",
    "print(\"JSON saved to results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "901b6440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 293.8335 seconds\n",
      "predicting time: 644.3919 seconds\n",
      "Run time: 938.2254 seconds\n",
      "mode used: full\n",
      "finetune Parameter 15455618\n",
      "Pretrain Parameter 17819648\n",
      "saved_model for testing Parameter 15455618\n",
      "20250725_225946\n",
      "seet used: 10\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Train time: {train_time - start_time:.4f} seconds\")\n",
    "print(f\"predicting time: {end_time - train_time:.4f} seconds\")\n",
    "print(f\"Run time: {end_time - start_time:.4f} seconds\")\n",
    "print(f\"mode used: {mode}\")\n",
    "print(f\"finetune Parameter {finetune_parameter}\")\n",
    "print(f\"Pretrain Parameter {pretrain_parameters}\")\n",
    "print(f\"saved_model for testing Parameter {saved_model_parameters}\")\n",
    "print(timestamp)\n",
    "print(f\"seet used: {seed}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_repo_ta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

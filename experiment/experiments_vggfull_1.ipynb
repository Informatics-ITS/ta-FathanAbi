{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a5a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "GPU Name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from HSI_class import HSI\n",
    "import createSample as CS\n",
    "import augmentation as aug\n",
    "\n",
    "import simsiam.loader\n",
    "import random\n",
    "import zeroPadding\n",
    "start_time = time.time()\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "\n",
    "# If available, print the GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    \n",
    "sample_per_class = 5\n",
    "num_per_category_augment_1 = 10\n",
    "num_per_category_augment_2 = 10\n",
    "patch_size = 9\n",
    "n_category = 2\n",
    "band_size = 224\n",
    "base_encoder = 'vgg16'\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "batch_size = 20\n",
    "test_size = 0.5\n",
    "\n",
    "random_indices = 1\n",
    "\n",
    "seeded_run = True\n",
    "seed = 10\n",
    "\n",
    "mode = \"full\"\n",
    "project_path = r\"C:\\Users\\Asus TUF\\Documents\\code\\TA\"\n",
    "# project_path = r\"D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25da8a0f-8f90-4f9e-9a04-991692e9ebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed has been set\n",
      "seet used: 10\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # PyTorch determinism\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "if seeded_run:\n",
    "    set_seed(seed)\n",
    "    print(\"seed has been set\")\n",
    "    print(f\"seet used: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "578786fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM01.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM02.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM03.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM04.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM05.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM06.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM07.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM08.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM09.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM10.mat\n",
      "random: 1\n",
      "generating random indices\n",
      "hsi shape\n",
      "(1243, 684, 224)\n",
      "creating 5 Randomly chosen 0 indices:\n",
      "creating 5 Randomly chosen 1 indices:\n",
      "indices 0 used: [(np.int64(910), np.int64(192)), (np.int64(51), np.int64(255)), (np.int64(689), np.int64(202)), (np.int64(772), np.int64(547)), (np.int64(920), np.int64(471))]\n",
      "indices 1 used: [(np.int64(22), np.int64(455)), (np.int64(170), np.int64(145)), (np.int64(410), np.int64(233)), (np.int64(1055), np.int64(123)), (np.int64(469), np.int64(582))]\n",
      "number of element equal 0 5\n",
      "number of element equal 1 5\n",
      "x_train shape: (10, 9, 9, 224)\n",
      "y_train shape: (10,)\n",
      "hasil augmentasi 1 shape: (20, 9, 9, 224)\n",
      "label augmentai 1 shape: (20,)\n",
      "hasil augmentasi 2 shape: (20, 9, 9, 224)\n",
      "label augmentasi 2 shape: (20,)\n",
      "label augment:\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "hasil augmentasi gabungan untuk training: (40, 9, 9, 224)\n",
      "label augmentasi gabungan: (40,)\n",
      "Element 0 occurs 20 times.\n",
      "Element 1 occurs 20 times.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = rf\"{project_path}\\Hyperspectral oil spill detection datasets\"\n",
    "\n",
    "dataset = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if i > 9:\n",
    "        break\n",
    "    file_path = os.path.join(dataset_path, filename)\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        hsi = HSI(file_path)\n",
    "        dataset.append(hsi)\n",
    "    i += 1\n",
    "\n",
    "train_hsi = dataset[0]\n",
    "patch_size = patch_size\n",
    "half_patch = patch_size // 2\n",
    "sample_per_class = sample_per_class\n",
    "\n",
    "train_indices_0 = []\n",
    "train_indices_1 = []\n",
    "\n",
    "print(f\"random: {random_indices}\")\n",
    "\n",
    "if random_indices:\n",
    "    print(\"generating random indices\")\n",
    "    selected_patches_0, selected_patches_1, train_indices_0, train_indices_1 = CS.createSample(train_hsi, patch_size, sample_per_class)\n",
    "else:\n",
    "    print(\"using generated indices\")\n",
    "    train_indices_0 = [(np.int64(188), np.int64(124)), (np.int64(523), np.int64(150)), (np.int64(1003), np.int64(474)), (np.int64(616), np.int64(508)), (np.int64(905), np.int64(552))]\n",
    "    train_indices_1 = [(np.int64(106), np.int64(606)), (np.int64(297), np.int64(468)), (np.int64(926), np.int64(35)), (np.int64(536), np.int64(519)), (np.int64(508), np.int64(442))]\n",
    "\n",
    "    selected_patches_0, selected_patches_1 = CS.getSample(train_hsi, patch_size, sample_per_class, train_indices_0, train_indices_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_indices = train_indices_0 +  train_indices_1\n",
    "\n",
    "# Concatenating along axis 0\n",
    "x_train = np.concatenate((selected_patches_0, selected_patches_1), )\n",
    "\n",
    "y_train = np.array([])\n",
    "\n",
    "gt = train_hsi.gt\n",
    "for indice in train_indices:\n",
    "    # print(gt[indice[0]][indice[1]])\n",
    "    y_train = np.append(y_train, gt[indice[0]][indice[1]])\n",
    "\n",
    "count = np.count_nonzero(y_train == 0)  # Count elements equal to 0\n",
    "print(f'number of element equal 0 {count}')\n",
    "\n",
    "count = np.count_nonzero(y_train == 1)  # Count elements equal to 1\n",
    "print(f'number of element equal 1 {count}')\n",
    "\n",
    "# Print shape to verify\n",
    "print(f\"x_train shape: {x_train.shape}\")  # Expected output: (10, 9, 9, 224)\n",
    "print(f\"y_train shape: {y_train.shape}\") \n",
    "\n",
    "\n",
    "n_category = n_category\n",
    "band_size = band_size\n",
    "num_per_category_augment_1 = num_per_category_augment_1\n",
    "num_per_category_augment_2 = num_per_category_augment_2\n",
    "\n",
    "data_augment1, label_augment1 = aug.Augment_data(x_train, y_train, n_category, patch_size, band_size, num_per_category_augment_1)\n",
    "\n",
    "data_augment2, label_augment2 = aug.Augment_data2(x_train, y_train, n_category, patch_size, band_size, num_per_category_augment_2)\n",
    "\n",
    "print(f\"hasil augmentasi 1 shape: {data_augment1.shape}\")\n",
    "print(f\"label augmentai 1 shape: {label_augment1.shape}\")\n",
    "\n",
    "print(f\"hasil augmentasi 2 shape: {data_augment2.shape}\")\n",
    "print(f\"label augmentasi 2 shape: {label_augment2.shape}\")\n",
    "\n",
    "print(\"label augment:\")\n",
    "print(label_augment1)\n",
    "print(label_augment2)\n",
    "\n",
    "data_augment = np.concatenate((data_augment1, data_augment2))\n",
    "label_augment = np.concatenate((label_augment1, label_augment2))\n",
    "\n",
    "print(f\"hasil augmentasi gabungan untuk training: {data_augment.shape}\")\n",
    "print(f\"label augmentasi gabungan: {label_augment.shape}\")\n",
    "\n",
    "\n",
    "# Count occurrences of each unique element\n",
    "counts = np.bincount(label_augment)\n",
    "\n",
    "# Print results\n",
    "for i, count in enumerate(counts):\n",
    "    print(f\"Element {i} occurs {count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cab1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    \"\"\"\n",
    "    Build a SimSiam model.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_encoder, spectral_band, dim=2048, pred_dim=512):\n",
    "        \"\"\"\n",
    "        dim: feature dimension (default: 2048)\n",
    "        pred_dim: hidden dimension of the predictor (default: 512)\n",
    "        \"\"\"\n",
    "        super(SimSiam, self).__init__()\n",
    "\n",
    "        self.pre_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=224, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # Reduce to (256, 1, 1)\n",
    "        )\n",
    "        # Fully Connected Layer to reshape to (64, 56, 56)\n",
    "        self.fc = nn.Linear(256 * 1 * 1, 64 * 56 * 56)\n",
    "    \n",
    "        self.encoder = base_encoder(pretrained=True)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.encoder.features = nn.Sequential(*list(self.encoder.features.children())[1:])\n",
    "   \n",
    "       \n",
    "        self.encoder.classifier[1] = nn.BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "   \n",
    "        self.encoder.classifier[4] = nn.BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        # Modify the classifier to match the desired output dimensions\n",
    "        # self.encoder.classifier[0] = nn.Linear(512, 4096, bias=True)\n",
    "        self.encoder.classifier[6] = nn.Linear(4096, dim)\n",
    "        self.encoder.classifier[3] = nn.Linear(in_features=4096, out_features=4096, bias=False)\n",
    "        # # Fix: Get the correct input dimension from VGG16 classifier\n",
    "        prev_dim = self.encoder.classifier[3].out_features\n",
    "\n",
    "        # Fix: Assign modified layers to classifier instead of non-existing 'fc'\n",
    "        self.encoder.classifier[6] = nn.Sequential(\n",
    "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(prev_dim),\n",
    "                                        nn.ReLU(inplace=True), # first layer\n",
    "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(prev_dim),\n",
    "                                        nn.ReLU(inplace=True), # second layer\n",
    "                                        self.encoder.classifier[6],\n",
    "                                        nn.BatchNorm1d(dim, affine=False)) # output layer# output layer\n",
    "                                        \n",
    "        self.encoder.classifier[6][6].bias.requires_grad = False\n",
    "        # self.projector[6].bias.requires_grad = False\n",
    "\n",
    "        # build a 3-layer projector\n",
    "        # prev_dim = self.encoder.fc.weight.shape[1]\n",
    "        # self.encoder.fc = nn.Sequential(nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "        #                                 nn.BatchNorm1d(prev_dim),\n",
    "        #                                 nn.ReLU(inplace=True), # first layer\n",
    "        #                                 nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "        #                                 nn.BatchNorm1d(prev_dim),\n",
    "        #                                 nn.ReLU(inplace=True), # second layer\n",
    "        #                                 self.encoder.fc,\n",
    "        #                                 nn.BatchNorm1d(dim, affine=False)) # output layer\n",
    "        # self.encoder.fc[6].bias.requires_grad = False # hack: not use bias as it is followed by BN\n",
    "\n",
    "        # build a 2-layer predictor\n",
    "        self.predictor = nn.Sequential(nn.Linear(dim, pred_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(pred_dim),\n",
    "                                        nn.ReLU(inplace=True), # hidden layer\n",
    "                                        nn.Linear(pred_dim, dim)) # output layer\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            x1: first views of images\n",
    "            x2: second views of images\n",
    "        Output:\n",
    "            p1, p2, z1, z2: predictors and targets of the network\n",
    "            See Sec. 3 of https://arxiv.org/abs/2011.10566 for detailed notations\n",
    "        \"\"\"\n",
    "        x1 = self.pre_conv(x1)\n",
    "        x2 = self.pre_conv(x2)\n",
    "\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "\n",
    "        x1 = self.fc(x1)\n",
    "        x2 = self.fc(x2)\n",
    "\n",
    "        x1 = x1.view(x1.size(0), 64, 56, 56)\n",
    "        x2 = x2.view(x2.size(0), 64, 56, 56)\n",
    "       \n",
    "        z1 = self.encoder.features(x1) # NxC\n",
    "        z2 = self.encoder.features(x2) # NxC\n",
    "      \n",
    "\n",
    "        z1 = self.encoder.avgpool(z1)\n",
    "        z2 = self.encoder.avgpool(z2)\n",
    "\n",
    "\n",
    "        z1 = torch.flatten(z1, 1)\n",
    "        z2 = torch.flatten(z2, 1)\n",
    "   \n",
    "        z1 = self.encoder.classifier(z1)\n",
    "        z2 = self.encoder.classifier(z2)\n",
    "\n",
    "\n",
    "\n",
    "        p1 = self.predictor(z1) # NxC\n",
    "        p2 = self.predictor(z2) # NxC\n",
    "\n",
    "        return p1, p2, z1.detach(), z2.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4613ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'vgg16'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimSiam(\n",
      "  (pre_conv): Sequential(\n",
      "    (0): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=200704, bias=True)\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): ReLU(inplace=True)\n",
      "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU(inplace=True)\n",
      "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): ReLU(inplace=True)\n",
      "      (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (12): ReLU(inplace=True)\n",
      "      (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (14): ReLU(inplace=True)\n",
      "      (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (17): ReLU(inplace=True)\n",
      "      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (19): ReLU(inplace=True)\n",
      "      (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (26): ReLU(inplace=True)\n",
      "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (28): ReLU(inplace=True)\n",
      "      (29): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "      (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Sequential(\n",
      "        (0): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "        (7): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (predictor): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=512, bias=False)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  )\n",
      ")\n",
      "parameter 230467776\n"
     ]
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "\n",
    "# create model\n",
    "base_encoder = base_encoder\n",
    "print(\"=> creating model '{}'\".format(base_encoder))\n",
    "pretrain_model = SimSiam(models.__dict__[base_encoder],224)\n",
    "\n",
    "\n",
    "lr = 0.01\n",
    "init_lr = lr * batch_size / 256\n",
    "gpu = 0\n",
    "\n",
    "print(pretrain_model)\n",
    "pretrain_parameters = sum(p.numel() for p in pretrain_model.parameters())\n",
    "print(f\"parameter {pretrain_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07ffc071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 224, 9, 9])\n",
      "input2 shape: torch.Size([1, 224, 9, 9])\n",
      "p1 shape torch.Size([1, 2048]), p2 shape torch.Size([1, 2048])\n",
      "z1 shape torch.Size([1, 2048]), z2 shape torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "test = data_augment[0]\n",
    "input = torch.tensor(test).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "test2 = data_augment[1]\n",
    "test2 = torch.tensor(test2).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "input2 = test2\n",
    "\n",
    "\n",
    "print(f\"input shape: {input.shape}\")\n",
    "print(f\"input2 shape: {input2.shape}\")\n",
    "\n",
    "# Pass the input through the model\n",
    "pretrain_model.eval()\n",
    "p1, p2, z1, z2  = pretrain_model(input, input2)\n",
    "\n",
    "print(f\"p1 shape {p1.shape}, p2 shape {p2.shape}\")\n",
    "print(f\"z1 shape {z1.shape}, z2 shape {z2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0224d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(40, 9, 9, 224)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CosineSimilarity(dim=1).cuda(gpu)\n",
    "print(gpu)\n",
    "optim_params = pretrain_model.parameters()\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "optimizer = torch.optim.SGD(optim_params, init_lr,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "augmentation = [\n",
    "    transforms.RandomHorizontalFlip(),  # Flip along width\n",
    "    transforms.RandomVerticalFlip(),    # Flip along height\n",
    "    transforms.RandomRotation(20),      # Rotate image slightly\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize hyperspectral data\n",
    "]\n",
    "\n",
    "transform = simsiam.loader.TwoCropsTransform(transforms.Compose(augmentation))\n",
    "\n",
    "print(data_augment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd6786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([40, 224, 9, 9])\n",
      "generate data loader using seed\n",
      "bacth size: torch.Size([20, 224, 9, 9])\n",
      "length batch: 20\n",
      "Train loader size: 2\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (Tensor or list of Tensors): Preloaded images of shape (N, 9, 9, 224)\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.images = images  # Assuming it's a list or tensor\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img1 = self.transform(img)  # First augmentation\n",
    "            img2 = self.transform(img)  # Second augmentation\n",
    "        \n",
    "            return img1, img2  # Return both augmented versions\n",
    "        \n",
    "        return img, img  # If no transform is provided, return the original image twice\n",
    "\n",
    "\n",
    "# Example usage\n",
    "pretrain_preloaded_image = data_augment \n",
    "\n",
    "pretrain_X_train = torch.tensor(pretrain_preloaded_image)\n",
    "pretrain_X_train = pretrain_X_train.to(torch.float32)\n",
    "pretrain_X_train = pretrain_X_train.permute(0, 3, 1, 2)\n",
    "print(f\"X_train shape: {pretrain_X_train.shape}\")\n",
    "\n",
    "# Define transformations if needed\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),  # Example normalization\n",
    "])\n",
    "\n",
    "pretrain_train_dataset = CustomDataset(pretrain_X_train, transform=transform)\n",
    "\n",
    "train_sampler = None\n",
    "\n",
    "if seeded_run:\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    \n",
    "    pretrain_train_loader = DataLoader(\n",
    "        pretrain_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    print(\"generate data loader using seed\")\n",
    "else:\n",
    "    pretrain_train_loader = DataLoader(\n",
    "        pretrain_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(train_sampler is None),\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 7. Check Output\n",
    "\n",
    "batch1, batch2 = next(iter(pretrain_train_loader))\n",
    "\n",
    "print(f\"bacth size: {batch1.size()}\")\n",
    "print(f\"length batch: {len(batch1)}\")  # Should print 2 (Two transformed views per image)\n",
    "print(f\"Train loader size: {len(pretrain_train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c59999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if 'fix_lr' in param_group and param_group['fix_lr']:\n",
    "            param_group['lr'] = init_lr\n",
    "        else:\n",
    "            param_group['lr'] = cur_lr\n",
    "\n",
    "class Pretrain_AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "    \n",
    "\n",
    "class Pretrain_ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "    \n",
    "def pretrain_save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6abedcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_train(train_loader, model, criterion, optimizer, epoch, device):\n",
    "    batch_time = Pretrain_AverageMeter('Time', ':6.3f')\n",
    "    data_time = Pretrain_AverageMeter('Data', ':6.3f')\n",
    "    losses = Pretrain_AverageMeter('Loss', ':.4f')\n",
    "    progress = Pretrain_ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    for i, (images1, images2) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input1 = images1.to(device, non_blocking=True)\n",
    "        input2 = images2.to(device, non_blocking=True)\n",
    "\n",
    "        p1, p2, z1, z2 = model(x1=input1, x2=input2) \n",
    "        loss = -(criterion(p1, z2).mean() + criterion(p2, z1).mean()) * 0.5\n",
    "\n",
    "        losses.update(loss.item(), input1.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "    # Return average training loss for early stopping\n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1714672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch: [0][0/2]\tTime  3.257 ( 3.257)\tData  0.034 ( 0.034)\tLoss -0.0038 (-0.0038)\n",
      "Epoch 1: Average Training Loss: -0.004357\n",
      "✅ New best model saved with loss -0.004357\n",
      "Epoch: [1][0/2]\tTime  0.312 ( 0.312)\tData  0.014 ( 0.014)\tLoss -0.0015 (-0.0015)\n",
      "Epoch 2: Average Training Loss: -0.001618\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [2][0/2]\tTime  0.461 ( 0.461)\tData  0.041 ( 0.041)\tLoss 0.0034 (0.0034)\n",
      "Epoch 3: Average Training Loss: -0.000994\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [3][0/2]\tTime  0.490 ( 0.490)\tData  0.010 ( 0.010)\tLoss -0.0052 (-0.0052)\n",
      "Epoch 4: Average Training Loss: -0.005668\n",
      "✅ New best model saved with loss -0.005668\n",
      "Epoch: [4][0/2]\tTime  0.340 ( 0.340)\tData  0.008 ( 0.008)\tLoss -0.0068 (-0.0068)\n",
      "Epoch 5: Average Training Loss: -0.003658\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [5][0/2]\tTime  0.559 ( 0.559)\tData  0.053 ( 0.053)\tLoss -0.0071 (-0.0071)\n",
      "Epoch 6: Average Training Loss: -0.005909\n",
      "✅ New best model saved with loss -0.005909\n",
      "Epoch: [6][0/2]\tTime  0.297 ( 0.297)\tData  0.009 ( 0.009)\tLoss -0.0018 (-0.0018)\n",
      "Epoch 7: Average Training Loss: -0.000706\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [7][0/2]\tTime  0.585 ( 0.585)\tData  0.051 ( 0.051)\tLoss -0.0015 (-0.0015)\n",
      "Epoch 8: Average Training Loss: -0.003545\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [8][0/2]\tTime  0.462 ( 0.462)\tData  0.014 ( 0.014)\tLoss -0.0001 (-0.0001)\n",
      "Epoch 9: Average Training Loss: -0.001781\n",
      "❌ No improvement. Patience: 3/50\n",
      "Epoch: [9][0/2]\tTime  0.313 ( 0.313)\tData  0.016 ( 0.016)\tLoss -0.0106 (-0.0106)\n",
      "Epoch 10: Average Training Loss: -0.006292\n",
      "✅ New best model saved with loss -0.006292\n",
      "Epoch: [10][0/2]\tTime  0.335 ( 0.335)\tData  0.022 ( 0.022)\tLoss -0.0069 (-0.0069)\n",
      "Epoch 11: Average Training Loss: -0.007179\n",
      "✅ New best model saved with loss -0.007179\n",
      "Epoch: [11][0/2]\tTime  0.336 ( 0.336)\tData  0.008 ( 0.008)\tLoss -0.0020 (-0.0020)\n",
      "Epoch 12: Average Training Loss: -0.001095\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [12][0/2]\tTime  0.562 ( 0.562)\tData  0.033 ( 0.033)\tLoss -0.0036 (-0.0036)\n",
      "Epoch 13: Average Training Loss: -0.004913\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [13][0/2]\tTime  0.250 ( 0.250)\tData  0.008 ( 0.008)\tLoss -0.0069 (-0.0069)\n",
      "Epoch 14: Average Training Loss: -0.005477\n",
      "❌ No improvement. Patience: 3/50\n",
      "Epoch: [14][0/2]\tTime  0.368 ( 0.368)\tData  0.014 ( 0.014)\tLoss -0.0045 (-0.0045)\n",
      "Epoch 15: Average Training Loss: -0.003591\n",
      "❌ No improvement. Patience: 4/50\n",
      "Epoch: [15][0/2]\tTime  0.386 ( 0.386)\tData  0.013 ( 0.013)\tLoss -0.0093 (-0.0093)\n",
      "Epoch 16: Average Training Loss: -0.006711\n",
      "❌ No improvement. Patience: 5/50\n",
      "Epoch: [16][0/2]\tTime  0.223 ( 0.223)\tData  0.008 ( 0.008)\tLoss -0.0084 (-0.0084)\n",
      "Epoch 17: Average Training Loss: -0.004756\n",
      "❌ No improvement. Patience: 6/50\n",
      "Epoch: [17][0/2]\tTime  0.441 ( 0.441)\tData  0.009 ( 0.009)\tLoss -0.0094 (-0.0094)\n",
      "Epoch 18: Average Training Loss: -0.005757\n",
      "❌ No improvement. Patience: 7/50\n",
      "Epoch: [18][0/2]\tTime  0.283 ( 0.283)\tData  0.013 ( 0.013)\tLoss -0.0039 (-0.0039)\n",
      "Epoch 19: Average Training Loss: -0.004416\n",
      "❌ No improvement. Patience: 8/50\n",
      "Epoch: [19][0/2]\tTime  0.400 ( 0.400)\tData  0.008 ( 0.008)\tLoss -0.0059 (-0.0059)\n",
      "Epoch 20: Average Training Loss: -0.006231\n",
      "❌ No improvement. Patience: 9/50\n"
     ]
    }
   ],
   "source": [
    "# Early stopping parameters\n",
    "best_loss = float('inf')\n",
    "patience = 50  # Number of epochs to wait for improvement\n",
    "patience_counter = 0\n",
    "\n",
    "start_epoch = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "pretrain_model.to(device)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "filename = f\"{timestamp}_model.pth.tar\"\n",
    "filepath = f\"models/pretrain/{filename}\"\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    pretrain_adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "\n",
    "    # Train and get average loss\n",
    "    avg_loss = pretrain_train(pretrain_train_loader, pretrain_model, criterion, optimizer, epoch, device)\n",
    "    print(f\"Epoch {epoch + 1}: Average Training Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': 'vgg16',\n",
    "            'state_dict': pretrain_model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'best_loss': best_loss\n",
    "        }, filepath)\n",
    "\n",
    "        print(f\"✅ New best model saved with loss {best_loss:.6f}\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"❌ No improvement. Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d5f40d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain Parameter 230467776\n",
      "models\\pretrain\\20250726_121712_model.pth.tar\n"
     ]
    }
   ],
   "source": [
    "pretrain_parameters = sum(p.numel() for p in pretrain_model.parameters())\n",
    "print(f\"pretrain Parameter {pretrain_parameters}\")\n",
    "\n",
    "pretrained = rf'models\\pretrain\\{filename}'\n",
    "print(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32ba8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "\n",
    "class VGG16_HSI(nn.Module):\n",
    "    def __init__(self, num_classes=2, spectral_band=224):\n",
    "        super(VGG16_HSI, self).__init__()\n",
    "\n",
    "        self.pre_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=224, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "      \n",
    "        self.fc = nn.Linear(256 * 1 * 1, 64 * 56 * 56)\n",
    "    \n",
    "        self.encoder = vgg16(pretrained=True)\n",
    "\n",
    "        self.encoder.features = nn.Sequential(*list(self.encoder.features.children())[1:])\n",
    "   \n",
    "       \n",
    "        self.encoder.classifier[1] = nn.BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.encoder.classifier[3] = nn.Linear(in_features=4096, out_features=4096, bias=False)\n",
    "        self.encoder.classifier[4] = nn.BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        self.encoder.classifier[6] = nn.Linear(4096, 2048)\n",
    "\n",
    "\n",
    "        self.encoder.added_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=128, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3, inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=2, bias=True)\n",
    "        )   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_conv(x)  # Process hyperspectral input\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "\n",
    "        # print(f'after preconv {x.shape}')\n",
    "        x = self.fc(x)  # Fully connected layer\n",
    "        # print(f'after fc {x.shape}')\n",
    "        # Reshape to (batch_size, 64, 56, 56) before passing to VGG\n",
    "        x = x.view(x.size(0), 64, 56, 56)\n",
    "        # print(f'after reshape, before vgg second layer {x.shape}')\n",
    "\n",
    "        x = self.encoder.features(x)  # Pass to VGG-16\n",
    "        x = self.encoder.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.encoder.classifier(x)  # Final classification layer\n",
    "        x = self.encoder.added_classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee42b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: 0 for training\n",
      "=> creating model\n",
      "finetune_parameter 195059266\n",
      "VGG16_HSI(\n",
      "  (pre_conv): Sequential(\n",
      "    (0): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=200704, bias=True)\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): ReLU(inplace=True)\n",
      "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU(inplace=True)\n",
      "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): ReLU(inplace=True)\n",
      "      (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (12): ReLU(inplace=True)\n",
      "      (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (14): ReLU(inplace=True)\n",
      "      (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (17): ReLU(inplace=True)\n",
      "      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (19): ReLU(inplace=True)\n",
      "      (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (26): ReLU(inplace=True)\n",
      "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (28): ReLU(inplace=True)\n",
      "      (29): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "      (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gpu = 0\n",
    "\n",
    "print(\"Use GPU: {} for training\".format(gpu))\n",
    "\n",
    "print(\"=> creating model\")\n",
    "\n",
    "model_finetune = VGG16_HSI()\n",
    "finetune_parameter = sum(p.numel() for p in model_finetune.parameters())\n",
    "print(f\"finetune_parameter {finetune_parameter}\")\n",
    "\n",
    "print(model_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9fa84ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'models\\pretrain\\20250726_121712_model.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_3068\\2432251866.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_3068\\2432251866.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually loading parameters with remapping:\n",
      "\n",
      "✓ Loaded: pre_conv.0.weight → pre_conv.0.weight\n",
      "✓ Loaded: pre_conv.0.bias → pre_conv.0.bias\n",
      "✓ Loaded: pre_conv.2.weight → pre_conv.2.weight\n",
      "✓ Loaded: pre_conv.2.bias → pre_conv.2.bias\n",
      "✓ Loaded: pre_conv.2.running_mean → pre_conv.2.running_mean\n",
      "✓ Loaded: pre_conv.2.running_var → pre_conv.2.running_var\n",
      "✓ Loaded: pre_conv.2.num_batches_tracked → pre_conv.2.num_batches_tracked\n",
      "✓ Loaded: pre_conv.3.weight → pre_conv.3.weight\n",
      "✓ Loaded: pre_conv.3.bias → pre_conv.3.bias\n",
      "✓ Loaded: pre_conv.5.weight → pre_conv.5.weight\n",
      "✓ Loaded: pre_conv.5.bias → pre_conv.5.bias\n",
      "✓ Loaded: pre_conv.5.running_mean → pre_conv.5.running_mean\n",
      "✓ Loaded: pre_conv.5.running_var → pre_conv.5.running_var\n",
      "✓ Loaded: pre_conv.5.num_batches_tracked → pre_conv.5.num_batches_tracked\n",
      "✓ Loaded: fc.weight → fc.weight\n",
      "✓ Loaded: fc.bias → fc.bias\n",
      "✓ Loaded: encoder.features.1.weight → encoder.features.1.weight\n",
      "✓ Loaded: encoder.features.1.bias → encoder.features.1.bias\n",
      "✓ Loaded: encoder.features.4.weight → encoder.features.4.weight\n",
      "✓ Loaded: encoder.features.4.bias → encoder.features.4.bias\n",
      "✓ Loaded: encoder.features.6.weight → encoder.features.6.weight\n",
      "✓ Loaded: encoder.features.6.bias → encoder.features.6.bias\n",
      "✓ Loaded: encoder.features.9.weight → encoder.features.9.weight\n",
      "✓ Loaded: encoder.features.9.bias → encoder.features.9.bias\n",
      "✓ Loaded: encoder.features.11.weight → encoder.features.11.weight\n",
      "✓ Loaded: encoder.features.11.bias → encoder.features.11.bias\n",
      "✓ Loaded: encoder.features.13.weight → encoder.features.13.weight\n",
      "✓ Loaded: encoder.features.13.bias → encoder.features.13.bias\n",
      "✓ Loaded: encoder.features.16.weight → encoder.features.16.weight\n",
      "✓ Loaded: encoder.features.16.bias → encoder.features.16.bias\n",
      "✓ Loaded: encoder.features.18.weight → encoder.features.18.weight\n",
      "✓ Loaded: encoder.features.18.bias → encoder.features.18.bias\n",
      "✓ Loaded: encoder.features.20.weight → encoder.features.20.weight\n",
      "✓ Loaded: encoder.features.20.bias → encoder.features.20.bias\n",
      "✓ Loaded: encoder.features.23.weight → encoder.features.23.weight\n",
      "✓ Loaded: encoder.features.23.bias → encoder.features.23.bias\n",
      "✓ Loaded: encoder.features.25.weight → encoder.features.25.weight\n",
      "✓ Loaded: encoder.features.25.bias → encoder.features.25.bias\n",
      "✓ Loaded: encoder.features.27.weight → encoder.features.27.weight\n",
      "✓ Loaded: encoder.features.27.bias → encoder.features.27.bias\n",
      "✓ Loaded: encoder.classifier.0.weight → encoder.classifier.0.weight\n",
      "✓ Loaded: encoder.classifier.0.bias → encoder.classifier.0.bias\n",
      "✓ Loaded: encoder.classifier.1.weight → encoder.classifier.1.weight\n",
      "✓ Loaded: encoder.classifier.1.bias → encoder.classifier.1.bias\n",
      "✓ Loaded: encoder.classifier.1.running_mean → encoder.classifier.1.running_mean\n",
      "✓ Loaded: encoder.classifier.1.running_var → encoder.classifier.1.running_var\n",
      "✓ Loaded: encoder.classifier.1.num_batches_tracked → encoder.classifier.1.num_batches_tracked\n",
      "✓ Loaded: encoder.classifier.3.weight → encoder.classifier.3.weight\n",
      "✓ Loaded: encoder.classifier.4.weight → encoder.classifier.4.weight\n",
      "✓ Loaded: encoder.classifier.4.bias → encoder.classifier.4.bias\n",
      "✓ Loaded: encoder.classifier.4.running_mean → encoder.classifier.4.running_mean\n",
      "✓ Loaded: encoder.classifier.4.running_var → encoder.classifier.4.running_var\n",
      "✓ Loaded: encoder.classifier.4.num_batches_tracked → encoder.classifier.4.num_batches_tracked\n",
      "❌ Key not found in model: encoder.classifier.6.0.weight\n",
      "❌ Key not found in model: encoder.classifier.6.1.weight\n",
      "❌ Key not found in model: encoder.classifier.6.1.bias\n",
      "❌ Key not found in model: encoder.classifier.6.1.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.1.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.1.num_batches_tracked\n",
      "❌ Key not found in model: encoder.classifier.6.3.weight\n",
      "❌ Key not found in model: encoder.classifier.6.4.weight\n",
      "❌ Key not found in model: encoder.classifier.6.4.bias\n",
      "❌ Key not found in model: encoder.classifier.6.4.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.4.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.4.num_batches_tracked\n",
      "✓ Loaded: encoder.classifier.6.6.weight → encoder.classifier.6.weight\n",
      "✓ Loaded: encoder.classifier.6.6.bias → encoder.classifier.6.bias\n",
      "❌ Key not found in model: encoder.classifier.6.7.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.7.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.7.num_batches_tracked\n",
      "❌ Key not found in model: predictor.0.weight\n",
      "❌ Key not found in model: predictor.1.weight\n",
      "❌ Key not found in model: predictor.1.bias\n",
      "❌ Key not found in model: predictor.1.running_mean\n",
      "❌ Key not found in model: predictor.1.running_var\n",
      "❌ Key not found in model: predictor.1.num_batches_tracked\n",
      "❌ Key not found in model: predictor.3.weight\n",
      "❌ Key not found in model: predictor.3.bias\n",
      "\n",
      "=== Summary ===\n",
      "Total checkpoint keys: 78\n",
      "Successfully loaded: 55\n",
      "Missing keys in model: 23\n",
      "Shape mismatches: 0\n",
      "\n",
      "Missing keys:\n",
      "  encoder.classifier.6.0.weight\n",
      "  encoder.classifier.6.1.weight\n",
      "  encoder.classifier.6.1.bias\n",
      "  encoder.classifier.6.1.running_mean\n",
      "  encoder.classifier.6.1.running_var\n",
      "  encoder.classifier.6.1.num_batches_tracked\n",
      "  encoder.classifier.6.3.weight\n",
      "  encoder.classifier.6.4.weight\n",
      "  encoder.classifier.6.4.bias\n",
      "  encoder.classifier.6.4.running_mean\n",
      "  encoder.classifier.6.4.running_var\n",
      "  encoder.classifier.6.4.num_batches_tracked\n",
      "  encoder.classifier.6.7.running_mean\n",
      "  encoder.classifier.6.7.running_var\n",
      "  encoder.classifier.6.7.num_batches_tracked\n",
      "  predictor.0.weight\n",
      "  predictor.1.weight\n",
      "  predictor.1.bias\n",
      "  predictor.1.running_mean\n",
      "  predictor.1.running_var\n",
      "  predictor.1.num_batches_tracked\n",
      "  predictor.3.weight\n",
      "  predictor.3.bias\n",
      "=> loaded pre-trained model 'models\\pretrain\\20250726_121712_model.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "if pretrained:\n",
    "    if os.path.isfile(pretrained):\n",
    "        print(\"=> loading checkpoint '{}'\".format(pretrained))\n",
    "        checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
    "\n",
    "        checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
    "        pretrained_dict = checkpoint['state_dict']\n",
    "        finetune_model_dict = model_finetune.state_dict()\n",
    "\n",
    "        # Key remapping: map .6.6.weight → .6.weight and .6.6.bias → .6.bias\n",
    "        key_mapping = {\n",
    "            'encoder.classifier.6.6.weight': 'encoder.classifier.6.weight',\n",
    "            'encoder.classifier.6.6.bias': 'encoder.classifier.6.bias',\n",
    "        }\n",
    "\n",
    "        # Prepare containers\n",
    "        remapped_dict = {}\n",
    "        loaded_keys = []\n",
    "        shape_mismatches = []\n",
    "        missing_keys = []\n",
    "\n",
    "        print(\"Manually loading parameters with remapping:\\n\")\n",
    "\n",
    "        for k, v in pretrained_dict.items():\n",
    "            new_k = key_mapping.get(k, k)  # Remap if necessary\n",
    "            if new_k in finetune_model_dict:\n",
    "                if finetune_model_dict[new_k].shape == v.shape:\n",
    "                    remapped_dict[new_k] = v\n",
    "                    loaded_keys.append((k, new_k))\n",
    "                    print(f\"✓ Loaded: {k} → {new_k}\")\n",
    "                else:\n",
    "                    shape_mismatches.append((new_k, finetune_model_dict[new_k].shape, v.shape))\n",
    "                    print(f\"⚠️ Shape mismatch: {new_k} | model: {finetune_model_dict[new_k].shape} vs checkpoint: {v.shape}\")\n",
    "            else:\n",
    "                missing_keys.append(new_k)\n",
    "                print(f\"❌ Key not found in model: {new_k}\")\n",
    "\n",
    "        # Load state dict\n",
    "        model_finetune.load_state_dict(remapped_dict, strict=False)\n",
    "\n",
    "        # Summary\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(f\"Total checkpoint keys: {len(pretrained_dict)}\")\n",
    "        print(f\"Successfully loaded: {len(loaded_keys)}\")\n",
    "        print(f\"Missing keys in model: {len(missing_keys)}\")\n",
    "        print(f\"Shape mismatches: {len(shape_mismatches)}\")\n",
    "\n",
    "        if missing_keys:\n",
    "            print(\"\\nMissing keys:\")\n",
    "            for key in missing_keys:\n",
    "                print(f\"  {key}\")\n",
    "\n",
    "        if shape_mismatches:\n",
    "            print(\"\\nShape mismatches:\")\n",
    "            for key, model_shape, ckpt_shape in shape_mismatches:\n",
    "                print(f\"  {key} | model: {model_shape}, checkpoint: {ckpt_shape}\")\n",
    "\n",
    "  \n",
    "     \n",
    "\n",
    "        print(\"=> loaded pre-trained model '{}'\".format(pretrained))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(pretrained))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28417fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16_HSI(\n",
      "  (pre_conv): Sequential(\n",
      "    (0): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=200704, bias=True)\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): ReLU(inplace=True)\n",
      "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU(inplace=True)\n",
      "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): ReLU(inplace=True)\n",
      "      (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (12): ReLU(inplace=True)\n",
      "      (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (14): ReLU(inplace=True)\n",
      "      (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (17): ReLU(inplace=True)\n",
      "      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (19): ReLU(inplace=True)\n",
      "      (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (26): ReLU(inplace=True)\n",
      "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (28): ReLU(inplace=True)\n",
      "      (29): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "      (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "pre_conv.0.weight: requires_grad=True\n",
      "pre_conv.0.bias: requires_grad=True\n",
      "pre_conv.2.weight: requires_grad=True\n",
      "pre_conv.2.bias: requires_grad=True\n",
      "pre_conv.3.weight: requires_grad=True\n",
      "pre_conv.3.bias: requires_grad=True\n",
      "pre_conv.5.weight: requires_grad=True\n",
      "pre_conv.5.bias: requires_grad=True\n",
      "fc.weight: requires_grad=True\n",
      "fc.bias: requires_grad=True\n",
      "encoder.features.1.weight: requires_grad=False\n",
      "encoder.features.1.bias: requires_grad=False\n",
      "encoder.features.4.weight: requires_grad=False\n",
      "encoder.features.4.bias: requires_grad=False\n",
      "encoder.features.6.weight: requires_grad=False\n",
      "encoder.features.6.bias: requires_grad=False\n",
      "encoder.features.9.weight: requires_grad=False\n",
      "encoder.features.9.bias: requires_grad=False\n",
      "encoder.features.11.weight: requires_grad=False\n",
      "encoder.features.11.bias: requires_grad=False\n",
      "encoder.features.13.weight: requires_grad=False\n",
      "encoder.features.13.bias: requires_grad=False\n",
      "encoder.features.16.weight: requires_grad=False\n",
      "encoder.features.16.bias: requires_grad=False\n",
      "encoder.features.18.weight: requires_grad=False\n",
      "encoder.features.18.bias: requires_grad=False\n",
      "encoder.features.20.weight: requires_grad=False\n",
      "encoder.features.20.bias: requires_grad=False\n",
      "encoder.features.23.weight: requires_grad=False\n",
      "encoder.features.23.bias: requires_grad=False\n",
      "encoder.features.25.weight: requires_grad=False\n",
      "encoder.features.25.bias: requires_grad=False\n",
      "encoder.features.27.weight: requires_grad=False\n",
      "encoder.features.27.bias: requires_grad=False\n",
      "encoder.classifier.0.weight: requires_grad=False\n",
      "encoder.classifier.0.bias: requires_grad=False\n",
      "encoder.classifier.1.weight: requires_grad=False\n",
      "encoder.classifier.1.bias: requires_grad=False\n",
      "encoder.classifier.3.weight: requires_grad=False\n",
      "encoder.classifier.4.weight: requires_grad=False\n",
      "encoder.classifier.4.bias: requires_grad=False\n",
      "encoder.classifier.6.weight: requires_grad=False\n",
      "encoder.classifier.6.bias: requires_grad=False\n",
      "encoder.added_classifier.0.weight: requires_grad=True\n",
      "encoder.added_classifier.0.bias: requires_grad=True\n",
      "encoder.added_classifier.3.weight: requires_grad=True\n",
      "encoder.added_classifier.3.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for param in model_finetune.encoder.features.parameters():\n",
    "    param.requires_grad = False  # Freeze convolutional layers\n",
    "\n",
    "for param in model_finetune.encoder.classifier.parameters():\n",
    "    param.requires_grad = False  # Freeze all but the last FC layer\n",
    "\n",
    "\n",
    "print(model_finetune)\n",
    "# Check which layers are trainable\n",
    "for name, param in model_finetune.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5f67fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 224, 9, 9])\n",
      "input2 shape: torch.Size([1, 224, 9, 9])\n",
      "output shape torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "test = data_augment[0]\n",
    "test = torch.tensor(test).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "input = test\n",
    "\n",
    "\n",
    "test2 = data_augment[1]\n",
    "test2 = torch.tensor(test2).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "input2 = test2\n",
    "\n",
    "\n",
    "print(f\"input shape: {input.shape}\")\n",
    "print(f\"input2 shape: {input2.shape}\")\n",
    "\n",
    "# Pass the input through the model\n",
    "model_finetune.eval()\n",
    "output = model_finetune(input)\n",
    "\n",
    "print(f\"output shape {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7321178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_augment shape (40, 9, 9, 224)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 0\n",
    "\n",
    "init_lr = lr * batch_size / 256\n",
    "\n",
    "torch.cuda.set_device(gpu)\n",
    "model_finetune = model_finetune.cuda(gpu)\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "\n",
    "# optimize only the linear classifier\n",
    "parameters = list(filter(lambda p: p.requires_grad, model_finetune.parameters()))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(parameters, init_lr,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=weight_decay)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "\n",
    "print(f\"data_augment shape {data_augment.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d915ed95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune_X_train shape: torch.Size([40, 224, 9, 9])\n",
      "Train shape: torch.Size([20, 224, 9, 9]), Validation shape: torch.Size([20, 224, 9, 9])\n",
      "generate data loader using seed\n",
      "torch.Size([20])\n",
      "Train loader size: 1, Validation loader size: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Example usage\n",
    "class CustomDatasetFinetune(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (Tensor or list of Tensors): Preloaded images of shape (N, 9, 9, 224)\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.images = images  # Assuming it's a list or tensor\n",
    "        self.transform = transform\n",
    "        self.label = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img1 = self.transform(img)  # First augmentation\n",
    "        \n",
    "            return img1, label  # Return both augmented versions\n",
    "        \n",
    "        return img, label  # If no transform is provided, return the original image twice\n",
    "    \n",
    "finetune_preloaded_images = data_augment  \n",
    "finetune_X = torch.tensor(finetune_preloaded_images)\n",
    "finetune_X= finetune_X.to(torch.float32)\n",
    "finetune_X = finetune_X.permute(0, 3, 1, 2)\n",
    "print(f\"finetune_X_train shape: {finetune_X.shape}\")\n",
    "\n",
    "finetune_y = torch.tensor(label_augment)\n",
    "#\n",
    "# Define transformations if needed\n",
    "\n",
    "testSize = test_size\n",
    "finetune_X_train, finetune_X_val, finetune_y_train, finetune_y_val = train_test_split(finetune_X, finetune_y, test_size = testSize, random_state=seed, stratify=finetune_y)\n",
    "print(f\"Train shape: {finetune_X_train.shape}, Validation shape: {finetune_X_val.shape}\")\n",
    "\n",
    "finetune_train_dataset = CustomDatasetFinetune(finetune_X_train, finetune_y_train)\n",
    "finetune_val_dataset = CustomDatasetFinetune(finetune_X_val, finetune_y_val)\n",
    "\n",
    "train_sampler = None\n",
    "\n",
    "if seeded_run:\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    \n",
    "    finetune_train_loader = DataLoader(\n",
    "        finetune_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    finetune_val_loader = DataLoader(\n",
    "        finetune_val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    \n",
    "    print(\"generate data loader using seed\")\n",
    "else:\n",
    "    finetune_train_loader = DataLoader(finetune_train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=False)\n",
    "    finetune_val_loader = DataLoader(finetune_val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "# 7. Check Output\n",
    "\n",
    "batch1 = next(iter(finetune_train_loader))\n",
    "\n",
    "print(batch1[1].size())\n",
    "print(f\"Train loader size: {len(finetune_train_loader)}, Validation loader size: {len(finetune_val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b237e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = FinetuneAverageMeter('Time', ':6.3f')\n",
    "    data_time = FinetuneAverageMeter('Data', ':6.3f')\n",
    "    losses = FinetuneAverageMeter('Loss', ':.4e')\n",
    "    top1 = FinetuneAverageMeter('Acc@1', ':6.2f')\n",
    "    progress = FinetuneProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    \"\"\"\n",
    "    Switch to eval mode:\n",
    "    Under the protocol of linear classification on frozen features/models,\n",
    "    it is not legitimate to change any part of the pre-trained model.\n",
    "    BatchNorm in train mode may revise running mean/std (even if it receives\n",
    "    no gradient), which are part of the model parameters too.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        gpu = 0\n",
    "        images = images.cuda(gpu, non_blocking=True)\n",
    "        target = target.cuda(gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, = finetune_accuracy(output, target, topk=(1,))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        print_freq = 10\n",
    "        if i % print_freq == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "\n",
    "def finetune_validate(val_loader, model, criterion):\n",
    "    batch_time = FinetuneAverageMeter('Time', ':6.3f')\n",
    "    losses = FinetuneAverageMeter('Loss', ':.4e')\n",
    "    top1 = FinetuneAverageMeter('Acc@1', ':6.2f')\n",
    "  \n",
    "    progress = FinetuneProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "       \n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "      \n",
    "            gpu = 0\n",
    "            images = images.cuda(gpu, non_blocking=True)\n",
    "            target = target.cuda(gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, = finetune_accuracy(output, target, topk=(1,))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            # top5.update(acc5[0], images.size(0))\n",
    "            print(f\"in validation finction {acc1}\")\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            print_freq = 10\n",
    "            if i % print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def finetune_save_checkpoint(timestamp, epoch, state, is_best, filename='models/checkpoint.pth.tar'):\n",
    "    filename='models/finetune/{}_model.pth.tar'.format(timestamp)\n",
    "    torch.save(state, filename)\n",
    "    # if is_best:\n",
    "    #     shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "def finetune_sanity_check(state_dict, pretrained_weights):\n",
    "    \"\"\"\n",
    "    Linear classifier should not change any weights other than the linear layer.\n",
    "    This sanity check asserts nothing wrong happens (e.g., BN stats updated).\n",
    "    \"\"\"\n",
    "    print(\"=> loading '{}' for sanity check\".format(pretrained_weights))\n",
    "    checkpoint = torch.load(pretrained_weights, map_location=\"cpu\")\n",
    "    state_dict_pre = checkpoint['state_dict']\n",
    "\n",
    "    for k in list(state_dict.keys()):\n",
    "        # Ignore fc layer\n",
    "        if 'fc.weight' in k or 'fc.bias' in k:\n",
    "            continue\n",
    "\n",
    "        # Adjust key mapping to match checkpoint format\n",
    "        k_pre = k.replace('module.encoder.', '')  # Remove unnecessary prefix\n",
    "\n",
    "        # Skip missing keys\n",
    "        if k_pre not in state_dict_pre:\n",
    "            print(f\"Warning: {k_pre} not found in pretrained model. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Check if tensor shapes match before comparing values\n",
    "        if state_dict[k].shape != state_dict_pre[k_pre].shape:\n",
    "            print(f\"Warning: Shape mismatch for {k}: {state_dict[k].shape} vs {state_dict_pre[k_pre].shape}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Assert that the weights remain unchanged\n",
    "        assert ((state_dict[k].cpu() == state_dict_pre[k_pre]).all()), \\\n",
    "            '{} is changed in linear classifier training.'.format(k)\n",
    "\n",
    "    print(\"=> sanity check passed.\")\n",
    "\n",
    "\n",
    "\n",
    "class FinetuneAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class FinetuneProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def finetune_adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = cur_lr\n",
    "\n",
    "\n",
    "def finetune_accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8982a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_conv.0.weight: requires_grad=True\n",
      "pre_conv.0.bias: requires_grad=True\n",
      "pre_conv.2.weight: requires_grad=True\n",
      "pre_conv.2.bias: requires_grad=True\n",
      "pre_conv.3.weight: requires_grad=True\n",
      "pre_conv.3.bias: requires_grad=True\n",
      "pre_conv.5.weight: requires_grad=True\n",
      "pre_conv.5.bias: requires_grad=True\n",
      "fc.weight: requires_grad=True\n",
      "fc.bias: requires_grad=True\n",
      "encoder.features.1.weight: requires_grad=False\n",
      "encoder.features.1.bias: requires_grad=False\n",
      "encoder.features.4.weight: requires_grad=False\n",
      "encoder.features.4.bias: requires_grad=False\n",
      "encoder.features.6.weight: requires_grad=False\n",
      "encoder.features.6.bias: requires_grad=False\n",
      "encoder.features.9.weight: requires_grad=False\n",
      "encoder.features.9.bias: requires_grad=False\n",
      "encoder.features.11.weight: requires_grad=False\n",
      "encoder.features.11.bias: requires_grad=False\n",
      "encoder.features.13.weight: requires_grad=False\n",
      "encoder.features.13.bias: requires_grad=False\n",
      "encoder.features.16.weight: requires_grad=False\n",
      "encoder.features.16.bias: requires_grad=False\n",
      "encoder.features.18.weight: requires_grad=False\n",
      "encoder.features.18.bias: requires_grad=False\n",
      "encoder.features.20.weight: requires_grad=False\n",
      "encoder.features.20.bias: requires_grad=False\n",
      "encoder.features.23.weight: requires_grad=False\n",
      "encoder.features.23.bias: requires_grad=False\n",
      "encoder.features.25.weight: requires_grad=False\n",
      "encoder.features.25.bias: requires_grad=False\n",
      "encoder.features.27.weight: requires_grad=False\n",
      "encoder.features.27.bias: requires_grad=False\n",
      "encoder.classifier.0.weight: requires_grad=False\n",
      "encoder.classifier.0.bias: requires_grad=False\n",
      "encoder.classifier.1.weight: requires_grad=False\n",
      "encoder.classifier.1.bias: requires_grad=False\n",
      "encoder.classifier.3.weight: requires_grad=False\n",
      "encoder.classifier.4.weight: requires_grad=False\n",
      "encoder.classifier.4.bias: requires_grad=False\n",
      "encoder.classifier.6.weight: requires_grad=False\n",
      "encoder.classifier.6.bias: requires_grad=False\n",
      "encoder.added_classifier.0.weight: requires_grad=True\n",
      "encoder.added_classifier.0.bias: requires_grad=True\n",
      "encoder.added_classifier.3.weight: requires_grad=True\n",
      "encoder.added_classifier.3.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_finetune.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa72c1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/1]\tTime  0.300 ( 0.300)\tData  0.002 ( 0.002)\tLoss 6.8995e-01 (6.8995e-01)\tAcc@1  50.00 ( 50.00)\n",
      "in validation finction tensor([80.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.340 ( 0.340)\tLoss 6.4697e-01 (6.4697e-01)\tAcc@1  80.00 ( 80.00)\n",
      " * Acc@1 80.000\n",
      "✅ Epoch 1: New best Acc@1: 80.00. Model saved.\n",
      "Epoch: [1][0/1]\tTime  0.104 ( 0.104)\tData  0.000 ( 0.000)\tLoss 6.4713e-01 (6.4713e-01)\tAcc@1  85.00 ( 85.00)\n",
      "in validation finction tensor([65.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.052 ( 0.052)\tLoss 6.9156e-01 (6.9156e-01)\tAcc@1  65.00 ( 65.00)\n",
      " * Acc@1 65.000\n",
      "❌ Epoch 2: No improvement. Patience counter: 1/50\n",
      "Epoch: [2][0/1]\tTime  0.051 ( 0.051)\tData  0.002 ( 0.002)\tLoss 6.9816e-01 (6.9816e-01)\tAcc@1  60.00 ( 60.00)\n",
      "in validation finction tensor([50.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.032 ( 0.032)\tLoss 7.2805e-01 (7.2805e-01)\tAcc@1  50.00 ( 50.00)\n",
      " * Acc@1 50.000\n",
      "❌ Epoch 3: No improvement. Patience counter: 2/50\n",
      "Epoch: [3][0/1]\tTime  0.039 ( 0.039)\tData  0.002 ( 0.002)\tLoss 7.3669e-01 (7.3669e-01)\tAcc@1  50.00 ( 50.00)\n",
      "in validation finction tensor([55.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.036 ( 0.036)\tLoss 6.5787e-01 (6.5787e-01)\tAcc@1  55.00 ( 55.00)\n",
      " * Acc@1 55.000\n",
      "❌ Epoch 4: No improvement. Patience counter: 3/50\n",
      "Epoch: [4][0/1]\tTime  0.043 ( 0.043)\tData  0.004 ( 0.004)\tLoss 6.6917e-01 (6.6917e-01)\tAcc@1  50.00 ( 50.00)\n",
      "in validation finction tensor([50.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.037 ( 0.037)\tLoss 6.5714e-01 (6.5714e-01)\tAcc@1  50.00 ( 50.00)\n",
      " * Acc@1 50.000\n",
      "❌ Epoch 5: No improvement. Patience counter: 4/50\n",
      "Epoch: [5][0/1]\tTime  0.047 ( 0.047)\tData  0.002 ( 0.002)\tLoss 6.7618e-01 (6.7618e-01)\tAcc@1  50.00 ( 50.00)\n",
      "in validation finction tensor([85.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.038 ( 0.038)\tLoss 5.6115e-01 (5.6115e-01)\tAcc@1  85.00 ( 85.00)\n",
      " * Acc@1 85.000\n",
      "✅ Epoch 6: New best Acc@1: 85.00. Model saved.\n",
      "Epoch: [6][0/1]\tTime  0.085 ( 0.085)\tData  0.000 ( 0.000)\tLoss 5.8725e-01 (5.8725e-01)\tAcc@1  75.00 ( 75.00)\n",
      "in validation finction tensor([90.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.045 ( 0.045)\tLoss 4.8842e-01 (4.8842e-01)\tAcc@1  90.00 ( 90.00)\n",
      " * Acc@1 90.000\n",
      "✅ Epoch 7: New best Acc@1: 90.00. Model saved.\n",
      "Epoch: [7][0/1]\tTime  0.062 ( 0.062)\tData  0.000 ( 0.000)\tLoss 5.0958e-01 (5.0958e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([95.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.036 ( 0.036)\tLoss 3.3196e-01 (3.3196e-01)\tAcc@1  95.00 ( 95.00)\n",
      " * Acc@1 95.000\n",
      "✅ Epoch 8: New best Acc@1: 95.00. Model saved.\n",
      "Epoch: [8][0/1]\tTime  0.047 ( 0.047)\tData  0.000 ( 0.000)\tLoss 3.7443e-01 (3.7443e-01)\tAcc@1  95.00 ( 95.00)\n",
      "in validation finction tensor([100.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.027 ( 0.027)\tLoss 2.0326e-01 (2.0326e-01)\tAcc@1 100.00 (100.00)\n",
      " * Acc@1 100.000\n",
      "✅ Epoch 9: New best Acc@1: 100.00. Model saved.\n",
      "Epoch: [9][0/1]\tTime  0.046 ( 0.046)\tData  0.002 ( 0.002)\tLoss 2.2343e-01 (2.2343e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([100.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.038 ( 0.038)\tLoss 1.1173e-01 (1.1173e-01)\tAcc@1 100.00 (100.00)\n",
      " * Acc@1 100.000\n",
      "❌ Epoch 10: No improvement. Patience counter: 1/50\n",
      "Epoch: [10][0/1]\tTime  0.041 ( 0.041)\tData  0.002 ( 0.002)\tLoss 1.2093e-01 (1.2093e-01)\tAcc@1 100.00 (100.00)\n",
      "in validation finction tensor([95.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.037 ( 0.037)\tLoss 1.0470e-01 (1.0470e-01)\tAcc@1  95.00 ( 95.00)\n",
      " * Acc@1 95.000\n",
      "❌ Epoch 11: No improvement. Patience counter: 2/50\n",
      "Epoch: [11][0/1]\tTime  0.055 ( 0.055)\tData  0.001 ( 0.001)\tLoss 1.6579e-01 (1.6579e-01)\tAcc@1  85.00 ( 85.00)\n",
      "in validation finction tensor([60.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.033 ( 0.033)\tLoss 9.3217e-01 (9.3217e-01)\tAcc@1  60.00 ( 60.00)\n",
      " * Acc@1 60.000\n",
      "❌ Epoch 12: No improvement. Patience counter: 3/50\n",
      "Epoch: [12][0/1]\tTime  0.043 ( 0.043)\tData  0.000 ( 0.000)\tLoss 9.9893e-01 (9.9893e-01)\tAcc@1  60.00 ( 60.00)\n",
      "in validation finction tensor([50.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.034 ( 0.034)\tLoss 2.3198e+00 (2.3198e+00)\tAcc@1  50.00 ( 50.00)\n",
      " * Acc@1 50.000\n",
      "❌ Epoch 13: No improvement. Patience counter: 4/50\n",
      "Epoch: [13][0/1]\tTime  0.035 ( 0.035)\tData  0.003 ( 0.003)\tLoss 2.3266e+00 (2.3266e+00)\tAcc@1  50.00 ( 50.00)\n",
      "in validation finction tensor([50.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.035 ( 0.035)\tLoss 1.8976e+00 (1.8976e+00)\tAcc@1  50.00 ( 50.00)\n",
      " * Acc@1 50.000\n",
      "❌ Epoch 14: No improvement. Patience counter: 5/50\n",
      "Epoch: [14][0/1]\tTime  0.041 ( 0.041)\tData  0.002 ( 0.002)\tLoss 1.9043e+00 (1.9043e+00)\tAcc@1  50.00 ( 50.00)\n",
      "in validation finction tensor([50.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.035 ( 0.035)\tLoss 1.1768e+00 (1.1768e+00)\tAcc@1  50.00 ( 50.00)\n",
      " * Acc@1 50.000\n",
      "❌ Epoch 15: No improvement. Patience counter: 6/50\n",
      "Epoch: [15][0/1]\tTime  0.033 ( 0.033)\tData  0.001 ( 0.001)\tLoss 1.1796e+00 (1.1796e+00)\tAcc@1  50.00 ( 50.00)\n",
      "in validation finction tensor([50.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.028 ( 0.028)\tLoss 7.5074e-01 (7.5074e-01)\tAcc@1  50.00 ( 50.00)\n",
      " * Acc@1 50.000\n",
      "❌ Epoch 16: No improvement. Patience counter: 7/50\n",
      "Epoch: [16][0/1]\tTime  0.046 ( 0.046)\tData  0.008 ( 0.008)\tLoss 7.4915e-01 (7.4915e-01)\tAcc@1  50.00 ( 50.00)\n",
      "in validation finction tensor([50.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.036 ( 0.036)\tLoss 7.1074e-01 (7.1074e-01)\tAcc@1  50.00 ( 50.00)\n",
      " * Acc@1 50.000\n",
      "❌ Epoch 17: No improvement. Patience counter: 8/50\n",
      "Epoch: [17][0/1]\tTime  0.066 ( 0.066)\tData  0.001 ( 0.001)\tLoss 7.1046e-01 (7.1046e-01)\tAcc@1  50.00 ( 50.00)\n",
      "in validation finction tensor([50.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.034 ( 0.034)\tLoss 7.4290e-01 (7.4290e-01)\tAcc@1  50.00 ( 50.00)\n",
      " * Acc@1 50.000\n",
      "❌ Epoch 18: No improvement. Patience counter: 9/50\n",
      "Epoch: [18][0/1]\tTime  0.042 ( 0.042)\tData  0.002 ( 0.002)\tLoss 7.4359e-01 (7.4359e-01)\tAcc@1  50.00 ( 50.00)\n",
      "in validation finction tensor([50.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.037 ( 0.037)\tLoss 7.5430e-01 (7.5430e-01)\tAcc@1  50.00 ( 50.00)\n",
      " * Acc@1 50.000\n",
      "❌ Epoch 19: No improvement. Patience counter: 10/50\n",
      "Epoch: [19][0/1]\tTime  0.044 ( 0.044)\tData  0.002 ( 0.002)\tLoss 7.5525e-01 (7.5525e-01)\tAcc@1  50.00 ( 50.00)\n",
      "in validation finction tensor([50.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.035 ( 0.035)\tLoss 7.5565e-01 (7.5565e-01)\tAcc@1  50.00 ( 50.00)\n",
      " * Acc@1 50.000\n",
      "❌ Epoch 20: No improvement. Patience counter: 11/50\n"
     ]
    }
   ],
   "source": [
    "best_acc1 = 0.0\n",
    "patience = 50  # Adjust as needed\n",
    "patience_counter = 0\n",
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "start_epoch = 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_finetune.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    finetune_adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "\n",
    "    # Train for one epoch\n",
    "    finetune_train(finetune_train_loader, model_finetune, criterion, optimizer, epoch)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    acc1 = finetune_validate(finetune_val_loader, model_finetune, criterion)\n",
    "\n",
    "    # Check if current accuracy is the best\n",
    "    is_best = acc1 > best_acc1\n",
    "\n",
    "    if is_best:\n",
    "        best_acc1 = acc1\n",
    "        patience_counter = 0\n",
    "\n",
    "        # Save best model only\n",
    "        finetune_save_checkpoint(timestamp, epoch, {\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': 'vgg16',\n",
    "            'state_dict': model_finetune.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best=True)\n",
    "\n",
    "        print(f\"✅ Epoch {epoch+1}: New best Acc@1: {best_acc1:.2f}. Model saved.\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"❌ Epoch {epoch+1}: No improvement. Patience counter: {patience_counter}/{patience}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"⏹️ Early stopping triggered at epoch {epoch+1}. Best Acc@1: {best_acc1:.2f}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "828ce5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250726_121712\n"
     ]
    }
   ],
   "source": [
    "train_time = time.time()\n",
    "\n",
    "\n",
    "print(timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c42bbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9859cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWithDataset(n): \n",
    "    hsi_test = dataset[n]\n",
    "\n",
    "    test_img = hsi_test.img\n",
    "    test_gt = hsi_test.gt\n",
    "\n",
    "    patch_size = 9\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    height = test_img.shape[0]\n",
    "    width = test_img.shape[1]\n",
    "\n",
    "    matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "    print(f\"img shape: {test_img.shape}\")\n",
    "    print(f\"img shape after padding {matrix.shape}\")\n",
    "    print(f\"number of pixel {width * height}\")\n",
    "\n",
    "    print(f\"ground truth shape: {test_gt.shape}\")\n",
    "\n",
    "    indices0 = np.argwhere(test_gt == 0)\n",
    "    indices1 = np.argwhere(test_gt == 1)\n",
    "\n",
    "    print(f\"indices = 0 shape: {indices0.shape}\")\n",
    "    print(f\"indices = 1 shape: {indices1.shape}\")\n",
    "\n",
    "    num_samples = 5000\n",
    "\n",
    "    random_indices0 = indices0[np.random.choice(len(indices0), num_samples, replace=False)]\n",
    "    random_indices1 = indices1[np.random.choice(len(indices1), num_samples, replace=False)]\n",
    "\n",
    "    test_indices = np.vstack((random_indices0, random_indices1))\n",
    "\n",
    "    print(test_indices.shape)\n",
    "\n",
    "    return test_indices, test_gt, matrix, random_indices0.shape, random_indices1.shape\n",
    "\n",
    "\n",
    "def testWithWholeDataset(n): \n",
    "    hsi_test = dataset[n]\n",
    "\n",
    "    test_img = hsi_test.img\n",
    "    gt= hsi_test.gt\n",
    "\n",
    "    patch_size = 9\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    height = test_img.shape[0]\n",
    "    width = test_img.shape[1]\n",
    "\n",
    "    matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "    print(f\"img shape: {test_img.shape}\")\n",
    "    print(f\"img shape after padding {matrix.shape}\")\n",
    "    print(f\"number of pixel {width * height}\")\n",
    "\n",
    "    print(f\"ground truth shape: {gt.shape}\")\n",
    "\n",
    "    indices0 = np.argwhere(gt == 0)\n",
    "    indices1 = np.argwhere(gt == 1)\n",
    "\n",
    "    print(f\"indices = 0 shape: {indices0.shape}\")\n",
    "    print(f\"indices = 1 shape: {indices1.shape}\")\n",
    "\n",
    "    return matrix, gt, indices0.shape, indices1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a0cfff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(model, batch_input, device):\n",
    "    model.eval()\n",
    "    batch_input = batch_input.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_input)\n",
    "        # Apply softmax to get class probabilities\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "        # Get predicted class (0 or 1)\n",
    "        predicted_classes = torch.argmax(probabilities, dim=1).cpu().numpy()\n",
    "\n",
    "        # Get probability of class 1 (positive class) — required for ROC\n",
    "        positive_class_probs = probabilities[:, 1].cpu().numpy()\n",
    "\n",
    "    \n",
    "\n",
    "    return predicted_classes, positive_class_probs\n",
    "\n",
    "\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, matrix, gt, half_patch, expected_shape):\n",
    "        self.matrix = matrix\n",
    "        self.gt = gt\n",
    "        self.half_patch = half_patch\n",
    "        self.expected_shape = expected_shape\n",
    "        self.size_x, self.size_y = matrix.shape[0], matrix.shape[1]\n",
    "        self.valid_coords = [\n",
    "            (x, y)\n",
    "            for x in range(half_patch, self.size_x - half_patch)\n",
    "            for y in range(half_patch, self.size_y - half_patch)\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.valid_coords[idx]\n",
    "        true_label = self.gt[x - self.half_patch, y - self.half_patch]\n",
    "\n",
    "        selected_rows = self.matrix[x- self.half_patch:x + 2 * self.half_patch + 1 - self.half_patch, :]\n",
    "        testing_patch = selected_rows[:, y - self.half_patch:y + 2 * self.half_patch + 1 - self.half_patch]\n",
    "\n",
    "        # Verify patch size\n",
    "        if testing_patch.shape != self.expected_shape:\n",
    "            raise ValueError(f\"Patch at ({x},{y}) has wrong shape {testing_patch.shape}\")\n",
    "\n",
    "        patch_tensor = torch.tensor(testing_patch, dtype=torch.float32)\n",
    "        patch_tensor = patch_tensor.permute(2, 0, 1)  # (C, H, W)\n",
    "\n",
    "        return patch_tensor, true_label, x, y  # Also return (x, y) for positioning later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "575b807c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\finetune\\20250726_121712_model.pth.tar\n",
      "Creating model 20250726_121712_model.pth.tar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_3068\\3084895309.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and moved to device\n",
      "saved_model for testing Parameter 195059266\n",
      "VGG16_HSI(\n",
      "  (pre_conv): Sequential(\n",
      "    (0): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=200704, bias=True)\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): ReLU(inplace=True)\n",
      "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU(inplace=True)\n",
      "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): ReLU(inplace=True)\n",
      "      (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (12): ReLU(inplace=True)\n",
      "      (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (14): ReLU(inplace=True)\n",
      "      (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (17): ReLU(inplace=True)\n",
      "      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (19): ReLU(inplace=True)\n",
      "      (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (26): ReLU(inplace=True)\n",
      "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (28): ReLU(inplace=True)\n",
      "      (29): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "      (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 64  # You can change this depending on your GPU capacity\n",
    "\n",
    "model_path = rf\"models\\finetune\\{timestamp}_model.pth.tar\"\n",
    "model_name = model_path.split('\\\\')[-1]\n",
    "print(model_path)\n",
    "\n",
    "print(f\"Creating model {model_name}...\")\n",
    "saved_model = VGG16_HSI().to(device)\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "saved_model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Model loaded and moved to device\")\n",
    "\n",
    "saved_model_parameters = sum(p.numel() for p in saved_model.parameters())\n",
    "print(f\"saved_model for testing Parameter {saved_model_parameters}\")\n",
    "print(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13871a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScoreTest(prediction, y_probs, groundtruth):\n",
    "    groundtruths = groundtruth\n",
    "    groundtruth_in = []\n",
    "\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "    predictions = prediction\n",
    "    prediction_in = []\n",
    "\n",
    "    for x in predictions:\n",
    "        for y in x:\n",
    "            prediction_in.append(y)\n",
    "\n",
    "\n",
    "    y_prob_in = []\n",
    "\n",
    "    for x in y_probs:\n",
    "        for y in x:\n",
    "            y_prob_in.append(y)\n",
    "\n",
    "    print(len(groundtruth_in))\n",
    "    print(len(prediction_in))\n",
    "    print(len(y_prob_in))\n",
    "\n",
    "    y_test = groundtruth_in\n",
    "    y_pred = prediction_in\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in zip(y_test, y_pred):\n",
    "        total += 1\n",
    "        if x == y:\n",
    "            correct += 1\n",
    "    \n",
    "    print(f'{correct}/{total}')\n",
    "\n",
    "    y_test_np = np.array([label.item() for label in y_test])\n",
    "    # Ensure labels are binary (0 and 1)\n",
    "    # print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "    # # Check if y_pred is probability (float) or hard prediction (int)\n",
    "    # print(\"Sample y_pred values:\", y_pred[:5])\n",
    "\n",
    "    test_df = pd.DataFrame(\n",
    "        {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Two Models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "    y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "    # Precision, Recall, F1\n",
    "    precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Overall Accuracy (OA)\n",
    "    oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Average Accuracy (AA) — mean of per-class accuracies\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    aa = per_class_acc.mean()\n",
    "\n",
    "    # Print all metrics\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"OA:        {oa:.4f}\")\n",
    "    print(f\"AA:        {aa:.4f}\")\n",
    "\n",
    "    performance = {\n",
    "        'AUC': float(roc_auc),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'F1 Score': float(f1),\n",
    "        'OA': float(oa),\n",
    "        'AA': float(aa),\n",
    "    }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a467139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(prediction, y_probs, groundtruth):\n",
    "    groundtruths = groundtruth\n",
    "    groundtruth_in = []\n",
    "\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "    predictions = prediction\n",
    "    prediction_in = []\n",
    "\n",
    "    for x in predictions:\n",
    "        for y in x:\n",
    "            prediction_in.append(y)\n",
    "\n",
    "\n",
    "    y_prob_in = []\n",
    "\n",
    "    for x in y_probs:\n",
    "        for y in x:\n",
    "            y_prob_in.append(y)\n",
    "\n",
    "    # print(len(groundtruth_in))\n",
    "    # print(len(prediction_in))\n",
    "    # print(len(y_prob_in))\n",
    "\n",
    "    y_test = groundtruth_in\n",
    "    y_pred = prediction_in\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in zip(y_test, y_pred):\n",
    "        total += 1\n",
    "        if x == y:\n",
    "            correct += 1\n",
    "    \n",
    "    print(f'{correct}/{total}')\n",
    "\n",
    "    y_test_np = np.array([label.item() for label in y_test])\n",
    "    # Ensure labels are binary (0 and 1)\n",
    "    # print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "    # # Check if y_pred is probability (float) or hard prediction (int)\n",
    "    # print(\"Sample y_pred values:\", y_pred[:5])\n",
    "\n",
    "    test_df = pd.DataFrame(\n",
    "        {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Two Models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "    y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "    # Precision, Recall, F1\n",
    "    precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Overall Accuracy (OA)\n",
    "    oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Average Accuracy (AA) — mean of per-class accuracies\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    aa = per_class_acc.mean()\n",
    "\n",
    "    # Print all metrics\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"OA:        {oa:.4f}\")\n",
    "    print(f\"AA:        {aa:.4f}\")\n",
    "\n",
    "    performance = {\n",
    "        'AUC': float(roc_auc),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'F1 Score': float(f1),\n",
    "        'OA': float(oa),\n",
    "        'AA': float(aa),\n",
    "    }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9ae6c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tes: 0\n",
      "dataset: 1\n",
      "img shape: (1243, 684, 224)\n",
      "img shape after padding (1251, 692, 224)\n",
      "number of pixel 850212\n",
      "ground truth shape: (1243, 684)\n",
      "indices = 0 shape: (820876, 2)\n",
      "indices = 1 shape: (29336, 2)\n",
      "820876\n",
      "29336\n",
      "generate data loader using seed\n",
      "torch.Size([64, 224, 9, 9])\n",
      "torch.Size([64])\n",
      "data loader size: 13285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 13285/13285 [38:07<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764037/850212\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6218\n",
      "Recall:    0.9178\n",
      "F1 Score:  0.6673\n",
      "OA:        0.8986\n",
      "AA:        0.9178\n",
      "correct0 = 736507\n",
      "correct1 = 27530\n",
      "Score: 764037/850212\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "scores = []\n",
    "\n",
    "groundtruth = []\n",
    "prediction = []\n",
    "y_probs = []\n",
    "\n",
    "\n",
    "if mode == \"test\":\n",
    "    for hsi_test in range(len(dataset)):\n",
    "        print(f\"tes: {hsi_test + 1}\")\n",
    "\n",
    "        hsi_prediction = []\n",
    "        hsi_yprobs = []\n",
    "        hsi_groundtruth = []\n",
    "\n",
    "\n",
    "        test_indices, test_gt, matrix, indices_0_shape, indices_1_shape = testWithDataset(hsi_test)\n",
    "\n",
    "        total = len(test_indices)\n",
    "        correct0 = 0\n",
    "        correct1 = 0\n",
    "\n",
    "        input_patches = []\n",
    "        true_labels = []\n",
    "\n",
    "        # Prepare all patches\n",
    "        for x_pos, y_pos in test_indices:\n",
    "            true_label = test_gt[x_pos][y_pos]\n",
    "\n",
    "            selected_rows = matrix[x_pos:x_pos + 2*half_patch + 1, :]\n",
    "            testing_patch = selected_rows[:, y_pos:y_pos + 2*half_patch + 1]\n",
    "\n",
    "            patch_tensor = torch.tensor(testing_patch, dtype=torch.float32)\n",
    "            patch_tensor = patch_tensor.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "            input_patches.append(patch_tensor)\n",
    "            true_labels.append(true_label)\n",
    "\n",
    "        input_patches = torch.cat(input_patches, dim=0)  # Shape: (N, C, H, W)\n",
    "        true_labels = torch.tensor(true_labels)\n",
    "\n",
    "        # Process in batches\n",
    "        for i in tqdm(range(0, total, batch_size), desc=\"Predicting\"):\n",
    "            batch = input_patches[i:i+batch_size]\n",
    "            labels = true_labels[i:i+batch_size]\n",
    "\n",
    "            groundtruth.append(labels)\n",
    "            \n",
    "\n",
    "            preds, postive_class_probs = predict_batch(saved_model, batch, device)\n",
    "\n",
    "            prediction.append(preds)\n",
    "            hsi_prediction.append(preds)\n",
    "\n",
    "            hsi_yprobs.append(postive_class_probs)\n",
    "            y_probs.append(postive_class_probs)\n",
    "\n",
    "            for j in range(len(preds)):\n",
    "                index = i + j\n",
    "                hsi_groundtruth.append(labels[j])\n",
    "                # print(f\"{index+1}: prediction = {preds[j]}, confidence: {confs[j]:.4f}, expected: {labels[j].item()}\")\n",
    "                if preds[j] == labels[j].item():\n",
    "                    if labels[j].item() == 0:\n",
    "                        correct0 += 1\n",
    "                    elif labels[j] == 1:\n",
    "                        correct1 += 1\n",
    "\n",
    "        performance_metrics = getScoreTest(hsi_prediction, hsi_yprobs, hsi_groundtruth) \n",
    "        correct = correct0 + correct1\n",
    "        print(f\"Score: {correct}/{total}\")\n",
    "        \n",
    "        score = {\n",
    "            'dataset': hsi_test,\n",
    "            'class0_size': indices_0_shape[0],\n",
    "            'class1_size': indices_1_shape[0],\n",
    "            'correct_0': correct0,\n",
    "            'correct_1': correct1,\n",
    "            'correct_total': correct,\n",
    "            'total': total,\n",
    "            'AUC': float(performance_metrics['AUC']),\n",
    "            'precision': float(performance_metrics['precision']),\n",
    "            'recall': float(performance_metrics['recall']),\n",
    "            'F1 Score': float(performance_metrics['F1 Score']),\n",
    "            'OA': float(performance_metrics['OA']),\n",
    "            'AA': float(performance_metrics['AA']),\n",
    "        }\n",
    "        scores.append(score)\n",
    "\n",
    "if mode == \"full\":\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    os.makedirs(f\"predictions/{timestamp}\", exist_ok=True)\n",
    "    for hsi_full in range(len(dataset)):\n",
    "        if hsi_full > 0:\n",
    "            break\n",
    "        print(f\"tes: {hsi_full}\")\n",
    "        # if hsi_full > 2:\n",
    "        #     break\n",
    "        print(f\"dataset: {hsi_full + 1}\")\n",
    "        hsi_prediction = []\n",
    "        hsi_yprobs = []\n",
    "        hsi_groundtruth = []\n",
    "\n",
    "        score = []\n",
    "        patch_size = 9\n",
    "        half_patch = patch_size // 2\n",
    "\n",
    "        data_sampler = None\n",
    "        batch_size = 64\n",
    "\n",
    "        correct0 = 0\n",
    "        correct1 = 0\n",
    "        matrix = []\n",
    "        gt = []\n",
    "        expected_patch_shape = []\n",
    "        dataset_patches = []\n",
    "        data_loader = []\n",
    "        patch_tensor = []\n",
    "        true_label = [] \n",
    "        x = []\n",
    "        y = []\n",
    "        pred_matrix = []\n",
    "\n",
    "        matrix, gt, indices_0_shape, indices_1_shape = testWithWholeDataset(hsi_full)\n",
    "        print(indices_0_shape[0])\n",
    "        print(indices_1_shape[0])\n",
    "\n",
    "        expected_patch_shape = (2 * half_patch + 1, 2 * half_patch + 1, matrix.shape[2])\n",
    "        dataset_patches = PatchDataset(matrix, gt, half_patch, expected_patch_shape)\n",
    "\n",
    "        if seeded_run:\n",
    "            g = torch.Generator()\n",
    "            g.manual_seed(seed)\n",
    "\n",
    "            data_loader = DataLoader(\n",
    "                dataset_patches,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,  # set to True if needed\n",
    "                num_workers=0,\n",
    "                pin_memory=True,\n",
    "                drop_last=False,\n",
    "                generator=g\n",
    "            )\n",
    "            print(\"generate data loader using seed\")\n",
    "        else:\n",
    "            data_loader = DataLoader(dataset_patches, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        patch_tensor, true_label, x, y = next(iter(data_loader))\n",
    "\n",
    "        print(patch_tensor.size())\n",
    "        print(true_label.size())\n",
    "        print(f\"data loader size: {len(data_loader)}\")\n",
    "\n",
    "        pred_matrix = np.full(gt.shape, -1, dtype=np.int32)\n",
    "        correct = 0\n",
    "\n",
    "        for input_batch, label_batch, x_batch, y_batch in tqdm(data_loader, desc=\"Predicting\"):\n",
    "\n",
    "\n",
    "            preds, confs = predict_batch(saved_model, input_batch, device)\n",
    "\n",
    "            hsi_prediction.append(preds)\n",
    "            prediction.append(preds)\n",
    "            hsi_yprobs.append(confs)\n",
    "            y_probs.append(confs)\n",
    "            \n",
    "            label_batch = label_batch.numpy()\n",
    "            x_batch = x_batch.numpy()\n",
    "            y_batch = y_batch.numpy()\n",
    "\n",
    "            for pred, label, x, y in zip(preds, label_batch, x_batch, y_batch):\n",
    "                hsi_groundtruth.append(label)\n",
    "                groundtruth.append(label)\n",
    "                pred_matrix[x - half_patch, y - half_patch] = pred\n",
    "                if pred == label:\n",
    "                    if label == 0:\n",
    "                        correct0 += 1\n",
    "                    elif label == 1:\n",
    "                        correct1 += 1\n",
    "\n",
    "        performance_metrics = getScore(hsi_prediction, hsi_yprobs, hsi_groundtruth)      \n",
    "            \n",
    "        correct = correct0+correct1\n",
    "        print(f\"correct0 = {correct0}\")\n",
    "        print(f\"correct1 = {correct1}\")\n",
    "        total = gt.shape[0] * gt.shape[1]\n",
    "        print(f\"Score: {correct}/{total}\")\n",
    "\n",
    "        score = {\n",
    "            'dataset': hsi_full,\n",
    "            'class0_size': indices_0_shape[0],\n",
    "            'class1_size': indices_1_shape[0],\n",
    "            'correct_0': correct0,\n",
    "            'correct_1': correct1,\n",
    "            'correct_total': correct,\n",
    "            'total': total,\n",
    "            'AUC': float(performance_metrics['AUC']),\n",
    "            'precision': float(performance_metrics['precision']),\n",
    "            'recall': float(performance_metrics['recall']),\n",
    "            'F1 Score': float(performance_metrics['F1 Score']),\n",
    "            'OA': float(performance_metrics['OA']),\n",
    "            'AA': float(performance_metrics['AA']),\n",
    "        }\n",
    "        # print(score)\n",
    "        scores.append(score)\n",
    "        # Save prediction matrix\n",
    "        # timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        np.save(f\"predictions/{timestamp}/results {hsi_full} MyMethod.npy\", pred_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3802cccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: 0\t 736507/820876\t 27530/29336\t 764037/850212\t 0.8986429267053394 0.9178290943427124\n",
      "dataset: 0\t AUC: 0.9651216168641942 precission: 0.6217896583118702 recall: 0.9178290943427124 F1 SCore0.6672887959571911\n",
      "total: \t\t 736507/410438.0 \t 27530/14668.0 \t 764037/850212\n",
      "acc: 0.8986429267053394\n"
     ]
    }
   ],
   "source": [
    "all_correct = 0\n",
    "all_total = 0\n",
    "all_correct0 = 0\n",
    "all_correct1 = 0\n",
    "class0_total = 0\n",
    "class1_total = 0\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    dataset = score['dataset']\n",
    "    correct0 = score['correct_0']\n",
    "    correct1 = score['correct_1']\n",
    "    class0_size = score['class0_size']\n",
    "    class1_size = score['class1_size']\n",
    "    correct = score['correct_total']\n",
    "    total = score['total']\n",
    "    auc_score = score['AUC']\n",
    "    precission = score['precision']\n",
    "    recall = score['recall']\n",
    "    f1 = score['F1 Score']\n",
    "    oa = score['OA']\n",
    "    aa = score['AA']\n",
    "    \n",
    "    print(f\"dataset: {dataset}\\t\", f'{correct0}/{class0_size}\\t', f'{correct1}/{class1_size}\\t', f'{correct}/{total}\\t', f\"{oa}\", f\"{aa}\")\n",
    "\n",
    "    all_correct += correct\n",
    "    all_total += total\n",
    "    all_correct0 += correct0\n",
    "    all_correct1 += correct1\n",
    "    class0_total += class0_size\n",
    "    class1_total += class1_size\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    dataset = score['dataset']\n",
    "    correct0 = score['correct_0']\n",
    "    correct1 = score['correct_1']\n",
    "    class0_size = score['class0_size']\n",
    "    class1_size = score['class1_size']\n",
    "    correct = score['correct_total']\n",
    "    total = score['total']\n",
    "    auc_score = score['AUC']\n",
    "    precission = score['precision']\n",
    "    recall = score['recall']\n",
    "    f1 = score['F1 Score']\n",
    "    oa = score['OA']\n",
    "    aa = score['AA']\n",
    "    print(f\"dataset: {dataset}\\t\", f\"AUC: {auc_score}\", f\"precission: {precission}\", f\"recall: {recall}\", f\"F1 SCore{f1}\")\n",
    "\n",
    "print(f\"total: \\t\\t {all_correct0}/{class0_total/2} \\t {all_correct1}/{class1_total/2} \\t {all_correct}/{all_total}\")\n",
    "\n",
    "print(f\"acc: {all_correct/all_total}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c74a969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_total_score = {\n",
    "    'dataset': 'Total Dataset',\n",
    "    'correct_0': all_correct0,\n",
    "    'correct_1': all_correct1,\n",
    "    'class0_total': class0_total,\n",
    "    'class1_total': class1_total,\n",
    "    'correct_total': all_correct,\n",
    "    'total': all_total\n",
    "}\n",
    "\n",
    "scores.append(all_total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddab0694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850212\n",
      "850212\n",
      "850212\n"
     ]
    }
   ],
   "source": [
    "groundtruths = groundtruth\n",
    "groundtruth_in = []\n",
    "\n",
    "if mode == \"test\":\n",
    "    for x in groundtruths:\n",
    "        for y in x:\n",
    "            groundtruth_in.append(y)    \n",
    "\n",
    "if mode == \"full\":\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "predictions = prediction\n",
    "prediction_in = []\n",
    "\n",
    "for x in predictions:\n",
    "    for y in x:\n",
    "        prediction_in.append(y)\n",
    "\n",
    "\n",
    "y_prob_in = []\n",
    "\n",
    "for x in y_probs:\n",
    "    for y in x:\n",
    "        y_prob_in.append(y)\n",
    "\n",
    "print(len(groundtruth_in))\n",
    "print(len(prediction_in))\n",
    "print(len(y_prob_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e85a806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764037/850212\n"
     ]
    }
   ],
   "source": [
    "y_test = groundtruth_in\n",
    "y_pred = prediction_in\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for x, y in zip(y_test, y_pred):\n",
    "    total += 1\n",
    "    if x == y:\n",
    "        correct += 1\n",
    "\n",
    "print(f'{correct}/{total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a4761e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_test: [0 1]\n",
      "Sample y_pred values: [np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1)]\n"
     ]
    }
   ],
   "source": [
    "y_test_np = np.array([label.item() for label in y_test])\n",
    "# Ensure labels are binary (0 and 1)\n",
    "print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "# Check if y_pred is probability (float) or hard prediction (int)\n",
    "print(\"Sample y_pred values:\", y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29515cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(\n",
    "    {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Two Models')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6a288ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6218\n",
      "Recall:    0.9178\n",
      "F1 Score:  0.6673\n",
      "OA:        0.8986\n",
      "AA:        0.9178\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "# Precision, Recall, F1\n",
    "precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "# Overall Accuracy (OA)\n",
    "oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Average Accuracy (AA) — mean of per-class accuracies\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "aa = per_class_acc.mean()\n",
    "\n",
    "# Print all metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"OA:        {oa:.4f}\")\n",
    "print(f\"AA:        {aa:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8abb93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {\n",
    "    'AUC': float(roc_auc),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'F1 Score': float(f1),\n",
    "    'OA': float(oa),\n",
    "    'AA': float(aa),\n",
    "}\n",
    "result_json = {\n",
    "    'prediction' : scores,\n",
    "    'performance' : performance,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c0c5d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [{'dataset': 0, 'class0_size': 820876, 'class1_size': 29336, 'correct_0': 736507, 'correct_1': 27530, 'correct_total': 764037, 'total': 850212, 'AUC': 0.9651216168641942, 'precision': 0.6217896583118702, 'recall': 0.9178290943427124, 'F1 Score': 0.6672887959571911, 'OA': 0.8986429267053394, 'AA': 0.9178290943427124}, {'dataset': 'Total Dataset', 'correct_0': 736507, 'correct_1': 27530, 'class0_total': 820876, 'class1_total': 29336, 'correct_total': 764037, 'total': 850212}], 'performance': {'AUC': 0.9651216168641942, 'precision': 0.6217896583118702, 'recall': 0.9178290943427124, 'F1 Score': 0.6672887959571911, 'OA': 0.8986429267053394, 'AA': 0.9178290943427124}}\n",
      "JSON saved to results.json\n"
     ]
    }
   ],
   "source": [
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "print(result_json)\n",
    "\n",
    "with open(f\"performance/MyMethod {timestamp}_results.json\", \"w\") as f:\n",
    "    json.dump(result_json, f, indent=2)\n",
    "\n",
    "print(\"JSON saved to results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "901b6440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 127.6816 seconds\n",
      "predicting time: 2306.2272 seconds\n",
      "Run time: 2433.9087 seconds\n",
      "mode used: full\n",
      "finetune Parameter 195059266\n",
      "Pretrain Parameter 230467776\n",
      "saved_model for testing Parameter 195059266\n",
      "20250726_121846\n",
      "seet used: 10\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Train time: {train_time - start_time:.4f} seconds\")\n",
    "print(f\"predicting time: {end_time - train_time:.4f} seconds\")\n",
    "print(f\"Run time: {end_time - start_time:.4f} seconds\")\n",
    "print(f\"mode used: {mode}\")\n",
    "print(f\"finetune Parameter {finetune_parameter}\")\n",
    "print(f\"Pretrain Parameter {pretrain_parameters}\")\n",
    "print(f\"saved_model for testing Parameter {saved_model_parameters}\")\n",
    "print(timestamp)\n",
    "print(f\"seet used: {seed}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_repo_ta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

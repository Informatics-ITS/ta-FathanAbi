{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a5a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "GPU Name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from HSI_class import HSI\n",
    "import createSample as CS\n",
    "import augmentation as aug\n",
    "\n",
    "import simsiam.loader\n",
    "import random\n",
    "import zeroPadding\n",
    "start_time = time.time()\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "\n",
    "# If available, print the GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    \n",
    "sample_per_class = 5\n",
    "num_per_category_augment_1 = 10\n",
    "num_per_category_augment_2 = 10\n",
    "patch_size = 9\n",
    "n_category = 2\n",
    "band_size = 224\n",
    "base_encoder = 'vgg16'\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "batch_size = 20\n",
    "test_size = 0.5\n",
    "\n",
    "random_indices = 1\n",
    "\n",
    "seeded_run = True\n",
    "seed = 10\n",
    "\n",
    "mode = \"full\"\n",
    "# dataset path\n",
    "project_path = r\"C:\\Users\\Asus TUF\\Documents\\code\\TA\"\n",
    "# project_path = r\"D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25da8a0f-8f90-4f9e-9a04-991692e9ebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed has been set\n",
      "seet used: 10\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # PyTorch determinism\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "if seeded_run:\n",
    "    set_seed(seed)\n",
    "    print(\"seed has been set\")\n",
    "    print(f\"seet used: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "578786fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM01.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM02.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM03.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM04.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM05.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM06.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM07.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM08.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM09.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM10.mat\n",
      "random: 1\n",
      "generating random indices\n",
      "hsi shape\n",
      "(1243, 684, 224)\n",
      "creating 5 Randomly chosen 0 indices:\n",
      "creating 5 Randomly chosen 1 indices:\n",
      "indices 0 used: [(np.int64(910), np.int64(192)), (np.int64(51), np.int64(255)), (np.int64(689), np.int64(202)), (np.int64(772), np.int64(547)), (np.int64(920), np.int64(471))]\n",
      "indices 1 used: [(np.int64(22), np.int64(455)), (np.int64(170), np.int64(145)), (np.int64(410), np.int64(233)), (np.int64(1055), np.int64(123)), (np.int64(469), np.int64(582))]\n",
      "number of element equal 0 5\n",
      "number of element equal 1 5\n",
      "x_train shape: (10, 9, 9, 224)\n",
      "y_train shape: (10,)\n",
      "hasil augmentasi 1 shape: (20, 9, 9, 224)\n",
      "label augmentai 1 shape: (20,)\n",
      "hasil augmentasi 2 shape: (20, 9, 9, 224)\n",
      "label augmentasi 2 shape: (20,)\n",
      "label augment:\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "hasil augmentasi gabungan untuk training: (40, 9, 9, 224)\n",
      "label augmentasi gabungan: (40,)\n",
      "Element 0 occurs 20 times.\n",
      "Element 1 occurs 20 times.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = rf\"{project_path}\\Hyperspectral oil spill detection datasets\"\n",
    "\n",
    "dataset = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if i > 9:\n",
    "        break\n",
    "    file_path = os.path.join(dataset_path, filename)\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        hsi = HSI(file_path)\n",
    "        dataset.append(hsi)\n",
    "    i += 1\n",
    "\n",
    "train_hsi = dataset[0]\n",
    "patch_size = patch_size\n",
    "half_patch = patch_size // 2\n",
    "sample_per_class = sample_per_class\n",
    "\n",
    "train_indices_0 = []\n",
    "train_indices_1 = []\n",
    "\n",
    "print(f\"random: {random_indices}\")\n",
    "\n",
    "if random_indices:\n",
    "    print(\"generating random indices\")\n",
    "    selected_patches_0, selected_patches_1, train_indices_0, train_indices_1 = CS.createSample(train_hsi, patch_size, sample_per_class)\n",
    "else:\n",
    "    print(\"using generated indices\")\n",
    "    train_indices_0 = [(np.int64(188), np.int64(124)), (np.int64(523), np.int64(150)), (np.int64(1003), np.int64(474)), (np.int64(616), np.int64(508)), (np.int64(905), np.int64(552))]\n",
    "    train_indices_1 = [(np.int64(106), np.int64(606)), (np.int64(297), np.int64(468)), (np.int64(926), np.int64(35)), (np.int64(536), np.int64(519)), (np.int64(508), np.int64(442))]\n",
    "\n",
    "    selected_patches_0, selected_patches_1 = CS.getSample(train_hsi, patch_size, sample_per_class, train_indices_0, train_indices_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_indices = train_indices_0 +  train_indices_1\n",
    "\n",
    "# Concatenating along axis 0\n",
    "x_train = np.concatenate((selected_patches_0, selected_patches_1), )\n",
    "\n",
    "y_train = np.array([])\n",
    "\n",
    "gt = train_hsi.gt\n",
    "for indice in train_indices:\n",
    "    # print(gt[indice[0]][indice[1]])\n",
    "    y_train = np.append(y_train, gt[indice[0]][indice[1]])\n",
    "\n",
    "count = np.count_nonzero(y_train == 0)  # Count elements equal to 0\n",
    "print(f'number of element equal 0 {count}')\n",
    "\n",
    "count = np.count_nonzero(y_train == 1)  # Count elements equal to 1\n",
    "print(f'number of element equal 1 {count}')\n",
    "\n",
    "# Print shape to verify\n",
    "print(f\"x_train shape: {x_train.shape}\")  # Expected output: (10, 9, 9, 224)\n",
    "print(f\"y_train shape: {y_train.shape}\") \n",
    "\n",
    "\n",
    "n_category = n_category\n",
    "band_size = band_size\n",
    "num_per_category_augment_1 = num_per_category_augment_1\n",
    "num_per_category_augment_2 = num_per_category_augment_2\n",
    "\n",
    "data_augment1, label_augment1 = aug.Augment_data(x_train, y_train, n_category, patch_size, band_size, num_per_category_augment_1)\n",
    "\n",
    "data_augment2, label_augment2 = aug.Augment_data2(x_train, y_train, n_category, patch_size, band_size, num_per_category_augment_2)\n",
    "\n",
    "print(f\"hasil augmentasi 1 shape: {data_augment1.shape}\")\n",
    "print(f\"label augmentai 1 shape: {label_augment1.shape}\")\n",
    "\n",
    "print(f\"hasil augmentasi 2 shape: {data_augment2.shape}\")\n",
    "print(f\"label augmentasi 2 shape: {label_augment2.shape}\")\n",
    "\n",
    "print(\"label augment:\")\n",
    "print(label_augment1)\n",
    "print(label_augment2)\n",
    "\n",
    "data_augment = np.concatenate((data_augment1, data_augment2))\n",
    "label_augment = np.concatenate((label_augment1, label_augment2))\n",
    "\n",
    "print(f\"hasil augmentasi gabungan untuk training: {data_augment.shape}\")\n",
    "print(f\"label augmentasi gabungan: {label_augment.shape}\")\n",
    "\n",
    "\n",
    "# Count occurrences of each unique element\n",
    "counts = np.bincount(label_augment)\n",
    "\n",
    "# Print results\n",
    "for i, count in enumerate(counts):\n",
    "    print(f\"Element {i} occurs {count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cab1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    \"\"\"\n",
    "    Build a SimSiam model.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_encoder, spectral_band, dim=2048, pred_dim=512):\n",
    "        \"\"\"\n",
    "        dim: feature dimension (default: 2048)\n",
    "        pred_dim: hidden dimension of the predictor (default: 512)\n",
    "        \"\"\"\n",
    "        super(SimSiam, self).__init__()\n",
    "    \n",
    "        self.encoder = base_encoder(pretrained=True)\n",
    "\n",
    "        self.encoder.features = nn.Sequential(*list(self.encoder.features.children())[28:])\n",
    "        self.encoder.features[0] = nn.Conv2d(spectral_band, 512, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.encoder.features[1] = nn.ReLU(inplace=True)\n",
    "        self.encoder.features[2] = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.encoder.classifier[0] = nn.Linear(in_features=25088, out_features=256, bias=True)\n",
    "        self.encoder.classifier[1] = nn.BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.encoder.classifier[3] = nn.Linear(in_features=256, out_features=256, bias=False)\n",
    "        self.encoder.classifier[4] = nn.BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        # Modify the classifier to match the desired output dimensions\n",
    "        # self.encoder.classifier[0] = nn.Linear(512, 4096, bias=True)\n",
    "        self.encoder.classifier[6] = nn.Linear(256, dim)\n",
    "\n",
    "        # # Fix: Get the correct input dimension from VGG16 classifier\n",
    "        prev_dim = self.encoder.classifier[3].out_features\n",
    "\n",
    "        # Fix: Assign modified layers to classifier instead of non-existing 'fc'\n",
    "        self.encoder.classifier[6] = nn.Sequential(\n",
    "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(prev_dim),\n",
    "                                        nn.ReLU(inplace=True), # first layer\n",
    "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(prev_dim),\n",
    "                                        nn.ReLU(inplace=True), # second layer\n",
    "                                        self.encoder.classifier[6],\n",
    "                                        nn.BatchNorm1d(dim, affine=False)) # output layer# output layer\n",
    "                                        \n",
    "        self.encoder.classifier[6][6].bias.requires_grad = False\n",
    "        # self.projector[6].bias.requires_grad = False\n",
    "\n",
    "        # build a 3-layer projector\n",
    "        # prev_dim = self.encoder.fc.weight.shape[1]\n",
    "        # self.encoder.fc = nn.Sequential(nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "        #                                 nn.BatchNorm1d(prev_dim),\n",
    "        #                                 nn.ReLU(inplace=True), # first layer\n",
    "        #                                 nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "        #                                 nn.BatchNorm1d(prev_dim),\n",
    "        #                                 nn.ReLU(inplace=True), # second layer\n",
    "        #                                 self.encoder.fc,\n",
    "        #                                 nn.BatchNorm1d(dim, affine=False)) # output layer\n",
    "        # self.encoder.fc[6].bias.requires_grad = False # hack: not use bias as it is followed by BN\n",
    "\n",
    "        # build a 2-layer predictor\n",
    "        self.predictor = nn.Sequential(nn.Linear(dim, pred_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(pred_dim),\n",
    "                                        nn.ReLU(inplace=True), # hidden layer\n",
    "                                        nn.Linear(pred_dim, dim)) # output layer\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            x1: first views of images\n",
    "            x2: second views of images\n",
    "        Output:\n",
    "            p1, p2, z1, z2: predictors and targets of the network\n",
    "            See Sec. 3 of https://arxiv.org/abs/2011.10566 for detailed notations\n",
    "        \"\"\"\n",
    "\n",
    "       \n",
    "        z1 = self.encoder.features(x1) # NxC\n",
    "        z2 = self.encoder.features(x2) # NxC\n",
    "      \n",
    "\n",
    "        z1 = self.encoder.avgpool(z1)\n",
    "        z2 = self.encoder.avgpool(z2)\n",
    "\n",
    "\n",
    "        z1 = torch.flatten(z1, 1)\n",
    "        z2 = torch.flatten(z2, 1)\n",
    "   \n",
    "        z1 = self.encoder.classifier(z1)\n",
    "        z2 = self.encoder.classifier(z2)\n",
    "\n",
    "\n",
    "\n",
    "        p1 = self.predictor(z1) # NxC\n",
    "        p2 = self.predictor(z2) # NxC\n",
    "\n",
    "        return p1, p2, z1.detach(), z2.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4613ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'vgg16'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimSiam(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=256, bias=True)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=256, out_features=256, bias=False)\n",
      "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Linear(in_features=256, out_features=2048, bias=True)\n",
      "        (7): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (predictor): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=512, bias=False)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  )\n",
      ")\n",
      "parameter 10280704\n"
     ]
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "\n",
    "# create model\n",
    "base_encoder = base_encoder\n",
    "print(\"=> creating model '{}'\".format(base_encoder))\n",
    "pretrain_model = SimSiam(models.__dict__[base_encoder],224)\n",
    "\n",
    "\n",
    "lr = 0.01\n",
    "init_lr = lr * batch_size / 256\n",
    "gpu = 0\n",
    "\n",
    "print(pretrain_model)\n",
    "pretrain_parameters = sum(p.numel() for p in pretrain_model.parameters())\n",
    "print(f\"parameter {pretrain_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07ffc071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 224, 9, 9])\n",
      "input2 shape: torch.Size([1, 224, 9, 9])\n",
      "p1 shape torch.Size([1, 2048]), p2 shape torch.Size([1, 2048])\n",
      "z1 shape torch.Size([1, 2048]), z2 shape torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "test = data_augment[0]\n",
    "input = torch.tensor(test).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "test2 = data_augment[1]\n",
    "test2 = torch.tensor(test2).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "input2 = test2\n",
    "\n",
    "\n",
    "print(f\"input shape: {input.shape}\")\n",
    "print(f\"input2 shape: {input2.shape}\")\n",
    "\n",
    "# Pass the input through the model\n",
    "pretrain_model.eval()\n",
    "p1, p2, z1, z2  = pretrain_model(input, input2)\n",
    "\n",
    "print(f\"p1 shape {p1.shape}, p2 shape {p2.shape}\")\n",
    "print(f\"z1 shape {z1.shape}, z2 shape {z2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0224d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(40, 9, 9, 224)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CosineSimilarity(dim=1).cuda(gpu)\n",
    "print(gpu)\n",
    "optim_params = pretrain_model.parameters()\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "optimizer = torch.optim.SGD(optim_params, init_lr,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "augmentation = [\n",
    "    transforms.RandomHorizontalFlip(),  # Flip along width\n",
    "    transforms.RandomVerticalFlip(),    # Flip along height\n",
    "    transforms.RandomRotation(20),      # Rotate image slightly\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize hyperspectral data\n",
    "]\n",
    "\n",
    "transform = simsiam.loader.TwoCropsTransform(transforms.Compose(augmentation))\n",
    "\n",
    "print(data_augment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd6786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([40, 224, 9, 9])\n",
      "generate data loader using seed\n",
      "bacth size: torch.Size([20, 224, 9, 9])\n",
      "length batch: 20\n",
      "Train loader size: 2\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (Tensor or list of Tensors): Preloaded images of shape (N, 9, 9, 224)\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.images = images  # Assuming it's a list or tensor\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img1 = self.transform(img)  # First augmentation\n",
    "            img2 = self.transform(img)  # Second augmentation\n",
    "        \n",
    "            return img1, img2  # Return both augmented versions\n",
    "        \n",
    "        return img, img  # If no transform is provided, return the original image twice\n",
    "\n",
    "\n",
    "# Example usage\n",
    "pretrain_preloaded_image = data_augment \n",
    "\n",
    "pretrain_X_train = torch.tensor(pretrain_preloaded_image)\n",
    "pretrain_X_train = pretrain_X_train.to(torch.float32)\n",
    "pretrain_X_train = pretrain_X_train.permute(0, 3, 1, 2)\n",
    "print(f\"X_train shape: {pretrain_X_train.shape}\")\n",
    "\n",
    "# Define transformations if needed\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),  # Example normalization\n",
    "])\n",
    "\n",
    "pretrain_train_dataset = CustomDataset(pretrain_X_train, transform=transform)\n",
    "\n",
    "train_sampler = None\n",
    "\n",
    "if seeded_run:\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    \n",
    "    pretrain_train_loader = DataLoader(\n",
    "        pretrain_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    print(\"generate data loader using seed\")\n",
    "else:\n",
    "    pretrain_train_loader = DataLoader(\n",
    "        pretrain_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(train_sampler is None),\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 7. Check Output\n",
    "\n",
    "batch1, batch2 = next(iter(pretrain_train_loader))\n",
    "\n",
    "print(f\"bacth size: {batch1.size()}\")\n",
    "print(f\"length batch: {len(batch1)}\")  # Should print 2 (Two transformed views per image)\n",
    "print(f\"Train loader size: {len(pretrain_train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c59999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if 'fix_lr' in param_group and param_group['fix_lr']:\n",
    "            param_group['lr'] = init_lr\n",
    "        else:\n",
    "            param_group['lr'] = cur_lr\n",
    "\n",
    "class Pretrain_AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "    \n",
    "\n",
    "class Pretrain_ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "    \n",
    "def pretrain_save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6abedcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_train(train_loader, model, criterion, optimizer, epoch, device):\n",
    "    batch_time = Pretrain_AverageMeter('Time', ':6.3f')\n",
    "    data_time = Pretrain_AverageMeter('Data', ':6.3f')\n",
    "    losses = Pretrain_AverageMeter('Loss', ':.4f')\n",
    "    progress = Pretrain_ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    for i, (images1, images2) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input1 = images1.to(device, non_blocking=True)\n",
    "        input2 = images2.to(device, non_blocking=True)\n",
    "\n",
    "        p1, p2, z1, z2 = model(x1=input1, x2=input2) \n",
    "        loss = -(criterion(p1, z2).mean() + criterion(p2, z1).mean()) * 0.5\n",
    "\n",
    "        losses.update(loss.item(), input1.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "    # Return average training loss for early stopping\n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1714672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch: [0][0/2]\tTime  0.605 ( 0.605)\tData  0.008 ( 0.008)\tLoss 0.0106 (0.0106)\n",
      "Epoch 1: Average Training Loss: 0.007702\n",
      "✅ New best model saved with loss 0.007702\n",
      "Epoch: [1][0/2]\tTime  0.035 ( 0.035)\tData  0.013 ( 0.013)\tLoss 0.0032 (0.0032)\n",
      "Epoch 2: Average Training Loss: 0.003640\n",
      "✅ New best model saved with loss 0.003640\n",
      "Epoch: [2][0/2]\tTime  0.038 ( 0.038)\tData  0.013 ( 0.013)\tLoss 0.0047 (0.0047)\n",
      "Epoch 3: Average Training Loss: 0.004302\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [3][0/2]\tTime  0.032 ( 0.032)\tData  0.011 ( 0.011)\tLoss 0.0040 (0.0040)\n",
      "Epoch 4: Average Training Loss: -0.000465\n",
      "✅ New best model saved with loss -0.000465\n",
      "Epoch: [4][0/2]\tTime  0.041 ( 0.041)\tData  0.010 ( 0.010)\tLoss -0.0016 (-0.0016)\n",
      "Epoch 5: Average Training Loss: -0.001473\n",
      "✅ New best model saved with loss -0.001473\n",
      "Epoch: [5][0/2]\tTime  0.045 ( 0.045)\tData  0.024 ( 0.024)\tLoss 0.0013 (0.0013)\n",
      "Epoch 6: Average Training Loss: 0.003271\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [6][0/2]\tTime  0.048 ( 0.048)\tData  0.013 ( 0.013)\tLoss 0.0025 (0.0025)\n",
      "Epoch 7: Average Training Loss: 0.000938\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [7][0/2]\tTime  0.053 ( 0.053)\tData  0.022 ( 0.022)\tLoss 0.0029 (0.0029)\n",
      "Epoch 8: Average Training Loss: 0.002739\n",
      "❌ No improvement. Patience: 3/50\n",
      "Epoch: [8][0/2]\tTime  0.041 ( 0.041)\tData  0.008 ( 0.008)\tLoss 0.0010 (0.0010)\n",
      "Epoch 9: Average Training Loss: 0.002192\n",
      "❌ No improvement. Patience: 4/50\n",
      "Epoch: [9][0/2]\tTime  0.040 ( 0.040)\tData  0.017 ( 0.017)\tLoss -0.0036 (-0.0036)\n",
      "Epoch 10: Average Training Loss: 0.000976\n",
      "❌ No improvement. Patience: 5/50\n",
      "Epoch: [10][0/2]\tTime  0.039 ( 0.039)\tData  0.020 ( 0.020)\tLoss -0.0008 (-0.0008)\n",
      "Epoch 11: Average Training Loss: -0.001249\n",
      "❌ No improvement. Patience: 6/50\n",
      "Epoch: [11][0/2]\tTime  0.034 ( 0.034)\tData  0.008 ( 0.008)\tLoss 0.0019 (0.0019)\n",
      "Epoch 12: Average Training Loss: 0.001600\n",
      "❌ No improvement. Patience: 7/50\n",
      "Epoch: [12][0/2]\tTime  0.043 ( 0.043)\tData  0.016 ( 0.016)\tLoss 0.0007 (0.0007)\n",
      "Epoch 13: Average Training Loss: 0.000080\n",
      "❌ No improvement. Patience: 8/50\n",
      "Epoch: [13][0/2]\tTime  0.033 ( 0.033)\tData  0.000 ( 0.000)\tLoss -0.0024 (-0.0024)\n",
      "Epoch 14: Average Training Loss: 0.000394\n",
      "❌ No improvement. Patience: 9/50\n",
      "Epoch: [14][0/2]\tTime  0.036 ( 0.036)\tData  0.011 ( 0.011)\tLoss -0.0002 (-0.0002)\n",
      "Epoch 15: Average Training Loss: -0.003297\n",
      "✅ New best model saved with loss -0.003297\n",
      "Epoch: [15][0/2]\tTime  0.032 ( 0.032)\tData  0.000 ( 0.000)\tLoss 0.0027 (0.0027)\n",
      "Epoch 16: Average Training Loss: 0.000318\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [16][0/2]\tTime  0.035 ( 0.035)\tData  0.016 ( 0.016)\tLoss -0.0029 (-0.0029)\n",
      "Epoch 17: Average Training Loss: -0.002187\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [17][0/2]\tTime  0.040 ( 0.040)\tData  0.018 ( 0.018)\tLoss -0.0032 (-0.0032)\n",
      "Epoch 18: Average Training Loss: -0.003566\n",
      "✅ New best model saved with loss -0.003566\n",
      "Epoch: [18][0/2]\tTime  0.043 ( 0.043)\tData  0.016 ( 0.016)\tLoss -0.0005 (-0.0005)\n",
      "Epoch 19: Average Training Loss: -0.002019\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [19][0/2]\tTime  0.032 ( 0.032)\tData  0.007 ( 0.007)\tLoss 0.0024 (0.0024)\n",
      "Epoch 20: Average Training Loss: -0.000801\n",
      "❌ No improvement. Patience: 2/50\n"
     ]
    }
   ],
   "source": [
    "# Early stopping parameters\n",
    "best_loss = float('inf')\n",
    "patience = 50  # Number of epochs to wait for improvement\n",
    "patience_counter = 0\n",
    "\n",
    "start_epoch = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "pretrain_model.to(device)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "filename = f\"{timestamp}_model.pth.tar\"\n",
    "filepath = f\"models/pretrain/{filename}\"\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    pretrain_adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "\n",
    "    # Train and get average loss\n",
    "    avg_loss = pretrain_train(pretrain_train_loader, pretrain_model, criterion, optimizer, epoch, device)\n",
    "    print(f\"Epoch {epoch + 1}: Average Training Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': 'vgg16',\n",
    "            'state_dict': pretrain_model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'best_loss': best_loss\n",
    "        }, filepath)\n",
    "\n",
    "        print(f\"✅ New best model saved with loss {best_loss:.6f}\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"❌ No improvement. Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d5f40d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain Parameter 10280704\n",
      "models\\pretrain\\20250726_114753_model.pth.tar\n"
     ]
    }
   ],
   "source": [
    "pretrain_parameters = sum(p.numel() for p in pretrain_model.parameters())\n",
    "print(f\"pretrain Parameter {pretrain_parameters}\")\n",
    "\n",
    "pretrained = rf'models\\pretrain\\{filename}'\n",
    "print(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32ba8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "\n",
    "class VGG16_HSI(nn.Module):\n",
    "    def __init__(self, num_classes=2, spectral_band=224):\n",
    "        super(VGG16_HSI, self).__init__()\n",
    "\n",
    "        self.encoder =  vgg16(pretrained=True)\n",
    "\n",
    "        self.encoder.features = nn.Sequential(*list(self.encoder.features.children())[28:])\n",
    "        self.encoder.features[0] = nn.Conv2d(spectral_band, 512, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.encoder.features[1] = nn.ReLU(inplace=True)\n",
    "        self.encoder.features[2] = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.encoder.classifier[0] = nn.Linear(in_features=25088, out_features=256, bias=True)\n",
    "        self.encoder.classifier[1] = nn.BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.encoder.classifier[3] = nn.Linear(in_features=256, out_features=256, bias=False)\n",
    "        self.encoder.classifier[4] = nn.BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        # Modify the classifier to match the desired output dimensions\n",
    "        # self.encoder.classifier[0] = nn.Linear(512, 4096, bias=True)\n",
    "        self.encoder.classifier[6] = nn.Linear(256, 2048)\n",
    "        self.encoder.added_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=128, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3, inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=2, bias=True)\n",
    "        )   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder.features(x)  # Pass to VGG-16\n",
    "        x = self.encoder.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.encoder.classifier(x)  # Final classification layer\n",
    "        x = self.encoder.added_classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee42b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: 0 for training\n",
      "=> creating model\n",
      "finetune_parameter 8310914\n",
      "VGG16_HSI(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=256, bias=True)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=256, out_features=256, bias=False)\n",
      "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=256, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gpu = 0\n",
    "\n",
    "print(\"Use GPU: {} for training\".format(gpu))\n",
    "\n",
    "print(\"=> creating model\")\n",
    "\n",
    "model_finetune = VGG16_HSI()\n",
    "finetune_parameter = sum(p.numel() for p in model_finetune.parameters())\n",
    "print(f\"finetune_parameter {finetune_parameter}\")\n",
    "\n",
    "print(model_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9fa84ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'models\\pretrain\\20250726_114753_model.pth.tar'\n",
      "Manually loading parameters with remapping:\n",
      "\n",
      "✓ Loaded: encoder.features.0.weight → encoder.features.0.weight\n",
      "✓ Loaded: encoder.features.0.bias → encoder.features.0.bias\n",
      "✓ Loaded: encoder.classifier.0.weight → encoder.classifier.0.weight\n",
      "✓ Loaded: encoder.classifier.0.bias → encoder.classifier.0.bias\n",
      "✓ Loaded: encoder.classifier.1.weight → encoder.classifier.1.weight\n",
      "✓ Loaded: encoder.classifier.1.bias → encoder.classifier.1.bias\n",
      "✓ Loaded: encoder.classifier.1.running_mean → encoder.classifier.1.running_mean\n",
      "✓ Loaded: encoder.classifier.1.running_var → encoder.classifier.1.running_var\n",
      "✓ Loaded: encoder.classifier.1.num_batches_tracked → encoder.classifier.1.num_batches_tracked\n",
      "✓ Loaded: encoder.classifier.3.weight → encoder.classifier.3.weight\n",
      "✓ Loaded: encoder.classifier.4.weight → encoder.classifier.4.weight\n",
      "✓ Loaded: encoder.classifier.4.bias → encoder.classifier.4.bias\n",
      "✓ Loaded: encoder.classifier.4.running_mean → encoder.classifier.4.running_mean\n",
      "✓ Loaded: encoder.classifier.4.running_var → encoder.classifier.4.running_var\n",
      "✓ Loaded: encoder.classifier.4.num_batches_tracked → encoder.classifier.4.num_batches_tracked\n",
      "❌ Key not found in model: encoder.classifier.6.0.weight\n",
      "❌ Key not found in model: encoder.classifier.6.1.weight\n",
      "❌ Key not found in model: encoder.classifier.6.1.bias\n",
      "❌ Key not found in model: encoder.classifier.6.1.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.1.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.1.num_batches_tracked\n",
      "❌ Key not found in model: encoder.classifier.6.3.weight\n",
      "❌ Key not found in model: encoder.classifier.6.4.weight\n",
      "❌ Key not found in model: encoder.classifier.6.4.bias\n",
      "❌ Key not found in model: encoder.classifier.6.4.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.4.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.4.num_batches_tracked\n",
      "✓ Loaded: encoder.classifier.6.6.weight → encoder.classifier.6.weight\n",
      "✓ Loaded: encoder.classifier.6.6.bias → encoder.classifier.6.bias\n",
      "❌ Key not found in model: encoder.classifier.6.7.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.7.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.7.num_batches_tracked\n",
      "❌ Key not found in model: predictor.0.weight\n",
      "❌ Key not found in model: predictor.1.weight\n",
      "❌ Key not found in model: predictor.1.bias\n",
      "❌ Key not found in model: predictor.1.running_mean\n",
      "❌ Key not found in model: predictor.1.running_var\n",
      "❌ Key not found in model: predictor.1.num_batches_tracked\n",
      "❌ Key not found in model: predictor.3.weight\n",
      "❌ Key not found in model: predictor.3.bias\n",
      "\n",
      "=== Summary ===\n",
      "Total checkpoint keys: 40\n",
      "Successfully loaded: 17\n",
      "Missing keys in model: 23\n",
      "Shape mismatches: 0\n",
      "\n",
      "Missing keys:\n",
      "  encoder.classifier.6.0.weight\n",
      "  encoder.classifier.6.1.weight\n",
      "  encoder.classifier.6.1.bias\n",
      "  encoder.classifier.6.1.running_mean\n",
      "  encoder.classifier.6.1.running_var\n",
      "  encoder.classifier.6.1.num_batches_tracked\n",
      "  encoder.classifier.6.3.weight\n",
      "  encoder.classifier.6.4.weight\n",
      "  encoder.classifier.6.4.bias\n",
      "  encoder.classifier.6.4.running_mean\n",
      "  encoder.classifier.6.4.running_var\n",
      "  encoder.classifier.6.4.num_batches_tracked\n",
      "  encoder.classifier.6.7.running_mean\n",
      "  encoder.classifier.6.7.running_var\n",
      "  encoder.classifier.6.7.num_batches_tracked\n",
      "  predictor.0.weight\n",
      "  predictor.1.weight\n",
      "  predictor.1.bias\n",
      "  predictor.1.running_mean\n",
      "  predictor.1.running_var\n",
      "  predictor.1.num_batches_tracked\n",
      "  predictor.3.weight\n",
      "  predictor.3.bias\n",
      "=> loaded pre-trained model 'models\\pretrain\\20250726_114753_model.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_5796\\2432251866.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_5796\\2432251866.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "if pretrained:\n",
    "    if os.path.isfile(pretrained):\n",
    "        print(\"=> loading checkpoint '{}'\".format(pretrained))\n",
    "        checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
    "\n",
    "        checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
    "        pretrained_dict = checkpoint['state_dict']\n",
    "        finetune_model_dict = model_finetune.state_dict()\n",
    "\n",
    "        # Key remapping: map .6.6.weight → .6.weight and .6.6.bias → .6.bias\n",
    "        key_mapping = {\n",
    "            'encoder.classifier.6.6.weight': 'encoder.classifier.6.weight',\n",
    "            'encoder.classifier.6.6.bias': 'encoder.classifier.6.bias',\n",
    "        }\n",
    "\n",
    "        # Prepare containers\n",
    "        remapped_dict = {}\n",
    "        loaded_keys = []\n",
    "        shape_mismatches = []\n",
    "        missing_keys = []\n",
    "\n",
    "        print(\"Manually loading parameters with remapping:\\n\")\n",
    "\n",
    "        for k, v in pretrained_dict.items():\n",
    "            new_k = key_mapping.get(k, k)  # Remap if necessary\n",
    "            if new_k in finetune_model_dict:\n",
    "                if finetune_model_dict[new_k].shape == v.shape:\n",
    "                    remapped_dict[new_k] = v\n",
    "                    loaded_keys.append((k, new_k))\n",
    "                    print(f\"✓ Loaded: {k} → {new_k}\")\n",
    "                else:\n",
    "                    shape_mismatches.append((new_k, finetune_model_dict[new_k].shape, v.shape))\n",
    "                    print(f\"⚠️ Shape mismatch: {new_k} | model: {finetune_model_dict[new_k].shape} vs checkpoint: {v.shape}\")\n",
    "            else:\n",
    "                missing_keys.append(new_k)\n",
    "                print(f\"❌ Key not found in model: {new_k}\")\n",
    "\n",
    "        # Load state dict\n",
    "        model_finetune.load_state_dict(remapped_dict, strict=False)\n",
    "\n",
    "        # Summary\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(f\"Total checkpoint keys: {len(pretrained_dict)}\")\n",
    "        print(f\"Successfully loaded: {len(loaded_keys)}\")\n",
    "        print(f\"Missing keys in model: {len(missing_keys)}\")\n",
    "        print(f\"Shape mismatches: {len(shape_mismatches)}\")\n",
    "\n",
    "        if missing_keys:\n",
    "            print(\"\\nMissing keys:\")\n",
    "            for key in missing_keys:\n",
    "                print(f\"  {key}\")\n",
    "\n",
    "        if shape_mismatches:\n",
    "            print(\"\\nShape mismatches:\")\n",
    "            for key, model_shape, ckpt_shape in shape_mismatches:\n",
    "                print(f\"  {key} | model: {model_shape}, checkpoint: {ckpt_shape}\")\n",
    "\n",
    "  \n",
    "     \n",
    "\n",
    "        print(\"=> loaded pre-trained model '{}'\".format(pretrained))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(pretrained))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28417fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16_HSI(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=256, bias=True)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=256, out_features=256, bias=False)\n",
      "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=256, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "encoder.features.0.weight: requires_grad=False\n",
      "encoder.features.0.bias: requires_grad=False\n",
      "encoder.classifier.0.weight: requires_grad=False\n",
      "encoder.classifier.0.bias: requires_grad=False\n",
      "encoder.classifier.1.weight: requires_grad=False\n",
      "encoder.classifier.1.bias: requires_grad=False\n",
      "encoder.classifier.3.weight: requires_grad=False\n",
      "encoder.classifier.4.weight: requires_grad=False\n",
      "encoder.classifier.4.bias: requires_grad=False\n",
      "encoder.classifier.6.weight: requires_grad=False\n",
      "encoder.classifier.6.bias: requires_grad=False\n",
      "encoder.added_classifier.0.weight: requires_grad=True\n",
      "encoder.added_classifier.0.bias: requires_grad=True\n",
      "encoder.added_classifier.3.weight: requires_grad=True\n",
      "encoder.added_classifier.3.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for param in model_finetune.encoder.features.parameters():\n",
    "    param.requires_grad = False  # Freeze convolutional layers\n",
    "\n",
    "for param in model_finetune.encoder.classifier.parameters():\n",
    "    param.requires_grad = False  # Freeze all but the last FC layer\n",
    "\n",
    "\n",
    "print(model_finetune)\n",
    "# Check which layers are trainable\n",
    "for name, param in model_finetune.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5f67fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 224, 9, 9])\n",
      "input2 shape: torch.Size([1, 224, 9, 9])\n",
      "output shape torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "test = data_augment[0]\n",
    "test = torch.tensor(test).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "input = test\n",
    "\n",
    "\n",
    "test2 = data_augment[1]\n",
    "test2 = torch.tensor(test2).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "input2 = test2\n",
    "\n",
    "\n",
    "print(f\"input shape: {input.shape}\")\n",
    "print(f\"input2 shape: {input2.shape}\")\n",
    "\n",
    "# Pass the input through the model\n",
    "model_finetune.eval()\n",
    "output = model_finetune(input)\n",
    "\n",
    "print(f\"output shape {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7321178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_augment shape (40, 9, 9, 224)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 0\n",
    "\n",
    "init_lr = lr * batch_size / 256\n",
    "\n",
    "torch.cuda.set_device(gpu)\n",
    "model_finetune = model_finetune.cuda(gpu)\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "\n",
    "# optimize only the linear classifier\n",
    "parameters = list(filter(lambda p: p.requires_grad, model_finetune.parameters()))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(parameters, init_lr,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=weight_decay)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "\n",
    "print(f\"data_augment shape {data_augment.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d915ed95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune_X_train shape: torch.Size([40, 224, 9, 9])\n",
      "Train shape: torch.Size([20, 224, 9, 9]), Validation shape: torch.Size([20, 224, 9, 9])\n",
      "generate data loader using seed\n",
      "torch.Size([20])\n",
      "Train loader size: 1, Validation loader size: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Example usage\n",
    "class CustomDatasetFinetune(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (Tensor or list of Tensors): Preloaded images of shape (N, 9, 9, 224)\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.images = images  # Assuming it's a list or tensor\n",
    "        self.transform = transform\n",
    "        self.label = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img1 = self.transform(img)  # First augmentation\n",
    "        \n",
    "            return img1, label  # Return both augmented versions\n",
    "        \n",
    "        return img, label  # If no transform is provided, return the original image twice\n",
    "    \n",
    "finetune_preloaded_images = data_augment  \n",
    "finetune_X = torch.tensor(finetune_preloaded_images)\n",
    "finetune_X= finetune_X.to(torch.float32)\n",
    "finetune_X = finetune_X.permute(0, 3, 1, 2)\n",
    "print(f\"finetune_X_train shape: {finetune_X.shape}\")\n",
    "\n",
    "finetune_y = torch.tensor(label_augment)\n",
    "#\n",
    "# Define transformations if needed\n",
    "\n",
    "testSize = test_size\n",
    "finetune_X_train, finetune_X_val, finetune_y_train, finetune_y_val = train_test_split(finetune_X, finetune_y, test_size = testSize, random_state=seed, stratify=finetune_y)\n",
    "print(f\"Train shape: {finetune_X_train.shape}, Validation shape: {finetune_X_val.shape}\")\n",
    "\n",
    "finetune_train_dataset = CustomDatasetFinetune(finetune_X_train, finetune_y_train)\n",
    "finetune_val_dataset = CustomDatasetFinetune(finetune_X_val, finetune_y_val)\n",
    "\n",
    "train_sampler = None\n",
    "\n",
    "if seeded_run:\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    \n",
    "    finetune_train_loader = DataLoader(\n",
    "        finetune_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    finetune_val_loader = DataLoader(\n",
    "        finetune_val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    \n",
    "    print(\"generate data loader using seed\")\n",
    "else:\n",
    "    finetune_train_loader = DataLoader(finetune_train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=False)\n",
    "    finetune_val_loader = DataLoader(finetune_val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "# 7. Check Output\n",
    "\n",
    "batch1 = next(iter(finetune_train_loader))\n",
    "\n",
    "print(batch1[1].size())\n",
    "print(f\"Train loader size: {len(finetune_train_loader)}, Validation loader size: {len(finetune_val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b237e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = FinetuneAverageMeter('Time', ':6.3f')\n",
    "    data_time = FinetuneAverageMeter('Data', ':6.3f')\n",
    "    losses = FinetuneAverageMeter('Loss', ':.4e')\n",
    "    top1 = FinetuneAverageMeter('Acc@1', ':6.2f')\n",
    "    progress = FinetuneProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    \"\"\"\n",
    "    Switch to eval mode:\n",
    "    Under the protocol of linear classification on frozen features/models,\n",
    "    it is not legitimate to change any part of the pre-trained model.\n",
    "    BatchNorm in train mode may revise running mean/std (even if it receives\n",
    "    no gradient), which are part of the model parameters too.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        gpu = 0\n",
    "        images = images.cuda(gpu, non_blocking=True)\n",
    "        target = target.cuda(gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, = finetune_accuracy(output, target, topk=(1,))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        print_freq = 10\n",
    "        if i % print_freq == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "\n",
    "def finetune_validate(val_loader, model, criterion):\n",
    "    batch_time = FinetuneAverageMeter('Time', ':6.3f')\n",
    "    losses = FinetuneAverageMeter('Loss', ':.4e')\n",
    "    top1 = FinetuneAverageMeter('Acc@1', ':6.2f')\n",
    "  \n",
    "    progress = FinetuneProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "       \n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "      \n",
    "            gpu = 0\n",
    "            images = images.cuda(gpu, non_blocking=True)\n",
    "            target = target.cuda(gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, = finetune_accuracy(output, target, topk=(1,))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            # top5.update(acc5[0], images.size(0))\n",
    "            print(f\"in validation finction {acc1}\")\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            print_freq = 10\n",
    "            if i % print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def finetune_save_checkpoint(timestamp, epoch, state, is_best, filename='models/checkpoint.pth.tar'):\n",
    "    filename='models/finetune/{}_model.pth.tar'.format(timestamp)\n",
    "    torch.save(state, filename)\n",
    "    # if is_best:\n",
    "    #     shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "def finetune_sanity_check(state_dict, pretrained_weights):\n",
    "    \"\"\"\n",
    "    Linear classifier should not change any weights other than the linear layer.\n",
    "    This sanity check asserts nothing wrong happens (e.g., BN stats updated).\n",
    "    \"\"\"\n",
    "    print(\"=> loading '{}' for sanity check\".format(pretrained_weights))\n",
    "    checkpoint = torch.load(pretrained_weights, map_location=\"cpu\")\n",
    "    state_dict_pre = checkpoint['state_dict']\n",
    "\n",
    "    for k in list(state_dict.keys()):\n",
    "        # Ignore fc layer\n",
    "        if 'fc.weight' in k or 'fc.bias' in k:\n",
    "            continue\n",
    "\n",
    "        # Adjust key mapping to match checkpoint format\n",
    "        k_pre = k.replace('module.encoder.', '')  # Remove unnecessary prefix\n",
    "\n",
    "        # Skip missing keys\n",
    "        if k_pre not in state_dict_pre:\n",
    "            print(f\"Warning: {k_pre} not found in pretrained model. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Check if tensor shapes match before comparing values\n",
    "        if state_dict[k].shape != state_dict_pre[k_pre].shape:\n",
    "            print(f\"Warning: Shape mismatch for {k}: {state_dict[k].shape} vs {state_dict_pre[k_pre].shape}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Assert that the weights remain unchanged\n",
    "        assert ((state_dict[k].cpu() == state_dict_pre[k_pre]).all()), \\\n",
    "            '{} is changed in linear classifier training.'.format(k)\n",
    "\n",
    "    print(\"=> sanity check passed.\")\n",
    "\n",
    "\n",
    "\n",
    "class FinetuneAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class FinetuneProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def finetune_adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = cur_lr\n",
    "\n",
    "\n",
    "def finetune_accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8982a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.features.0.weight: requires_grad=False\n",
      "encoder.features.0.bias: requires_grad=False\n",
      "encoder.classifier.0.weight: requires_grad=False\n",
      "encoder.classifier.0.bias: requires_grad=False\n",
      "encoder.classifier.1.weight: requires_grad=False\n",
      "encoder.classifier.1.bias: requires_grad=False\n",
      "encoder.classifier.3.weight: requires_grad=False\n",
      "encoder.classifier.4.weight: requires_grad=False\n",
      "encoder.classifier.4.bias: requires_grad=False\n",
      "encoder.classifier.6.weight: requires_grad=False\n",
      "encoder.classifier.6.bias: requires_grad=False\n",
      "encoder.added_classifier.0.weight: requires_grad=True\n",
      "encoder.added_classifier.0.bias: requires_grad=True\n",
      "encoder.added_classifier.3.weight: requires_grad=True\n",
      "encoder.added_classifier.3.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_finetune.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa72c1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/1]\tTime  0.055 ( 0.055)\tData  0.002 ( 0.002)\tLoss 7.0322e-01 (7.0322e-01)\tAcc@1  40.00 ( 40.00)\n",
      "in validation finction tensor([40.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.065 ( 0.065)\tLoss 6.9509e-01 (6.9509e-01)\tAcc@1  40.00 ( 40.00)\n",
      " * Acc@1 40.000\n",
      "✅ Epoch 1: New best Acc@1: 40.00. Model saved.\n",
      "Epoch: [1][0/1]\tTime  0.008 ( 0.008)\tData  0.000 ( 0.000)\tLoss 6.9433e-01 (6.9433e-01)\tAcc@1  40.00 ( 40.00)\n",
      "in validation finction tensor([70.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.010 ( 0.010)\tLoss 6.7655e-01 (6.7655e-01)\tAcc@1  70.00 ( 70.00)\n",
      " * Acc@1 70.000\n",
      "✅ Epoch 2: New best Acc@1: 70.00. Model saved.\n",
      "Epoch: [2][0/1]\tTime  0.007 ( 0.007)\tData  0.000 ( 0.000)\tLoss 6.8013e-01 (6.8013e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([70.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.009 ( 0.009)\tLoss 6.5549e-01 (6.5549e-01)\tAcc@1  70.00 ( 70.00)\n",
      " * Acc@1 70.000\n",
      "❌ Epoch 3: No improvement. Patience counter: 1/50\n",
      "Epoch: [3][0/1]\tTime  0.010 ( 0.010)\tData  0.001 ( 0.001)\tLoss 6.6444e-01 (6.6444e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([70.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.009 ( 0.009)\tLoss 6.3688e-01 (6.3688e-01)\tAcc@1  70.00 ( 70.00)\n",
      " * Acc@1 70.000\n",
      "❌ Epoch 4: No improvement. Patience counter: 2/50\n",
      "Epoch: [4][0/1]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tLoss 6.5103e-01 (6.5103e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([70.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.018 ( 0.018)\tLoss 6.1943e-01 (6.1943e-01)\tAcc@1  70.00 ( 70.00)\n",
      " * Acc@1 70.000\n",
      "❌ Epoch 5: No improvement. Patience counter: 3/50\n",
      "Epoch: [5][0/1]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tLoss 6.3929e-01 (6.3929e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([70.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.016 ( 0.016)\tLoss 6.0356e-01 (6.0356e-01)\tAcc@1  70.00 ( 70.00)\n",
      " * Acc@1 70.000\n",
      "❌ Epoch 6: No improvement. Patience counter: 4/50\n",
      "Epoch: [6][0/1]\tTime  0.002 ( 0.002)\tData  0.000 ( 0.000)\tLoss 6.2921e-01 (6.2921e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([70.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.014 ( 0.014)\tLoss 5.8965e-01 (5.8965e-01)\tAcc@1  70.00 ( 70.00)\n",
      " * Acc@1 70.000\n",
      "❌ Epoch 7: No improvement. Patience counter: 5/50\n",
      "Epoch: [7][0/1]\tTime  0.012 ( 0.012)\tData  0.000 ( 0.000)\tLoss 6.2031e-01 (6.2031e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([70.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.000 ( 0.000)\tLoss 5.7673e-01 (5.7673e-01)\tAcc@1  70.00 ( 70.00)\n",
      " * Acc@1 70.000\n",
      "❌ Epoch 8: No improvement. Patience counter: 6/50\n",
      "Epoch: [8][0/1]\tTime  0.016 ( 0.016)\tData  0.000 ( 0.000)\tLoss 6.1176e-01 (6.1176e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([70.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.006 ( 0.006)\tLoss 5.6522e-01 (5.6522e-01)\tAcc@1  70.00 ( 70.00)\n",
      " * Acc@1 70.000\n",
      "❌ Epoch 9: No improvement. Patience counter: 7/50\n",
      "Epoch: [9][0/1]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tLoss 6.0390e-01 (6.0390e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([70.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.016 ( 0.016)\tLoss 5.5522e-01 (5.5522e-01)\tAcc@1  70.00 ( 70.00)\n",
      " * Acc@1 70.000\n",
      "❌ Epoch 10: No improvement. Patience counter: 8/50\n",
      "Epoch: [10][0/1]\tTime  0.011 ( 0.011)\tData  0.000 ( 0.000)\tLoss 5.9682e-01 (5.9682e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([70.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.010 ( 0.010)\tLoss 5.4671e-01 (5.4671e-01)\tAcc@1  70.00 ( 70.00)\n",
      " * Acc@1 70.000\n",
      "❌ Epoch 11: No improvement. Patience counter: 9/50\n",
      "Epoch: [11][0/1]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tLoss 5.9073e-01 (5.9073e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([70.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.008 ( 0.008)\tLoss 5.3947e-01 (5.3947e-01)\tAcc@1  70.00 ( 70.00)\n",
      " * Acc@1 70.000\n",
      "❌ Epoch 12: No improvement. Patience counter: 10/50\n",
      "Epoch: [12][0/1]\tTime  0.004 ( 0.004)\tData  0.000 ( 0.000)\tLoss 5.8547e-01 (5.8547e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.000 ( 0.000)\tLoss 5.3351e-01 (5.3351e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "✅ Epoch 13: New best Acc@1: 75.00. Model saved.\n",
      "Epoch: [13][0/1]\tTime  0.010 ( 0.010)\tData  0.000 ( 0.000)\tLoss 5.8103e-01 (5.8103e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.000 ( 0.000)\tLoss 5.2879e-01 (5.2879e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 14: No improvement. Patience counter: 1/50\n",
      "Epoch: [14][0/1]\tTime  0.016 ( 0.016)\tData  0.000 ( 0.000)\tLoss 5.7739e-01 (5.7739e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.000 ( 0.000)\tLoss 5.2518e-01 (5.2518e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 15: No improvement. Patience counter: 2/50\n",
      "Epoch: [15][0/1]\tTime  0.020 ( 0.020)\tData  0.000 ( 0.000)\tLoss 5.7454e-01 (5.7454e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.008 ( 0.008)\tLoss 5.2261e-01 (5.2261e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 16: No improvement. Patience counter: 3/50\n",
      "Epoch: [16][0/1]\tTime  0.004 ( 0.004)\tData  0.002 ( 0.002)\tLoss 5.7249e-01 (5.7249e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.012 ( 0.012)\tLoss 5.2091e-01 (5.2091e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 17: No improvement. Patience counter: 4/50\n",
      "Epoch: [17][0/1]\tTime  0.007 ( 0.007)\tData  0.000 ( 0.000)\tLoss 5.7111e-01 (5.7111e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.009 ( 0.009)\tLoss 5.1992e-01 (5.1992e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 18: No improvement. Patience counter: 5/50\n",
      "Epoch: [18][0/1]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tLoss 5.7030e-01 (5.7030e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.008 ( 0.008)\tLoss 5.1947e-01 (5.1947e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 19: No improvement. Patience counter: 6/50\n",
      "Epoch: [19][0/1]\tTime  0.009 ( 0.009)\tData  0.003 ( 0.003)\tLoss 5.6993e-01 (5.6993e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.011 ( 0.011)\tLoss 5.1936e-01 (5.1936e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 20: No improvement. Patience counter: 7/50\n"
     ]
    }
   ],
   "source": [
    "best_acc1 = 0.0\n",
    "patience = 50  # Adjust as needed\n",
    "patience_counter = 0\n",
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "start_epoch = 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_finetune.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    finetune_adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "\n",
    "    # Train for one epoch\n",
    "    finetune_train(finetune_train_loader, model_finetune, criterion, optimizer, epoch)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    acc1 = finetune_validate(finetune_val_loader, model_finetune, criterion)\n",
    "\n",
    "    # Check if current accuracy is the best\n",
    "    is_best = acc1 > best_acc1\n",
    "\n",
    "    if is_best:\n",
    "        best_acc1 = acc1\n",
    "        patience_counter = 0\n",
    "\n",
    "        # Save best model only\n",
    "        finetune_save_checkpoint(timestamp, epoch, {\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': 'vgg16',\n",
    "            'state_dict': model_finetune.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best=True)\n",
    "\n",
    "        print(f\"✅ Epoch {epoch+1}: New best Acc@1: {best_acc1:.2f}. Model saved.\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"❌ Epoch {epoch+1}: No improvement. Patience counter: {patience_counter}/{patience}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"⏹️ Early stopping triggered at epoch {epoch+1}. Best Acc@1: {best_acc1:.2f}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "828ce5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250726_114753\n"
     ]
    }
   ],
   "source": [
    "train_time = time.time()\n",
    "\n",
    "\n",
    "print(timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c42bbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9859cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWithDataset(n): \n",
    "    hsi_test = dataset[n]\n",
    "\n",
    "    test_img = hsi_test.img\n",
    "    test_gt = hsi_test.gt\n",
    "\n",
    "    patch_size = 9\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    height = test_img.shape[0]\n",
    "    width = test_img.shape[1]\n",
    "\n",
    "    matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "    print(f\"img shape: {test_img.shape}\")\n",
    "    print(f\"img shape after padding {matrix.shape}\")\n",
    "    print(f\"number of pixel {width * height}\")\n",
    "\n",
    "    print(f\"ground truth shape: {test_gt.shape}\")\n",
    "\n",
    "    indices0 = np.argwhere(test_gt == 0)\n",
    "    indices1 = np.argwhere(test_gt == 1)\n",
    "\n",
    "    print(f\"indices = 0 shape: {indices0.shape}\")\n",
    "    print(f\"indices = 1 shape: {indices1.shape}\")\n",
    "\n",
    "    num_samples = 5000\n",
    "\n",
    "    random_indices0 = indices0[np.random.choice(len(indices0), num_samples, replace=False)]\n",
    "    random_indices1 = indices1[np.random.choice(len(indices1), num_samples, replace=False)]\n",
    "\n",
    "    test_indices = np.vstack((random_indices0, random_indices1))\n",
    "\n",
    "    print(test_indices.shape)\n",
    "\n",
    "    return test_indices, test_gt, matrix, random_indices0.shape, random_indices1.shape\n",
    "\n",
    "\n",
    "def testWithWholeDataset(n): \n",
    "    hsi_test = dataset[n]\n",
    "\n",
    "    test_img = hsi_test.img\n",
    "    gt= hsi_test.gt\n",
    "\n",
    "    patch_size = 9\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    height = test_img.shape[0]\n",
    "    width = test_img.shape[1]\n",
    "\n",
    "    matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "    print(f\"img shape: {test_img.shape}\")\n",
    "    print(f\"img shape after padding {matrix.shape}\")\n",
    "    print(f\"number of pixel {width * height}\")\n",
    "\n",
    "    print(f\"ground truth shape: {gt.shape}\")\n",
    "\n",
    "    indices0 = np.argwhere(gt == 0)\n",
    "    indices1 = np.argwhere(gt == 1)\n",
    "\n",
    "    print(f\"indices = 0 shape: {indices0.shape}\")\n",
    "    print(f\"indices = 1 shape: {indices1.shape}\")\n",
    "\n",
    "    return matrix, gt, indices0.shape, indices1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a0cfff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(model, batch_input, device):\n",
    "    model.eval()\n",
    "    batch_input = batch_input.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_input)\n",
    "        # Apply softmax to get class probabilities\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "        # Get predicted class (0 or 1)\n",
    "        predicted_classes = torch.argmax(probabilities, dim=1).cpu().numpy()\n",
    "\n",
    "        # Get probability of class 1 (positive class) — required for ROC\n",
    "        positive_class_probs = probabilities[:, 1].cpu().numpy()\n",
    "\n",
    "    \n",
    "\n",
    "    return predicted_classes, positive_class_probs\n",
    "\n",
    "\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, matrix, gt, half_patch, expected_shape):\n",
    "        self.matrix = matrix\n",
    "        self.gt = gt\n",
    "        self.half_patch = half_patch\n",
    "        self.expected_shape = expected_shape\n",
    "        self.size_x, self.size_y = matrix.shape[0], matrix.shape[1]\n",
    "        self.valid_coords = [\n",
    "            (x, y)\n",
    "            for x in range(half_patch, self.size_x - half_patch)\n",
    "            for y in range(half_patch, self.size_y - half_patch)\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.valid_coords[idx]\n",
    "        true_label = self.gt[x - self.half_patch, y - self.half_patch]\n",
    "\n",
    "        selected_rows = self.matrix[x- self.half_patch:x + 2 * self.half_patch + 1 - self.half_patch, :]\n",
    "        testing_patch = selected_rows[:, y - self.half_patch:y + 2 * self.half_patch + 1 - self.half_patch]\n",
    "\n",
    "        # Verify patch size\n",
    "        if testing_patch.shape != self.expected_shape:\n",
    "            raise ValueError(f\"Patch at ({x},{y}) has wrong shape {testing_patch.shape}\")\n",
    "\n",
    "        patch_tensor = torch.tensor(testing_patch, dtype=torch.float32)\n",
    "        patch_tensor = patch_tensor.permute(2, 0, 1)  # (C, H, W)\n",
    "\n",
    "        return patch_tensor, true_label, x, y  # Also return (x, y) for positioning later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "575b807c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\finetune\\20250726_114753_model.pth.tar\n",
      "Creating model 20250726_114753_model.pth.tar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and moved to device\n",
      "saved_model for testing Parameter 8310914\n",
      "VGG16_HSI(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=256, bias=True)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=256, out_features=256, bias=False)\n",
      "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=256, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_5796\\3084895309.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 64  # You can change this depending on your GPU capacity\n",
    "\n",
    "model_path = rf\"models\\finetune\\{timestamp}_model.pth.tar\"\n",
    "model_name = model_path.split('\\\\')[-1]\n",
    "print(model_path)\n",
    "\n",
    "print(f\"Creating model {model_name}...\")\n",
    "saved_model = VGG16_HSI().to(device)\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "saved_model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Model loaded and moved to device\")\n",
    "\n",
    "saved_model_parameters = sum(p.numel() for p in saved_model.parameters())\n",
    "print(f\"saved_model for testing Parameter {saved_model_parameters}\")\n",
    "print(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13871a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScoreTest(prediction, y_probs, groundtruth):\n",
    "    groundtruths = groundtruth\n",
    "    groundtruth_in = []\n",
    "\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "    predictions = prediction\n",
    "    prediction_in = []\n",
    "\n",
    "    for x in predictions:\n",
    "        for y in x:\n",
    "            prediction_in.append(y)\n",
    "\n",
    "\n",
    "    y_prob_in = []\n",
    "\n",
    "    for x in y_probs:\n",
    "        for y in x:\n",
    "            y_prob_in.append(y)\n",
    "\n",
    "    print(len(groundtruth_in))\n",
    "    print(len(prediction_in))\n",
    "    print(len(y_prob_in))\n",
    "\n",
    "    y_test = groundtruth_in\n",
    "    y_pred = prediction_in\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in zip(y_test, y_pred):\n",
    "        total += 1\n",
    "        if x == y:\n",
    "            correct += 1\n",
    "    \n",
    "    print(f'{correct}/{total}')\n",
    "\n",
    "    y_test_np = np.array([label.item() for label in y_test])\n",
    "    # Ensure labels are binary (0 and 1)\n",
    "    # print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "    # # Check if y_pred is probability (float) or hard prediction (int)\n",
    "    # print(\"Sample y_pred values:\", y_pred[:5])\n",
    "\n",
    "    test_df = pd.DataFrame(\n",
    "        {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Two Models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "    y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "    # Precision, Recall, F1\n",
    "    precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Overall Accuracy (OA)\n",
    "    oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Average Accuracy (AA) — mean of per-class accuracies\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    aa = per_class_acc.mean()\n",
    "\n",
    "    # Print all metrics\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"OA:        {oa:.4f}\")\n",
    "    print(f\"AA:        {aa:.4f}\")\n",
    "\n",
    "    performance = {\n",
    "        'AUC': float(roc_auc),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'F1 Score': float(f1),\n",
    "        'OA': float(oa),\n",
    "        'AA': float(aa),\n",
    "    }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a467139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(prediction, y_probs, groundtruth):\n",
    "    groundtruths = groundtruth\n",
    "    groundtruth_in = []\n",
    "\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "    predictions = prediction\n",
    "    prediction_in = []\n",
    "\n",
    "    for x in predictions:\n",
    "        for y in x:\n",
    "            prediction_in.append(y)\n",
    "\n",
    "\n",
    "    y_prob_in = []\n",
    "\n",
    "    for x in y_probs:\n",
    "        for y in x:\n",
    "            y_prob_in.append(y)\n",
    "\n",
    "    # print(len(groundtruth_in))\n",
    "    # print(len(prediction_in))\n",
    "    # print(len(y_prob_in))\n",
    "\n",
    "    y_test = groundtruth_in\n",
    "    y_pred = prediction_in\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in zip(y_test, y_pred):\n",
    "        total += 1\n",
    "        if x == y:\n",
    "            correct += 1\n",
    "    \n",
    "    print(f'{correct}/{total}')\n",
    "\n",
    "    y_test_np = np.array([label.item() for label in y_test])\n",
    "    # Ensure labels are binary (0 and 1)\n",
    "    # print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "    # # Check if y_pred is probability (float) or hard prediction (int)\n",
    "    # print(\"Sample y_pred values:\", y_pred[:5])\n",
    "\n",
    "    test_df = pd.DataFrame(\n",
    "        {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Two Models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "    y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "    # Precision, Recall, F1\n",
    "    precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Overall Accuracy (OA)\n",
    "    oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Average Accuracy (AA) — mean of per-class accuracies\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    aa = per_class_acc.mean()\n",
    "\n",
    "    # Print all metrics\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"OA:        {oa:.4f}\")\n",
    "    print(f\"AA:        {aa:.4f}\")\n",
    "\n",
    "    performance = {\n",
    "        'AUC': float(roc_auc),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'F1 Score': float(f1),\n",
    "        'OA': float(oa),\n",
    "        'AA': float(aa),\n",
    "    }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9ae6c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tes: 0\n",
      "dataset: 1\n",
      "img shape: (1243, 684, 224)\n",
      "img shape after padding (1251, 692, 224)\n",
      "number of pixel 850212\n",
      "ground truth shape: (1243, 684)\n",
      "indices = 0 shape: (820876, 2)\n",
      "indices = 1 shape: (29336, 2)\n",
      "820876\n",
      "29336\n",
      "generate data loader using seed\n",
      "torch.Size([64, 224, 9, 9])\n",
      "torch.Size([64])\n",
      "data loader size: 13285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 13285/13285 [07:54<00:00, 28.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823060/850212\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7741\n",
      "Recall:    0.6421\n",
      "F1 Score:  0.6853\n",
      "OA:        0.9681\n",
      "AA:        0.6421\n",
      "correct0 = 814492\n",
      "correct1 = 8568\n",
      "Score: 823060/850212\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "scores = []\n",
    "\n",
    "groundtruth = []\n",
    "prediction = []\n",
    "y_probs = []\n",
    "\n",
    "\n",
    "if mode == \"test\":\n",
    "    for hsi_test in range(len(dataset)):\n",
    "        print(f\"tes: {hsi_test + 1}\")\n",
    "\n",
    "        hsi_prediction = []\n",
    "        hsi_yprobs = []\n",
    "        hsi_groundtruth = []\n",
    "\n",
    "\n",
    "        test_indices, test_gt, matrix, indices_0_shape, indices_1_shape = testWithDataset(hsi_test)\n",
    "\n",
    "        total = len(test_indices)\n",
    "        correct0 = 0\n",
    "        correct1 = 0\n",
    "\n",
    "        input_patches = []\n",
    "        true_labels = []\n",
    "\n",
    "        # Prepare all patches\n",
    "        for x_pos, y_pos in test_indices:\n",
    "            true_label = test_gt[x_pos][y_pos]\n",
    "\n",
    "            selected_rows = matrix[x_pos:x_pos + 2*half_patch + 1, :]\n",
    "            testing_patch = selected_rows[:, y_pos:y_pos + 2*half_patch + 1]\n",
    "\n",
    "            patch_tensor = torch.tensor(testing_patch, dtype=torch.float32)\n",
    "            patch_tensor = patch_tensor.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "            input_patches.append(patch_tensor)\n",
    "            true_labels.append(true_label)\n",
    "\n",
    "        input_patches = torch.cat(input_patches, dim=0)  # Shape: (N, C, H, W)\n",
    "        true_labels = torch.tensor(true_labels)\n",
    "\n",
    "        # Process in batches\n",
    "        for i in tqdm(range(0, total, batch_size), desc=\"Predicting\"):\n",
    "            batch = input_patches[i:i+batch_size]\n",
    "            labels = true_labels[i:i+batch_size]\n",
    "\n",
    "            groundtruth.append(labels)\n",
    "            \n",
    "\n",
    "            preds, postive_class_probs = predict_batch(saved_model, batch, device)\n",
    "\n",
    "            prediction.append(preds)\n",
    "            hsi_prediction.append(preds)\n",
    "\n",
    "            hsi_yprobs.append(postive_class_probs)\n",
    "            y_probs.append(postive_class_probs)\n",
    "\n",
    "            for j in range(len(preds)):\n",
    "                index = i + j\n",
    "                hsi_groundtruth.append(labels[j])\n",
    "                # print(f\"{index+1}: prediction = {preds[j]}, confidence: {confs[j]:.4f}, expected: {labels[j].item()}\")\n",
    "                if preds[j] == labels[j].item():\n",
    "                    if labels[j].item() == 0:\n",
    "                        correct0 += 1\n",
    "                    elif labels[j] == 1:\n",
    "                        correct1 += 1\n",
    "\n",
    "        performance_metrics = getScoreTest(hsi_prediction, hsi_yprobs, hsi_groundtruth) \n",
    "        correct = correct0 + correct1\n",
    "        print(f\"Score: {correct}/{total}\")\n",
    "        \n",
    "        score = {\n",
    "            'dataset': hsi_test,\n",
    "            'class0_size': indices_0_shape[0],\n",
    "            'class1_size': indices_1_shape[0],\n",
    "            'correct_0': correct0,\n",
    "            'correct_1': correct1,\n",
    "            'correct_total': correct,\n",
    "            'total': total,\n",
    "            'AUC': float(performance_metrics['AUC']),\n",
    "            'precision': float(performance_metrics['precision']),\n",
    "            'recall': float(performance_metrics['recall']),\n",
    "            'F1 Score': float(performance_metrics['F1 Score']),\n",
    "            'OA': float(performance_metrics['OA']),\n",
    "            'AA': float(performance_metrics['AA']),\n",
    "        }\n",
    "        scores.append(score)\n",
    "\n",
    "if mode == \"full\":\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    os.makedirs(f\"predictions/{timestamp}\", exist_ok=True)\n",
    "    for hsi_full in range(len(dataset)):\n",
    "        if hsi_full > 0:\n",
    "            break\n",
    "        print(f\"tes: {hsi_full}\")\n",
    "        # if hsi_full > 2:\n",
    "        #     break\n",
    "        print(f\"dataset: {hsi_full + 1}\")\n",
    "        hsi_prediction = []\n",
    "        hsi_yprobs = []\n",
    "        hsi_groundtruth = []\n",
    "\n",
    "        score = []\n",
    "        patch_size = 9\n",
    "        half_patch = patch_size // 2\n",
    "\n",
    "        data_sampler = None\n",
    "        batch_size = 64\n",
    "\n",
    "        correct0 = 0\n",
    "        correct1 = 0\n",
    "        matrix = []\n",
    "        gt = []\n",
    "        expected_patch_shape = []\n",
    "        dataset_patches = []\n",
    "        data_loader = []\n",
    "        patch_tensor = []\n",
    "        true_label = [] \n",
    "        x = []\n",
    "        y = []\n",
    "        pred_matrix = []\n",
    "\n",
    "        matrix, gt, indices_0_shape, indices_1_shape = testWithWholeDataset(hsi_full)\n",
    "        print(indices_0_shape[0])\n",
    "        print(indices_1_shape[0])\n",
    "\n",
    "        expected_patch_shape = (2 * half_patch + 1, 2 * half_patch + 1, matrix.shape[2])\n",
    "        dataset_patches = PatchDataset(matrix, gt, half_patch, expected_patch_shape)\n",
    "\n",
    "        if seeded_run:\n",
    "            g = torch.Generator()\n",
    "            g.manual_seed(seed)\n",
    "\n",
    "            data_loader = DataLoader(\n",
    "                dataset_patches,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,  # set to True if needed\n",
    "                num_workers=0,\n",
    "                pin_memory=True,\n",
    "                drop_last=False,\n",
    "                generator=g\n",
    "            )\n",
    "            print(\"generate data loader using seed\")\n",
    "        else:\n",
    "            data_loader = DataLoader(dataset_patches, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        patch_tensor, true_label, x, y = next(iter(data_loader))\n",
    "\n",
    "        print(patch_tensor.size())\n",
    "        print(true_label.size())\n",
    "        print(f\"data loader size: {len(data_loader)}\")\n",
    "\n",
    "        pred_matrix = np.full(gt.shape, -1, dtype=np.int32)\n",
    "        correct = 0\n",
    "\n",
    "        for input_batch, label_batch, x_batch, y_batch in tqdm(data_loader, desc=\"Predicting\"):\n",
    "\n",
    "\n",
    "            preds, confs = predict_batch(saved_model, input_batch, device)\n",
    "\n",
    "            hsi_prediction.append(preds)\n",
    "            prediction.append(preds)\n",
    "            hsi_yprobs.append(confs)\n",
    "            y_probs.append(confs)\n",
    "            \n",
    "            label_batch = label_batch.numpy()\n",
    "            x_batch = x_batch.numpy()\n",
    "            y_batch = y_batch.numpy()\n",
    "\n",
    "            for pred, label, x, y in zip(preds, label_batch, x_batch, y_batch):\n",
    "                hsi_groundtruth.append(label)\n",
    "                groundtruth.append(label)\n",
    "                pred_matrix[x - half_patch, y - half_patch] = pred\n",
    "                if pred == label:\n",
    "                    if label == 0:\n",
    "                        correct0 += 1\n",
    "                    elif label == 1:\n",
    "                        correct1 += 1\n",
    "\n",
    "        performance_metrics = getScore(hsi_prediction, hsi_yprobs, hsi_groundtruth)      \n",
    "            \n",
    "        correct = correct0+correct1\n",
    "        print(f\"correct0 = {correct0}\")\n",
    "        print(f\"correct1 = {correct1}\")\n",
    "        total = gt.shape[0] * gt.shape[1]\n",
    "        print(f\"Score: {correct}/{total}\")\n",
    "\n",
    "        score = {\n",
    "            'dataset': hsi_full,\n",
    "            'class0_size': indices_0_shape[0],\n",
    "            'class1_size': indices_1_shape[0],\n",
    "            'correct_0': correct0,\n",
    "            'correct_1': correct1,\n",
    "            'correct_total': correct,\n",
    "            'total': total,\n",
    "            'AUC': float(performance_metrics['AUC']),\n",
    "            'precision': float(performance_metrics['precision']),\n",
    "            'recall': float(performance_metrics['recall']),\n",
    "            'F1 Score': float(performance_metrics['F1 Score']),\n",
    "            'OA': float(performance_metrics['OA']),\n",
    "            'AA': float(performance_metrics['AA']),\n",
    "        }\n",
    "        # print(score)\n",
    "        scores.append(score)\n",
    "        # Save prediction matrix\n",
    "        # timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        np.save(f\"predictions/{timestamp}/results {hsi_full} MyMethod.npy\", pred_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3802cccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: 0\t 814492/820876\t 8568/29336\t 823060/850212\t 0.9680644356936858 0.6421436500529056\n",
      "dataset: 0\t AUC: 0.9652415903829624 precission: 0.7740847968485625 recall: 0.6421436500529056 F1 SCore0.6852635882420759\n",
      "total: \t\t 814492/410438.0 \t 8568/14668.0 \t 823060/850212\n",
      "acc: 0.9680644356936858\n"
     ]
    }
   ],
   "source": [
    "all_correct = 0\n",
    "all_total = 0\n",
    "all_correct0 = 0\n",
    "all_correct1 = 0\n",
    "class0_total = 0\n",
    "class1_total = 0\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    dataset = score['dataset']\n",
    "    correct0 = score['correct_0']\n",
    "    correct1 = score['correct_1']\n",
    "    class0_size = score['class0_size']\n",
    "    class1_size = score['class1_size']\n",
    "    correct = score['correct_total']\n",
    "    total = score['total']\n",
    "    auc_score = score['AUC']\n",
    "    precission = score['precision']\n",
    "    recall = score['recall']\n",
    "    f1 = score['F1 Score']\n",
    "    oa = score['OA']\n",
    "    aa = score['AA']\n",
    "    \n",
    "    print(f\"dataset: {dataset}\\t\", f'{correct0}/{class0_size}\\t', f'{correct1}/{class1_size}\\t', f'{correct}/{total}\\t', f\"{oa}\", f\"{aa}\")\n",
    "\n",
    "    all_correct += correct\n",
    "    all_total += total\n",
    "    all_correct0 += correct0\n",
    "    all_correct1 += correct1\n",
    "    class0_total += class0_size\n",
    "    class1_total += class1_size\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    dataset = score['dataset']\n",
    "    correct0 = score['correct_0']\n",
    "    correct1 = score['correct_1']\n",
    "    class0_size = score['class0_size']\n",
    "    class1_size = score['class1_size']\n",
    "    correct = score['correct_total']\n",
    "    total = score['total']\n",
    "    auc_score = score['AUC']\n",
    "    precission = score['precision']\n",
    "    recall = score['recall']\n",
    "    f1 = score['F1 Score']\n",
    "    oa = score['OA']\n",
    "    aa = score['AA']\n",
    "    print(f\"dataset: {dataset}\\t\", f\"AUC: {auc_score}\", f\"precission: {precission}\", f\"recall: {recall}\", f\"F1 SCore{f1}\")\n",
    "\n",
    "print(f\"total: \\t\\t {all_correct0}/{class0_total/2} \\t {all_correct1}/{class1_total/2} \\t {all_correct}/{all_total}\")\n",
    "\n",
    "print(f\"acc: {all_correct/all_total}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c74a969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_total_score = {\n",
    "    'dataset': 'Total Dataset',\n",
    "    'correct_0': all_correct0,\n",
    "    'correct_1': all_correct1,\n",
    "    'class0_total': class0_total,\n",
    "    'class1_total': class1_total,\n",
    "    'correct_total': all_correct,\n",
    "    'total': all_total\n",
    "}\n",
    "\n",
    "scores.append(all_total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddab0694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850212\n",
      "850212\n",
      "850212\n"
     ]
    }
   ],
   "source": [
    "groundtruths = groundtruth\n",
    "groundtruth_in = []\n",
    "\n",
    "if mode == \"test\":\n",
    "    for x in groundtruths:\n",
    "        for y in x:\n",
    "            groundtruth_in.append(y)    \n",
    "\n",
    "if mode == \"full\":\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "predictions = prediction\n",
    "prediction_in = []\n",
    "\n",
    "for x in predictions:\n",
    "    for y in x:\n",
    "        prediction_in.append(y)\n",
    "\n",
    "\n",
    "y_prob_in = []\n",
    "\n",
    "for x in y_probs:\n",
    "    for y in x:\n",
    "        y_prob_in.append(y)\n",
    "\n",
    "print(len(groundtruth_in))\n",
    "print(len(prediction_in))\n",
    "print(len(y_prob_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e85a806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823060/850212\n"
     ]
    }
   ],
   "source": [
    "y_test = groundtruth_in\n",
    "y_pred = prediction_in\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for x, y in zip(y_test, y_pred):\n",
    "    total += 1\n",
    "    if x == y:\n",
    "        correct += 1\n",
    "\n",
    "print(f'{correct}/{total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a4761e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_test: [0 1]\n",
      "Sample y_pred values: [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n"
     ]
    }
   ],
   "source": [
    "y_test_np = np.array([label.item() for label in y_test])\n",
    "# Ensure labels are binary (0 and 1)\n",
    "print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "# Check if y_pred is probability (float) or hard prediction (int)\n",
    "print(\"Sample y_pred values:\", y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29515cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(\n",
    "    {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Two Models')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6a288ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7741\n",
      "Recall:    0.6421\n",
      "F1 Score:  0.6853\n",
      "OA:        0.9681\n",
      "AA:        0.6421\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "# Precision, Recall, F1\n",
    "precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "# Overall Accuracy (OA)\n",
    "oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Average Accuracy (AA) — mean of per-class accuracies\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "aa = per_class_acc.mean()\n",
    "\n",
    "# Print all metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"OA:        {oa:.4f}\")\n",
    "print(f\"AA:        {aa:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8abb93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {\n",
    "    'AUC': float(roc_auc),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'F1 Score': float(f1),\n",
    "    'OA': float(oa),\n",
    "    'AA': float(aa),\n",
    "}\n",
    "result_json = {\n",
    "    'prediction' : scores,\n",
    "    'performance' : performance,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c0c5d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [{'dataset': 0, 'class0_size': 820876, 'class1_size': 29336, 'correct_0': 814492, 'correct_1': 8568, 'correct_total': 823060, 'total': 850212, 'AUC': 0.9652415903829624, 'precision': 0.7740847968485625, 'recall': 0.6421436500529056, 'F1 Score': 0.6852635882420759, 'OA': 0.9680644356936858, 'AA': 0.6421436500529056}, {'dataset': 'Total Dataset', 'correct_0': 814492, 'correct_1': 8568, 'class0_total': 820876, 'class1_total': 29336, 'correct_total': 823060, 'total': 850212}], 'performance': {'AUC': 0.9652415903829624, 'precision': 0.7740847968485625, 'recall': 0.6421436500529056, 'F1 Score': 0.6852635882420759, 'OA': 0.9680644356936858, 'AA': 0.6421436500529056}}\n",
      "JSON saved to results.json\n"
     ]
    }
   ],
   "source": [
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "print(result_json)\n",
    "\n",
    "with open(f\"performance/MyMethod {timestamp}_results.json\", \"w\") as f:\n",
    "    json.dump(result_json, f, indent=2)\n",
    "\n",
    "print(\"JSON saved to results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "901b6440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 40.3482 seconds\n",
      "predicting time: 501.1889 seconds\n",
      "Run time: 541.5371 seconds\n",
      "mode used: full\n",
      "finetune Parameter 8310914\n",
      "Pretrain Parameter 10280704\n",
      "saved_model for testing Parameter 8310914\n",
      "20250726_114802\n",
      "seet used: 10\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Train time: {train_time - start_time:.4f} seconds\")\n",
    "print(f\"predicting time: {end_time - train_time:.4f} seconds\")\n",
    "print(f\"Run time: {end_time - start_time:.4f} seconds\")\n",
    "print(f\"mode used: {mode}\")\n",
    "print(f\"finetune Parameter {finetune_parameter}\")\n",
    "print(f\"Pretrain Parameter {pretrain_parameters}\")\n",
    "print(f\"saved_model for testing Parameter {saved_model_parameters}\")\n",
    "print(timestamp)\n",
    "print(f\"seet used: {seed}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_repo_ta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

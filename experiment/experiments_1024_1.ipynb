{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a5a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "GPU Name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from HSI_class import HSI\n",
    "import createSample as CS\n",
    "import augmentation as aug\n",
    "\n",
    "import simsiam.loader\n",
    "import random\n",
    "import zeroPadding\n",
    "start_time = time.time()\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "\n",
    "# If available, print the GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    \n",
    "sample_per_class = 5\n",
    "num_per_category_augment_1 = 10\n",
    "num_per_category_augment_2 = 10\n",
    "patch_size = 9\n",
    "n_category = 2\n",
    "band_size = 224\n",
    "base_encoder = 'vgg16'\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "batch_size = 20\n",
    "test_size = 0.5\n",
    "\n",
    "random_indices = 1\n",
    "\n",
    "seeded_run = True\n",
    "seed = 10\n",
    "\n",
    "mode = \"full\"\n",
    "project_path = r\"C:\\Users\\Asus TUF\\Documents\\code\\TA\"\n",
    "# project_path = r\"D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25da8a0f-8f90-4f9e-9a04-991692e9ebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed has been set\n",
      "seet used: 10\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # PyTorch determinism\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "if seeded_run:\n",
    "    set_seed(seed)\n",
    "    print(\"seed has been set\")\n",
    "    print(f\"seet used: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "578786fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM01.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM02.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM03.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM04.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM05.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM06.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM07.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM08.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM09.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM10.mat\n",
      "random: 1\n",
      "generating random indices\n",
      "hsi shape\n",
      "(1243, 684, 224)\n",
      "creating 5 Randomly chosen 0 indices:\n",
      "creating 5 Randomly chosen 1 indices:\n",
      "indices 0 used: [(np.int64(910), np.int64(192)), (np.int64(51), np.int64(255)), (np.int64(689), np.int64(202)), (np.int64(772), np.int64(547)), (np.int64(920), np.int64(471))]\n",
      "indices 1 used: [(np.int64(22), np.int64(455)), (np.int64(170), np.int64(145)), (np.int64(410), np.int64(233)), (np.int64(1055), np.int64(123)), (np.int64(469), np.int64(582))]\n",
      "number of element equal 0 5\n",
      "number of element equal 1 5\n",
      "x_train shape: (10, 9, 9, 224)\n",
      "y_train shape: (10,)\n",
      "hasil augmentasi 1 shape: (20, 9, 9, 224)\n",
      "label augmentai 1 shape: (20,)\n",
      "hasil augmentasi 2 shape: (20, 9, 9, 224)\n",
      "label augmentasi 2 shape: (20,)\n",
      "label augment:\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "hasil augmentasi gabungan untuk training: (40, 9, 9, 224)\n",
      "label augmentasi gabungan: (40,)\n",
      "Element 0 occurs 20 times.\n",
      "Element 1 occurs 20 times.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = rf\"{project_path}\\Hyperspectral oil spill detection datasets\"\n",
    "\n",
    "dataset = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if i > 9:\n",
    "        break\n",
    "    file_path = os.path.join(dataset_path, filename)\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        hsi = HSI(file_path)\n",
    "        dataset.append(hsi)\n",
    "    i += 1\n",
    "\n",
    "train_hsi = dataset[0]\n",
    "patch_size = patch_size\n",
    "half_patch = patch_size // 2\n",
    "sample_per_class = sample_per_class\n",
    "\n",
    "train_indices_0 = []\n",
    "train_indices_1 = []\n",
    "\n",
    "print(f\"random: {random_indices}\")\n",
    "\n",
    "if random_indices:\n",
    "    print(\"generating random indices\")\n",
    "    selected_patches_0, selected_patches_1, train_indices_0, train_indices_1 = CS.createSample(train_hsi, patch_size, sample_per_class)\n",
    "else:\n",
    "    print(\"using generated indices\")\n",
    "    train_indices_0 = [(np.int64(188), np.int64(124)), (np.int64(523), np.int64(150)), (np.int64(1003), np.int64(474)), (np.int64(616), np.int64(508)), (np.int64(905), np.int64(552))]\n",
    "    train_indices_1 = [(np.int64(106), np.int64(606)), (np.int64(297), np.int64(468)), (np.int64(926), np.int64(35)), (np.int64(536), np.int64(519)), (np.int64(508), np.int64(442))]\n",
    "\n",
    "    selected_patches_0, selected_patches_1 = CS.getSample(train_hsi, patch_size, sample_per_class, train_indices_0, train_indices_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_indices = train_indices_0 +  train_indices_1\n",
    "\n",
    "# Concatenating along axis 0\n",
    "x_train = np.concatenate((selected_patches_0, selected_patches_1), )\n",
    "\n",
    "y_train = np.array([])\n",
    "\n",
    "gt = train_hsi.gt\n",
    "for indice in train_indices:\n",
    "    # print(gt[indice[0]][indice[1]])\n",
    "    y_train = np.append(y_train, gt[indice[0]][indice[1]])\n",
    "\n",
    "count = np.count_nonzero(y_train == 0)  # Count elements equal to 0\n",
    "print(f'number of element equal 0 {count}')\n",
    "\n",
    "count = np.count_nonzero(y_train == 1)  # Count elements equal to 1\n",
    "print(f'number of element equal 1 {count}')\n",
    "\n",
    "# Print shape to verify\n",
    "print(f\"x_train shape: {x_train.shape}\")  # Expected output: (10, 9, 9, 224)\n",
    "print(f\"y_train shape: {y_train.shape}\") \n",
    "\n",
    "\n",
    "n_category = n_category\n",
    "band_size = band_size\n",
    "num_per_category_augment_1 = num_per_category_augment_1\n",
    "num_per_category_augment_2 = num_per_category_augment_2\n",
    "\n",
    "data_augment1, label_augment1 = aug.Augment_data(x_train, y_train, n_category, patch_size, band_size, num_per_category_augment_1)\n",
    "\n",
    "data_augment2, label_augment2 = aug.Augment_data2(x_train, y_train, n_category, patch_size, band_size, num_per_category_augment_2)\n",
    "\n",
    "print(f\"hasil augmentasi 1 shape: {data_augment1.shape}\")\n",
    "print(f\"label augmentai 1 shape: {label_augment1.shape}\")\n",
    "\n",
    "print(f\"hasil augmentasi 2 shape: {data_augment2.shape}\")\n",
    "print(f\"label augmentasi 2 shape: {label_augment2.shape}\")\n",
    "\n",
    "print(\"label augment:\")\n",
    "print(label_augment1)\n",
    "print(label_augment2)\n",
    "\n",
    "data_augment = np.concatenate((data_augment1, data_augment2))\n",
    "label_augment = np.concatenate((label_augment1, label_augment2))\n",
    "\n",
    "print(f\"hasil augmentasi gabungan untuk training: {data_augment.shape}\")\n",
    "print(f\"label augmentasi gabungan: {label_augment.shape}\")\n",
    "\n",
    "\n",
    "# Count occurrences of each unique element\n",
    "counts = np.bincount(label_augment)\n",
    "\n",
    "# Print results\n",
    "for i, count in enumerate(counts):\n",
    "    print(f\"Element {i} occurs {count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cab1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    \"\"\"\n",
    "    Build a SimSiam model.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_encoder, spectral_band, dim=2048, pred_dim=512):\n",
    "        \"\"\"\n",
    "        dim: feature dimension (default: 2048)\n",
    "        pred_dim: hidden dimension of the predictor (default: 512)\n",
    "        \"\"\"\n",
    "        super(SimSiam, self).__init__()\n",
    "    \n",
    "        self.encoder = base_encoder(pretrained=True)\n",
    "\n",
    "        self.encoder.features = nn.Sequential(*list(self.encoder.features.children())[28:])\n",
    "        self.encoder.features[0] = nn.Conv2d(spectral_band, 512, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.encoder.features[1] = nn.ReLU(inplace=True)\n",
    "        self.encoder.features[2] = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.encoder.classifier[0] = nn.Linear(in_features=25088, out_features=1024, bias=True)\n",
    "        self.encoder.classifier[1] = nn.BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.encoder.classifier[3] = nn.Linear(in_features=1024, out_features=1024, bias=False)\n",
    "        self.encoder.classifier[4] = nn.BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        # Modify the classifier to match the desired output dimensions\n",
    "        # self.encoder.classifier[0] = nn.Linear(512, 4096, bias=True)\n",
    "        self.encoder.classifier[6] = nn.Linear(1024, dim)\n",
    "\n",
    "        # # Fix: Get the correct input dimension from VGG16 classifier\n",
    "        prev_dim = self.encoder.classifier[3].out_features\n",
    "\n",
    "        # Fix: Assign modified layers to classifier instead of non-existing 'fc'\n",
    "        self.encoder.classifier[6] = nn.Sequential(\n",
    "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(prev_dim),\n",
    "                                        nn.ReLU(inplace=True), # first layer\n",
    "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(prev_dim),\n",
    "                                        nn.ReLU(inplace=True), # second layer\n",
    "                                        self.encoder.classifier[6],\n",
    "                                        nn.BatchNorm1d(dim, affine=False)) # output layer# output layer\n",
    "                                        \n",
    "        self.encoder.classifier[6][6].bias.requires_grad = False\n",
    "        # self.projector[6].bias.requires_grad = False\n",
    "\n",
    "        # build a 3-layer projector\n",
    "        # prev_dim = self.encoder.fc.weight.shape[1]\n",
    "        # self.encoder.fc = nn.Sequential(nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "        #                                 nn.BatchNorm1d(prev_dim),\n",
    "        #                                 nn.ReLU(inplace=True), # first layer\n",
    "        #                                 nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "        #                                 nn.BatchNorm1d(prev_dim),\n",
    "        #                                 nn.ReLU(inplace=True), # second layer\n",
    "        #                                 self.encoder.fc,\n",
    "        #                                 nn.BatchNorm1d(dim, affine=False)) # output layer\n",
    "        # self.encoder.fc[6].bias.requires_grad = False # hack: not use bias as it is followed by BN\n",
    "\n",
    "        # build a 2-layer predictor\n",
    "        self.predictor = nn.Sequential(nn.Linear(dim, pred_dim, bias=False),\n",
    "                                        nn.BatchNorm1d(pred_dim),\n",
    "                                        nn.ReLU(inplace=True), # hidden layer\n",
    "                                        nn.Linear(pred_dim, dim)) # output layer\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            x1: first views of images\n",
    "            x2: second views of images\n",
    "        Output:\n",
    "            p1, p2, z1, z2: predictors and targets of the network\n",
    "            See Sec. 3 of https://arxiv.org/abs/2011.10566 for detailed notations\n",
    "        \"\"\"\n",
    "\n",
    "       \n",
    "        z1 = self.encoder.features(x1) # NxC\n",
    "        z2 = self.encoder.features(x2) # NxC\n",
    "      \n",
    "\n",
    "        z1 = self.encoder.avgpool(z1)\n",
    "        z2 = self.encoder.avgpool(z2)\n",
    "\n",
    "\n",
    "        z1 = torch.flatten(z1, 1)\n",
    "        z2 = torch.flatten(z2, 1)\n",
    "   \n",
    "        z1 = self.encoder.classifier(z1)\n",
    "        z2 = self.encoder.classifier(z2)\n",
    "\n",
    "\n",
    "\n",
    "        p1 = self.predictor(z1) # NxC\n",
    "        p2 = self.predictor(z2) # NxC\n",
    "\n",
    "        return p1, p2, z1.detach(), z2.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4613ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'vgg16'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimSiam(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Sequential(\n",
      "        (0): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "        (7): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (predictor): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=512, bias=False)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  )\n",
      ")\n",
      "parameter 34077184\n"
     ]
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "\n",
    "# create model\n",
    "base_encoder = base_encoder\n",
    "print(\"=> creating model '{}'\".format(base_encoder))\n",
    "pretrain_model = SimSiam(models.__dict__[base_encoder],224)\n",
    "\n",
    "\n",
    "lr = 0.01\n",
    "init_lr = lr * batch_size / 256\n",
    "gpu = 0\n",
    "\n",
    "print(pretrain_model)\n",
    "pretrain_parameters = sum(p.numel() for p in pretrain_model.parameters())\n",
    "print(f\"parameter {pretrain_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07ffc071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 224, 9, 9])\n",
      "input2 shape: torch.Size([1, 224, 9, 9])\n",
      "p1 shape torch.Size([1, 2048]), p2 shape torch.Size([1, 2048])\n",
      "z1 shape torch.Size([1, 2048]), z2 shape torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "test = data_augment[0]\n",
    "input = torch.tensor(test).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "test2 = data_augment[1]\n",
    "test2 = torch.tensor(test2).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "input2 = test2\n",
    "\n",
    "\n",
    "print(f\"input shape: {input.shape}\")\n",
    "print(f\"input2 shape: {input2.shape}\")\n",
    "\n",
    "# Pass the input through the model\n",
    "pretrain_model.eval()\n",
    "p1, p2, z1, z2  = pretrain_model(input, input2)\n",
    "\n",
    "print(f\"p1 shape {p1.shape}, p2 shape {p2.shape}\")\n",
    "print(f\"z1 shape {z1.shape}, z2 shape {z2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0224d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(40, 9, 9, 224)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CosineSimilarity(dim=1).cuda(gpu)\n",
    "print(gpu)\n",
    "optim_params = pretrain_model.parameters()\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "optimizer = torch.optim.SGD(optim_params, init_lr,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "augmentation = [\n",
    "    transforms.RandomHorizontalFlip(),  # Flip along width\n",
    "    transforms.RandomVerticalFlip(),    # Flip along height\n",
    "    transforms.RandomRotation(20),      # Rotate image slightly\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize hyperspectral data\n",
    "]\n",
    "\n",
    "transform = simsiam.loader.TwoCropsTransform(transforms.Compose(augmentation))\n",
    "\n",
    "print(data_augment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd6786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([40, 224, 9, 9])\n",
      "generate data loader using seed\n",
      "bacth size: torch.Size([20, 224, 9, 9])\n",
      "length batch: 20\n",
      "Train loader size: 2\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (Tensor or list of Tensors): Preloaded images of shape (N, 9, 9, 224)\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.images = images  # Assuming it's a list or tensor\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img1 = self.transform(img)  # First augmentation\n",
    "            img2 = self.transform(img)  # Second augmentation\n",
    "        \n",
    "            return img1, img2  # Return both augmented versions\n",
    "        \n",
    "        return img, img  # If no transform is provided, return the original image twice\n",
    "\n",
    "\n",
    "# Example usage\n",
    "pretrain_preloaded_image = data_augment \n",
    "\n",
    "pretrain_X_train = torch.tensor(pretrain_preloaded_image)\n",
    "pretrain_X_train = pretrain_X_train.to(torch.float32)\n",
    "pretrain_X_train = pretrain_X_train.permute(0, 3, 1, 2)\n",
    "print(f\"X_train shape: {pretrain_X_train.shape}\")\n",
    "\n",
    "# Define transformations if needed\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),  # Example normalization\n",
    "])\n",
    "\n",
    "pretrain_train_dataset = CustomDataset(pretrain_X_train, transform=transform)\n",
    "\n",
    "train_sampler = None\n",
    "\n",
    "if seeded_run:\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    \n",
    "    pretrain_train_loader = DataLoader(\n",
    "        pretrain_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    print(\"generate data loader using seed\")\n",
    "else:\n",
    "    pretrain_train_loader = DataLoader(\n",
    "        pretrain_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(train_sampler is None),\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 7. Check Output\n",
    "\n",
    "batch1, batch2 = next(iter(pretrain_train_loader))\n",
    "\n",
    "print(f\"bacth size: {batch1.size()}\")\n",
    "print(f\"length batch: {len(batch1)}\")  # Should print 2 (Two transformed views per image)\n",
    "print(f\"Train loader size: {len(pretrain_train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c59999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if 'fix_lr' in param_group and param_group['fix_lr']:\n",
    "            param_group['lr'] = init_lr\n",
    "        else:\n",
    "            param_group['lr'] = cur_lr\n",
    "\n",
    "class Pretrain_AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "    \n",
    "\n",
    "class Pretrain_ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "    \n",
    "def pretrain_save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6abedcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_train(train_loader, model, criterion, optimizer, epoch, device):\n",
    "    batch_time = Pretrain_AverageMeter('Time', ':6.3f')\n",
    "    data_time = Pretrain_AverageMeter('Data', ':6.3f')\n",
    "    losses = Pretrain_AverageMeter('Loss', ':.4f')\n",
    "    progress = Pretrain_ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    for i, (images1, images2) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input1 = images1.to(device, non_blocking=True)\n",
    "        input2 = images2.to(device, non_blocking=True)\n",
    "\n",
    "        p1, p2, z1, z2 = model(x1=input1, x2=input2) \n",
    "        loss = -(criterion(p1, z2).mean() + criterion(p2, z1).mean()) * 0.5\n",
    "\n",
    "        losses.update(loss.item(), input1.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "    # Return average training loss for early stopping\n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1714672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch: [0][0/2]\tTime  0.613 ( 0.613)\tData  0.013 ( 0.013)\tLoss 0.0023 (0.0023)\n",
      "Epoch 1: Average Training Loss: 0.000392\n",
      "✅ New best model saved with loss 0.000392\n",
      "Epoch: [1][0/2]\tTime  0.050 ( 0.050)\tData  0.018 ( 0.018)\tLoss -0.0026 (-0.0026)\n",
      "Epoch 2: Average Training Loss: 0.000606\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [2][0/2]\tTime  0.045 ( 0.045)\tData  0.014 ( 0.014)\tLoss -0.0059 (-0.0059)\n",
      "Epoch 3: Average Training Loss: -0.003100\n",
      "✅ New best model saved with loss -0.003100\n",
      "Epoch: [3][0/2]\tTime  0.040 ( 0.040)\tData  0.008 ( 0.008)\tLoss -0.0000 (-0.0000)\n",
      "Epoch 4: Average Training Loss: 0.000730\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [4][0/2]\tTime  0.045 ( 0.045)\tData  0.014 ( 0.014)\tLoss 0.0002 (0.0002)\n",
      "Epoch 5: Average Training Loss: -0.002917\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [5][0/2]\tTime  0.053 ( 0.053)\tData  0.016 ( 0.016)\tLoss -0.0046 (-0.0046)\n",
      "Epoch 6: Average Training Loss: -0.004918\n",
      "✅ New best model saved with loss -0.004918\n",
      "Epoch: [6][0/2]\tTime  0.034 ( 0.034)\tData  0.000 ( 0.000)\tLoss -0.0069 (-0.0069)\n",
      "Epoch 7: Average Training Loss: -0.008514\n",
      "✅ New best model saved with loss -0.008514\n",
      "Epoch: [7][0/2]\tTime  0.034 ( 0.034)\tData  0.009 ( 0.009)\tLoss -0.0038 (-0.0038)\n",
      "Epoch 8: Average Training Loss: -0.005639\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [8][0/2]\tTime  0.041 ( 0.041)\tData  0.009 ( 0.009)\tLoss -0.0073 (-0.0073)\n",
      "Epoch 9: Average Training Loss: -0.004224\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [9][0/2]\tTime  0.038 ( 0.038)\tData  0.012 ( 0.012)\tLoss -0.0080 (-0.0080)\n",
      "Epoch 10: Average Training Loss: -0.005412\n",
      "❌ No improvement. Patience: 3/50\n",
      "Epoch: [10][0/2]\tTime  0.045 ( 0.045)\tData  0.011 ( 0.011)\tLoss -0.0098 (-0.0098)\n",
      "Epoch 11: Average Training Loss: -0.008270\n",
      "❌ No improvement. Patience: 4/50\n",
      "Epoch: [11][0/2]\tTime  0.053 ( 0.053)\tData  0.016 ( 0.016)\tLoss -0.0151 (-0.0151)\n",
      "Epoch 12: Average Training Loss: -0.013016\n",
      "✅ New best model saved with loss -0.013016\n",
      "Epoch: [12][0/2]\tTime  0.038 ( 0.038)\tData  0.007 ( 0.007)\tLoss -0.0063 (-0.0063)\n",
      "Epoch 13: Average Training Loss: -0.006550\n",
      "❌ No improvement. Patience: 1/50\n",
      "Epoch: [13][0/2]\tTime  0.043 ( 0.043)\tData  0.006 ( 0.006)\tLoss -0.0034 (-0.0034)\n",
      "Epoch 14: Average Training Loss: -0.006358\n",
      "❌ No improvement. Patience: 2/50\n",
      "Epoch: [14][0/2]\tTime  0.051 ( 0.051)\tData  0.012 ( 0.012)\tLoss -0.0043 (-0.0043)\n",
      "Epoch 15: Average Training Loss: -0.005094\n",
      "❌ No improvement. Patience: 3/50\n",
      "Epoch: [15][0/2]\tTime  0.042 ( 0.042)\tData  0.012 ( 0.012)\tLoss -0.0091 (-0.0091)\n",
      "Epoch 16: Average Training Loss: -0.010065\n",
      "❌ No improvement. Patience: 4/50\n",
      "Epoch: [16][0/2]\tTime  0.043 ( 0.043)\tData  0.015 ( 0.015)\tLoss -0.0062 (-0.0062)\n",
      "Epoch 17: Average Training Loss: -0.009849\n",
      "❌ No improvement. Patience: 5/50\n",
      "Epoch: [17][0/2]\tTime  0.049 ( 0.049)\tData  0.012 ( 0.012)\tLoss -0.0113 (-0.0113)\n",
      "Epoch 18: Average Training Loss: -0.009949\n",
      "❌ No improvement. Patience: 6/50\n",
      "Epoch: [18][0/2]\tTime  0.060 ( 0.060)\tData  0.022 ( 0.022)\tLoss -0.0088 (-0.0088)\n",
      "Epoch 19: Average Training Loss: -0.007794\n",
      "❌ No improvement. Patience: 7/50\n",
      "Epoch: [19][0/2]\tTime  0.049 ( 0.049)\tData  0.008 ( 0.008)\tLoss -0.0057 (-0.0057)\n",
      "Epoch 20: Average Training Loss: -0.006014\n",
      "❌ No improvement. Patience: 8/50\n"
     ]
    }
   ],
   "source": [
    "# Early stopping parameters\n",
    "best_loss = float('inf')\n",
    "patience = 50  # Number of epochs to wait for improvement\n",
    "patience_counter = 0\n",
    "\n",
    "start_epoch = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "pretrain_model.to(device)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "filename = f\"{timestamp}_model.pth.tar\"\n",
    "filepath = f\"models/pretrain/{filename}\"\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    pretrain_adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "\n",
    "    # Train and get average loss\n",
    "    avg_loss = pretrain_train(pretrain_train_loader, pretrain_model, criterion, optimizer, epoch, device)\n",
    "    print(f\"Epoch {epoch + 1}: Average Training Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': 'vgg16',\n",
    "            'state_dict': pretrain_model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'best_loss': best_loss\n",
    "        }, filepath)\n",
    "\n",
    "        print(f\"✅ New best model saved with loss {best_loss:.6f}\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"❌ No improvement. Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d5f40d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain Parameter 34077184\n",
      "models\\pretrain\\20250726_120310_model.pth.tar\n"
     ]
    }
   ],
   "source": [
    "pretrain_parameters = sum(p.numel() for p in pretrain_model.parameters())\n",
    "print(f\"pretrain Parameter {pretrain_parameters}\")\n",
    "\n",
    "pretrained = rf'models\\pretrain\\{filename}'\n",
    "print(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32ba8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "\n",
    "class VGG16_HSI(nn.Module):\n",
    "    def __init__(self, num_classes=2, spectral_band=224):\n",
    "        super(VGG16_HSI, self).__init__()\n",
    "\n",
    "        self.encoder =  vgg16(pretrained=True)\n",
    "\n",
    "        self.encoder.features = nn.Sequential(*list(self.encoder.features.children())[28:])\n",
    "        self.encoder.features[0] = nn.Conv2d(spectral_band, 512, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.encoder.features[1] = nn.ReLU(inplace=True)\n",
    "        self.encoder.features[2] = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        self.encoder.classifier[0] = nn.Linear(in_features=25088, out_features=1024, bias=True)\n",
    "        self.encoder.classifier[1] = nn.BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.encoder.classifier[3] = nn.Linear(in_features=1024, out_features=1024, bias=False)\n",
    "        self.encoder.classifier[4] = nn.BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        # Modify the classifier to match the desired output dimensions\n",
    "        # self.encoder.classifier[0] = nn.Linear(512, 4096, bias=True)\n",
    "        self.encoder.classifier[6] = nn.Linear(1024, 2048)\n",
    "        self.encoder.added_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=128, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3, inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=2, bias=True)\n",
    "        )   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder.features(x)  # Pass to VGG-16\n",
    "        x = self.encoder.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.encoder.classifier(x)  # Final classification layer\n",
    "        x = self.encoder.added_classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee42b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: 0 for training\n",
      "=> creating model\n",
      "finetune_parameter 30138242\n",
      "VGG16_HSI(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gpu = 0\n",
    "\n",
    "print(\"Use GPU: {} for training\".format(gpu))\n",
    "\n",
    "print(\"=> creating model\")\n",
    "\n",
    "model_finetune = VGG16_HSI()\n",
    "finetune_parameter = sum(p.numel() for p in model_finetune.parameters())\n",
    "print(f\"finetune_parameter {finetune_parameter}\")\n",
    "\n",
    "print(model_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9fa84ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'models\\pretrain\\20250726_120310_model.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_8900\\2432251866.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_8900\\2432251866.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually loading parameters with remapping:\n",
      "\n",
      "✓ Loaded: encoder.features.0.weight → encoder.features.0.weight\n",
      "✓ Loaded: encoder.features.0.bias → encoder.features.0.bias\n",
      "✓ Loaded: encoder.classifier.0.weight → encoder.classifier.0.weight\n",
      "✓ Loaded: encoder.classifier.0.bias → encoder.classifier.0.bias\n",
      "✓ Loaded: encoder.classifier.1.weight → encoder.classifier.1.weight\n",
      "✓ Loaded: encoder.classifier.1.bias → encoder.classifier.1.bias\n",
      "✓ Loaded: encoder.classifier.1.running_mean → encoder.classifier.1.running_mean\n",
      "✓ Loaded: encoder.classifier.1.running_var → encoder.classifier.1.running_var\n",
      "✓ Loaded: encoder.classifier.1.num_batches_tracked → encoder.classifier.1.num_batches_tracked\n",
      "✓ Loaded: encoder.classifier.3.weight → encoder.classifier.3.weight\n",
      "✓ Loaded: encoder.classifier.4.weight → encoder.classifier.4.weight\n",
      "✓ Loaded: encoder.classifier.4.bias → encoder.classifier.4.bias\n",
      "✓ Loaded: encoder.classifier.4.running_mean → encoder.classifier.4.running_mean\n",
      "✓ Loaded: encoder.classifier.4.running_var → encoder.classifier.4.running_var\n",
      "✓ Loaded: encoder.classifier.4.num_batches_tracked → encoder.classifier.4.num_batches_tracked\n",
      "❌ Key not found in model: encoder.classifier.6.0.weight\n",
      "❌ Key not found in model: encoder.classifier.6.1.weight\n",
      "❌ Key not found in model: encoder.classifier.6.1.bias\n",
      "❌ Key not found in model: encoder.classifier.6.1.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.1.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.1.num_batches_tracked\n",
      "❌ Key not found in model: encoder.classifier.6.3.weight\n",
      "❌ Key not found in model: encoder.classifier.6.4.weight\n",
      "❌ Key not found in model: encoder.classifier.6.4.bias\n",
      "❌ Key not found in model: encoder.classifier.6.4.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.4.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.4.num_batches_tracked\n",
      "✓ Loaded: encoder.classifier.6.6.weight → encoder.classifier.6.weight\n",
      "✓ Loaded: encoder.classifier.6.6.bias → encoder.classifier.6.bias\n",
      "❌ Key not found in model: encoder.classifier.6.7.running_mean\n",
      "❌ Key not found in model: encoder.classifier.6.7.running_var\n",
      "❌ Key not found in model: encoder.classifier.6.7.num_batches_tracked\n",
      "❌ Key not found in model: predictor.0.weight\n",
      "❌ Key not found in model: predictor.1.weight\n",
      "❌ Key not found in model: predictor.1.bias\n",
      "❌ Key not found in model: predictor.1.running_mean\n",
      "❌ Key not found in model: predictor.1.running_var\n",
      "❌ Key not found in model: predictor.1.num_batches_tracked\n",
      "❌ Key not found in model: predictor.3.weight\n",
      "❌ Key not found in model: predictor.3.bias\n",
      "\n",
      "=== Summary ===\n",
      "Total checkpoint keys: 40\n",
      "Successfully loaded: 17\n",
      "Missing keys in model: 23\n",
      "Shape mismatches: 0\n",
      "\n",
      "Missing keys:\n",
      "  encoder.classifier.6.0.weight\n",
      "  encoder.classifier.6.1.weight\n",
      "  encoder.classifier.6.1.bias\n",
      "  encoder.classifier.6.1.running_mean\n",
      "  encoder.classifier.6.1.running_var\n",
      "  encoder.classifier.6.1.num_batches_tracked\n",
      "  encoder.classifier.6.3.weight\n",
      "  encoder.classifier.6.4.weight\n",
      "  encoder.classifier.6.4.bias\n",
      "  encoder.classifier.6.4.running_mean\n",
      "  encoder.classifier.6.4.running_var\n",
      "  encoder.classifier.6.4.num_batches_tracked\n",
      "  encoder.classifier.6.7.running_mean\n",
      "  encoder.classifier.6.7.running_var\n",
      "  encoder.classifier.6.7.num_batches_tracked\n",
      "  predictor.0.weight\n",
      "  predictor.1.weight\n",
      "  predictor.1.bias\n",
      "  predictor.1.running_mean\n",
      "  predictor.1.running_var\n",
      "  predictor.1.num_batches_tracked\n",
      "  predictor.3.weight\n",
      "  predictor.3.bias\n",
      "=> loaded pre-trained model 'models\\pretrain\\20250726_120310_model.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "if pretrained:\n",
    "    if os.path.isfile(pretrained):\n",
    "        print(\"=> loading checkpoint '{}'\".format(pretrained))\n",
    "        checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
    "\n",
    "        checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
    "        pretrained_dict = checkpoint['state_dict']\n",
    "        finetune_model_dict = model_finetune.state_dict()\n",
    "\n",
    "        # Key remapping: map .6.6.weight → .6.weight and .6.6.bias → .6.bias\n",
    "        key_mapping = {\n",
    "            'encoder.classifier.6.6.weight': 'encoder.classifier.6.weight',\n",
    "            'encoder.classifier.6.6.bias': 'encoder.classifier.6.bias',\n",
    "        }\n",
    "\n",
    "        # Prepare containers\n",
    "        remapped_dict = {}\n",
    "        loaded_keys = []\n",
    "        shape_mismatches = []\n",
    "        missing_keys = []\n",
    "\n",
    "        print(\"Manually loading parameters with remapping:\\n\")\n",
    "\n",
    "        for k, v in pretrained_dict.items():\n",
    "            new_k = key_mapping.get(k, k)  # Remap if necessary\n",
    "            if new_k in finetune_model_dict:\n",
    "                if finetune_model_dict[new_k].shape == v.shape:\n",
    "                    remapped_dict[new_k] = v\n",
    "                    loaded_keys.append((k, new_k))\n",
    "                    print(f\"✓ Loaded: {k} → {new_k}\")\n",
    "                else:\n",
    "                    shape_mismatches.append((new_k, finetune_model_dict[new_k].shape, v.shape))\n",
    "                    print(f\"⚠️ Shape mismatch: {new_k} | model: {finetune_model_dict[new_k].shape} vs checkpoint: {v.shape}\")\n",
    "            else:\n",
    "                missing_keys.append(new_k)\n",
    "                print(f\"❌ Key not found in model: {new_k}\")\n",
    "\n",
    "        # Load state dict\n",
    "        model_finetune.load_state_dict(remapped_dict, strict=False)\n",
    "\n",
    "        # Summary\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(f\"Total checkpoint keys: {len(pretrained_dict)}\")\n",
    "        print(f\"Successfully loaded: {len(loaded_keys)}\")\n",
    "        print(f\"Missing keys in model: {len(missing_keys)}\")\n",
    "        print(f\"Shape mismatches: {len(shape_mismatches)}\")\n",
    "\n",
    "        if missing_keys:\n",
    "            print(\"\\nMissing keys:\")\n",
    "            for key in missing_keys:\n",
    "                print(f\"  {key}\")\n",
    "\n",
    "        if shape_mismatches:\n",
    "            print(\"\\nShape mismatches:\")\n",
    "            for key, model_shape, ckpt_shape in shape_mismatches:\n",
    "                print(f\"  {key} | model: {model_shape}, checkpoint: {ckpt_shape}\")\n",
    "\n",
    "  \n",
    "     \n",
    "\n",
    "        print(\"=> loaded pre-trained model '{}'\".format(pretrained))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(pretrained))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28417fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16_HSI(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "encoder.features.0.weight: requires_grad=False\n",
      "encoder.features.0.bias: requires_grad=False\n",
      "encoder.classifier.0.weight: requires_grad=False\n",
      "encoder.classifier.0.bias: requires_grad=False\n",
      "encoder.classifier.1.weight: requires_grad=False\n",
      "encoder.classifier.1.bias: requires_grad=False\n",
      "encoder.classifier.3.weight: requires_grad=False\n",
      "encoder.classifier.4.weight: requires_grad=False\n",
      "encoder.classifier.4.bias: requires_grad=False\n",
      "encoder.classifier.6.weight: requires_grad=False\n",
      "encoder.classifier.6.bias: requires_grad=False\n",
      "encoder.added_classifier.0.weight: requires_grad=True\n",
      "encoder.added_classifier.0.bias: requires_grad=True\n",
      "encoder.added_classifier.3.weight: requires_grad=True\n",
      "encoder.added_classifier.3.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for param in model_finetune.encoder.features.parameters():\n",
    "    param.requires_grad = False  # Freeze convolutional layers\n",
    "\n",
    "for param in model_finetune.encoder.classifier.parameters():\n",
    "    param.requires_grad = False  # Freeze all but the last FC layer\n",
    "\n",
    "\n",
    "print(model_finetune)\n",
    "# Check which layers are trainable\n",
    "for name, param in model_finetune.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5f67fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 224, 9, 9])\n",
      "input2 shape: torch.Size([1, 224, 9, 9])\n",
      "output shape torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "test = data_augment[0]\n",
    "test = torch.tensor(test).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "input = test\n",
    "\n",
    "\n",
    "test2 = data_augment[1]\n",
    "test2 = torch.tensor(test2).to(torch.float32).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "input2 = test2\n",
    "\n",
    "\n",
    "print(f\"input shape: {input.shape}\")\n",
    "print(f\"input2 shape: {input2.shape}\")\n",
    "\n",
    "# Pass the input through the model\n",
    "model_finetune.eval()\n",
    "output = model_finetune(input)\n",
    "\n",
    "print(f\"output shape {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7321178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_augment shape (40, 9, 9, 224)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 0\n",
    "\n",
    "init_lr = lr * batch_size / 256\n",
    "\n",
    "torch.cuda.set_device(gpu)\n",
    "model_finetune = model_finetune.cuda(gpu)\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "\n",
    "# optimize only the linear classifier\n",
    "parameters = list(filter(lambda p: p.requires_grad, model_finetune.parameters()))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(parameters, init_lr,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=weight_decay)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "\n",
    "print(f\"data_augment shape {data_augment.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d915ed95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune_X_train shape: torch.Size([40, 224, 9, 9])\n",
      "Train shape: torch.Size([20, 224, 9, 9]), Validation shape: torch.Size([20, 224, 9, 9])\n",
      "generate data loader using seed\n",
      "torch.Size([20])\n",
      "Train loader size: 1, Validation loader size: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Example usage\n",
    "class CustomDatasetFinetune(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (Tensor or list of Tensors): Preloaded images of shape (N, 9, 9, 224)\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.images = images  # Assuming it's a list or tensor\n",
    "        self.transform = transform\n",
    "        self.label = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img1 = self.transform(img)  # First augmentation\n",
    "        \n",
    "            return img1, label  # Return both augmented versions\n",
    "        \n",
    "        return img, label  # If no transform is provided, return the original image twice\n",
    "    \n",
    "finetune_preloaded_images = data_augment  \n",
    "finetune_X = torch.tensor(finetune_preloaded_images)\n",
    "finetune_X= finetune_X.to(torch.float32)\n",
    "finetune_X = finetune_X.permute(0, 3, 1, 2)\n",
    "print(f\"finetune_X_train shape: {finetune_X.shape}\")\n",
    "\n",
    "finetune_y = torch.tensor(label_augment)\n",
    "#\n",
    "# Define transformations if needed\n",
    "\n",
    "testSize = test_size\n",
    "finetune_X_train, finetune_X_val, finetune_y_train, finetune_y_val = train_test_split(finetune_X, finetune_y, test_size = testSize, random_state=seed, stratify=finetune_y)\n",
    "print(f\"Train shape: {finetune_X_train.shape}, Validation shape: {finetune_X_val.shape}\")\n",
    "\n",
    "finetune_train_dataset = CustomDatasetFinetune(finetune_X_train, finetune_y_train)\n",
    "finetune_val_dataset = CustomDatasetFinetune(finetune_X_val, finetune_y_val)\n",
    "\n",
    "train_sampler = None\n",
    "\n",
    "if seeded_run:\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    \n",
    "    finetune_train_loader = DataLoader(\n",
    "        finetune_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    finetune_val_loader = DataLoader(\n",
    "        finetune_val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # set to True if needed\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        generator=g\n",
    "    )\n",
    "    \n",
    "    print(\"generate data loader using seed\")\n",
    "else:\n",
    "    finetune_train_loader = DataLoader(finetune_train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=False)\n",
    "    finetune_val_loader = DataLoader(finetune_val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "# 7. Check Output\n",
    "\n",
    "batch1 = next(iter(finetune_train_loader))\n",
    "\n",
    "print(batch1[1].size())\n",
    "print(f\"Train loader size: {len(finetune_train_loader)}, Validation loader size: {len(finetune_val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b237e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = FinetuneAverageMeter('Time', ':6.3f')\n",
    "    data_time = FinetuneAverageMeter('Data', ':6.3f')\n",
    "    losses = FinetuneAverageMeter('Loss', ':.4e')\n",
    "    top1 = FinetuneAverageMeter('Acc@1', ':6.2f')\n",
    "    progress = FinetuneProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    \"\"\"\n",
    "    Switch to eval mode:\n",
    "    Under the protocol of linear classification on frozen features/models,\n",
    "    it is not legitimate to change any part of the pre-trained model.\n",
    "    BatchNorm in train mode may revise running mean/std (even if it receives\n",
    "    no gradient), which are part of the model parameters too.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        gpu = 0\n",
    "        images = images.cuda(gpu, non_blocking=True)\n",
    "        target = target.cuda(gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, = finetune_accuracy(output, target, topk=(1,))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        print_freq = 10\n",
    "        if i % print_freq == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "\n",
    "def finetune_validate(val_loader, model, criterion):\n",
    "    batch_time = FinetuneAverageMeter('Time', ':6.3f')\n",
    "    losses = FinetuneAverageMeter('Loss', ':.4e')\n",
    "    top1 = FinetuneAverageMeter('Acc@1', ':6.2f')\n",
    "  \n",
    "    progress = FinetuneProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "       \n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "      \n",
    "            gpu = 0\n",
    "            images = images.cuda(gpu, non_blocking=True)\n",
    "            target = target.cuda(gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, = finetune_accuracy(output, target, topk=(1,))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            # top5.update(acc5[0], images.size(0))\n",
    "            print(f\"in validation finction {acc1}\")\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            print_freq = 10\n",
    "            if i % print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def finetune_save_checkpoint(timestamp, epoch, state, is_best, filename='models/checkpoint.pth.tar'):\n",
    "    filename='models/finetune/{}_model.pth.tar'.format(timestamp)\n",
    "    torch.save(state, filename)\n",
    "    # if is_best:\n",
    "    #     shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "def finetune_sanity_check(state_dict, pretrained_weights):\n",
    "    \"\"\"\n",
    "    Linear classifier should not change any weights other than the linear layer.\n",
    "    This sanity check asserts nothing wrong happens (e.g., BN stats updated).\n",
    "    \"\"\"\n",
    "    print(\"=> loading '{}' for sanity check\".format(pretrained_weights))\n",
    "    checkpoint = torch.load(pretrained_weights, map_location=\"cpu\")\n",
    "    state_dict_pre = checkpoint['state_dict']\n",
    "\n",
    "    for k in list(state_dict.keys()):\n",
    "        # Ignore fc layer\n",
    "        if 'fc.weight' in k or 'fc.bias' in k:\n",
    "            continue\n",
    "\n",
    "        # Adjust key mapping to match checkpoint format\n",
    "        k_pre = k.replace('module.encoder.', '')  # Remove unnecessary prefix\n",
    "\n",
    "        # Skip missing keys\n",
    "        if k_pre not in state_dict_pre:\n",
    "            print(f\"Warning: {k_pre} not found in pretrained model. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Check if tensor shapes match before comparing values\n",
    "        if state_dict[k].shape != state_dict_pre[k_pre].shape:\n",
    "            print(f\"Warning: Shape mismatch for {k}: {state_dict[k].shape} vs {state_dict_pre[k_pre].shape}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Assert that the weights remain unchanged\n",
    "        assert ((state_dict[k].cpu() == state_dict_pre[k_pre]).all()), \\\n",
    "            '{} is changed in linear classifier training.'.format(k)\n",
    "\n",
    "    print(\"=> sanity check passed.\")\n",
    "\n",
    "\n",
    "\n",
    "class FinetuneAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class FinetuneProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def finetune_adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = cur_lr\n",
    "\n",
    "\n",
    "def finetune_accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8982a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.features.0.weight: requires_grad=False\n",
      "encoder.features.0.bias: requires_grad=False\n",
      "encoder.classifier.0.weight: requires_grad=False\n",
      "encoder.classifier.0.bias: requires_grad=False\n",
      "encoder.classifier.1.weight: requires_grad=False\n",
      "encoder.classifier.1.bias: requires_grad=False\n",
      "encoder.classifier.3.weight: requires_grad=False\n",
      "encoder.classifier.4.weight: requires_grad=False\n",
      "encoder.classifier.4.bias: requires_grad=False\n",
      "encoder.classifier.6.weight: requires_grad=False\n",
      "encoder.classifier.6.bias: requires_grad=False\n",
      "encoder.added_classifier.0.weight: requires_grad=True\n",
      "encoder.added_classifier.0.bias: requires_grad=True\n",
      "encoder.added_classifier.3.weight: requires_grad=True\n",
      "encoder.added_classifier.3.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_finetune.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa72c1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/1]\tTime  0.111 ( 0.111)\tData  0.003 ( 0.003)\tLoss 7.0684e-01 (7.0684e-01)\tAcc@1  35.00 ( 35.00)\n",
      "in validation finction tensor([20.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.110 ( 0.110)\tLoss 7.0414e-01 (7.0414e-01)\tAcc@1  20.00 ( 20.00)\n",
      " * Acc@1 20.000\n",
      "✅ Epoch 1: New best Acc@1: 20.00. Model saved.\n",
      "Epoch: [1][0/1]\tTime  0.011 ( 0.011)\tData  0.000 ( 0.000)\tLoss 6.9797e-01 (6.9797e-01)\tAcc@1  20.00 ( 20.00)\n",
      "in validation finction tensor([65.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.015 ( 0.015)\tLoss 6.8504e-01 (6.8504e-01)\tAcc@1  65.00 ( 65.00)\n",
      " * Acc@1 65.000\n",
      "✅ Epoch 2: New best Acc@1: 65.00. Model saved.\n",
      "Epoch: [2][0/1]\tTime  0.022 ( 0.022)\tData  0.000 ( 0.000)\tLoss 6.8369e-01 (6.8369e-01)\tAcc@1  60.00 ( 60.00)\n",
      "in validation finction tensor([65.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.010 ( 0.010)\tLoss 6.6398e-01 (6.6398e-01)\tAcc@1  65.00 ( 65.00)\n",
      " * Acc@1 65.000\n",
      "❌ Epoch 3: No improvement. Patience counter: 1/50\n",
      "Epoch: [3][0/1]\tTime  0.016 ( 0.016)\tData  0.000 ( 0.000)\tLoss 6.6812e-01 (6.6812e-01)\tAcc@1  60.00 ( 60.00)\n",
      "in validation finction tensor([65.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.012 ( 0.012)\tLoss 6.4491e-01 (6.4491e-01)\tAcc@1  65.00 ( 65.00)\n",
      " * Acc@1 65.000\n",
      "❌ Epoch 4: No improvement. Patience counter: 2/50\n",
      "Epoch: [4][0/1]\tTime  0.006 ( 0.006)\tData  0.002 ( 0.002)\tLoss 6.5457e-01 (6.5457e-01)\tAcc@1  60.00 ( 60.00)\n",
      "in validation finction tensor([65.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.010 ( 0.010)\tLoss 6.2580e-01 (6.2580e-01)\tAcc@1  65.00 ( 65.00)\n",
      " * Acc@1 65.000\n",
      "❌ Epoch 5: No improvement. Patience counter: 3/50\n",
      "Epoch: [5][0/1]\tTime  0.007 ( 0.007)\tData  0.000 ( 0.000)\tLoss 6.4110e-01 (6.4110e-01)\tAcc@1  60.00 ( 60.00)\n",
      "in validation finction tensor([65.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.016 ( 0.016)\tLoss 6.0785e-01 (6.0785e-01)\tAcc@1  65.00 ( 65.00)\n",
      " * Acc@1 65.000\n",
      "❌ Epoch 6: No improvement. Patience counter: 4/50\n",
      "Epoch: [6][0/1]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tLoss 6.2899e-01 (6.2899e-01)\tAcc@1  60.00 ( 60.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.024 ( 0.024)\tLoss 5.9185e-01 (5.9185e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "✅ Epoch 7: New best Acc@1: 75.00. Model saved.\n",
      "Epoch: [7][0/1]\tTime  0.016 ( 0.016)\tData  0.000 ( 0.000)\tLoss 6.1852e-01 (6.1852e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.011 ( 0.011)\tLoss 5.7773e-01 (5.7773e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 8: No improvement. Patience counter: 1/50\n",
      "Epoch: [8][0/1]\tTime  0.004 ( 0.004)\tData  0.002 ( 0.002)\tLoss 6.0940e-01 (6.0940e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.020 ( 0.020)\tLoss 5.6524e-01 (5.6524e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 9: No improvement. Patience counter: 2/50\n",
      "Epoch: [9][0/1]\tTime  0.012 ( 0.012)\tData  0.000 ( 0.000)\tLoss 6.0109e-01 (6.0109e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.012 ( 0.012)\tLoss 5.5420e-01 (5.5420e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 10: No improvement. Patience counter: 3/50\n",
      "Epoch: [10][0/1]\tTime  0.010 ( 0.010)\tData  0.002 ( 0.002)\tLoss 5.9351e-01 (5.9351e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.006 ( 0.006)\tLoss 5.4460e-01 (5.4460e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 11: No improvement. Patience counter: 4/50\n",
      "Epoch: [11][0/1]\tTime  0.016 ( 0.016)\tData  0.000 ( 0.000)\tLoss 5.8658e-01 (5.8658e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.016 ( 0.016)\tLoss 5.3644e-01 (5.3644e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 12: No improvement. Patience counter: 5/50\n",
      "Epoch: [12][0/1]\tTime  0.013 ( 0.013)\tData  0.000 ( 0.000)\tLoss 5.8037e-01 (5.8037e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.011 ( 0.011)\tLoss 5.2970e-01 (5.2970e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 13: No improvement. Patience counter: 6/50\n",
      "Epoch: [13][0/1]\tTime  0.013 ( 0.013)\tData  0.000 ( 0.000)\tLoss 5.7505e-01 (5.7505e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.010 ( 0.010)\tLoss 5.2440e-01 (5.2440e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 14: No improvement. Patience counter: 7/50\n",
      "Epoch: [14][0/1]\tTime  0.011 ( 0.011)\tData  0.003 ( 0.003)\tLoss 5.7075e-01 (5.7075e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([75.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.002 ( 0.002)\tLoss 5.2041e-01 (5.2041e-01)\tAcc@1  75.00 ( 75.00)\n",
      " * Acc@1 75.000\n",
      "❌ Epoch 15: No improvement. Patience counter: 8/50\n",
      "Epoch: [15][0/1]\tTime  0.018 ( 0.018)\tData  0.010 ( 0.010)\tLoss 5.6745e-01 (5.6745e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([80.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.014 ( 0.014)\tLoss 5.1757e-01 (5.1757e-01)\tAcc@1  80.00 ( 80.00)\n",
      " * Acc@1 80.000\n",
      "✅ Epoch 16: New best Acc@1: 80.00. Model saved.\n",
      "Epoch: [16][0/1]\tTime  0.013 ( 0.013)\tData  0.000 ( 0.000)\tLoss 5.6507e-01 (5.6507e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([80.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.011 ( 0.011)\tLoss 5.1570e-01 (5.1570e-01)\tAcc@1  80.00 ( 80.00)\n",
      " * Acc@1 80.000\n",
      "❌ Epoch 17: No improvement. Patience counter: 1/50\n",
      "Epoch: [17][0/1]\tTime  0.008 ( 0.008)\tData  0.002 ( 0.002)\tLoss 5.6349e-01 (5.6349e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([80.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.012 ( 0.012)\tLoss 5.1462e-01 (5.1462e-01)\tAcc@1  80.00 ( 80.00)\n",
      " * Acc@1 80.000\n",
      "❌ Epoch 18: No improvement. Patience counter: 2/50\n",
      "Epoch: [18][0/1]\tTime  0.011 ( 0.011)\tData  0.000 ( 0.000)\tLoss 5.6258e-01 (5.6258e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([80.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.012 ( 0.012)\tLoss 5.1412e-01 (5.1412e-01)\tAcc@1  80.00 ( 80.00)\n",
      " * Acc@1 80.000\n",
      "❌ Epoch 19: No improvement. Patience counter: 3/50\n",
      "Epoch: [19][0/1]\tTime  0.010 ( 0.010)\tData  0.002 ( 0.002)\tLoss 5.6216e-01 (5.6216e-01)\tAcc@1  65.00 ( 65.00)\n",
      "in validation finction tensor([80.], device='cuda:0')\n",
      "Test: [0/1]\tTime  0.012 ( 0.012)\tLoss 5.1400e-01 (5.1400e-01)\tAcc@1  80.00 ( 80.00)\n",
      " * Acc@1 80.000\n",
      "❌ Epoch 20: No improvement. Patience counter: 4/50\n"
     ]
    }
   ],
   "source": [
    "best_acc1 = 0.0\n",
    "patience = 50  # Adjust as needed\n",
    "patience_counter = 0\n",
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "start_epoch = 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_finetune.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    finetune_adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "\n",
    "    # Train for one epoch\n",
    "    finetune_train(finetune_train_loader, model_finetune, criterion, optimizer, epoch)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    acc1 = finetune_validate(finetune_val_loader, model_finetune, criterion)\n",
    "\n",
    "    # Check if current accuracy is the best\n",
    "    is_best = acc1 > best_acc1\n",
    "\n",
    "    if is_best:\n",
    "        best_acc1 = acc1\n",
    "        patience_counter = 0\n",
    "\n",
    "        # Save best model only\n",
    "        finetune_save_checkpoint(timestamp, epoch, {\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': 'vgg16',\n",
    "            'state_dict': model_finetune.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best=True)\n",
    "\n",
    "        print(f\"✅ Epoch {epoch+1}: New best Acc@1: {best_acc1:.2f}. Model saved.\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"❌ Epoch {epoch+1}: No improvement. Patience counter: {patience_counter}/{patience}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"⏹️ Early stopping triggered at epoch {epoch+1}. Best Acc@1: {best_acc1:.2f}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "828ce5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250726_120310\n"
     ]
    }
   ],
   "source": [
    "train_time = time.time()\n",
    "\n",
    "\n",
    "print(timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c42bbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9859cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWithDataset(n): \n",
    "    hsi_test = dataset[n]\n",
    "\n",
    "    test_img = hsi_test.img\n",
    "    test_gt = hsi_test.gt\n",
    "\n",
    "    patch_size = 9\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    height = test_img.shape[0]\n",
    "    width = test_img.shape[1]\n",
    "\n",
    "    matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "    print(f\"img shape: {test_img.shape}\")\n",
    "    print(f\"img shape after padding {matrix.shape}\")\n",
    "    print(f\"number of pixel {width * height}\")\n",
    "\n",
    "    print(f\"ground truth shape: {test_gt.shape}\")\n",
    "\n",
    "    indices0 = np.argwhere(test_gt == 0)\n",
    "    indices1 = np.argwhere(test_gt == 1)\n",
    "\n",
    "    print(f\"indices = 0 shape: {indices0.shape}\")\n",
    "    print(f\"indices = 1 shape: {indices1.shape}\")\n",
    "\n",
    "    num_samples = 5000\n",
    "\n",
    "    random_indices0 = indices0[np.random.choice(len(indices0), num_samples, replace=False)]\n",
    "    random_indices1 = indices1[np.random.choice(len(indices1), num_samples, replace=False)]\n",
    "\n",
    "    test_indices = np.vstack((random_indices0, random_indices1))\n",
    "\n",
    "    print(test_indices.shape)\n",
    "\n",
    "    return test_indices, test_gt, matrix, random_indices0.shape, random_indices1.shape\n",
    "\n",
    "\n",
    "def testWithWholeDataset(n): \n",
    "    hsi_test = dataset[n]\n",
    "\n",
    "    test_img = hsi_test.img\n",
    "    gt= hsi_test.gt\n",
    "\n",
    "    patch_size = 9\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    height = test_img.shape[0]\n",
    "    width = test_img.shape[1]\n",
    "\n",
    "    matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "    print(f\"img shape: {test_img.shape}\")\n",
    "    print(f\"img shape after padding {matrix.shape}\")\n",
    "    print(f\"number of pixel {width * height}\")\n",
    "\n",
    "    print(f\"ground truth shape: {gt.shape}\")\n",
    "\n",
    "    indices0 = np.argwhere(gt == 0)\n",
    "    indices1 = np.argwhere(gt == 1)\n",
    "\n",
    "    print(f\"indices = 0 shape: {indices0.shape}\")\n",
    "    print(f\"indices = 1 shape: {indices1.shape}\")\n",
    "\n",
    "    return matrix, gt, indices0.shape, indices1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a0cfff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(model, batch_input, device):\n",
    "    model.eval()\n",
    "    batch_input = batch_input.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_input)\n",
    "        # Apply softmax to get class probabilities\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "        # Get predicted class (0 or 1)\n",
    "        predicted_classes = torch.argmax(probabilities, dim=1).cpu().numpy()\n",
    "\n",
    "        # Get probability of class 1 (positive class) — required for ROC\n",
    "        positive_class_probs = probabilities[:, 1].cpu().numpy()\n",
    "\n",
    "    \n",
    "\n",
    "    return predicted_classes, positive_class_probs\n",
    "\n",
    "\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, matrix, gt, half_patch, expected_shape):\n",
    "        self.matrix = matrix\n",
    "        self.gt = gt\n",
    "        self.half_patch = half_patch\n",
    "        self.expected_shape = expected_shape\n",
    "        self.size_x, self.size_y = matrix.shape[0], matrix.shape[1]\n",
    "        self.valid_coords = [\n",
    "            (x, y)\n",
    "            for x in range(half_patch, self.size_x - half_patch)\n",
    "            for y in range(half_patch, self.size_y - half_patch)\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.valid_coords[idx]\n",
    "        true_label = self.gt[x - self.half_patch, y - self.half_patch]\n",
    "\n",
    "        selected_rows = self.matrix[x- self.half_patch:x + 2 * self.half_patch + 1 - self.half_patch, :]\n",
    "        testing_patch = selected_rows[:, y - self.half_patch:y + 2 * self.half_patch + 1 - self.half_patch]\n",
    "\n",
    "        # Verify patch size\n",
    "        if testing_patch.shape != self.expected_shape:\n",
    "            raise ValueError(f\"Patch at ({x},{y}) has wrong shape {testing_patch.shape}\")\n",
    "\n",
    "        patch_tensor = torch.tensor(testing_patch, dtype=torch.float32)\n",
    "        patch_tensor = patch_tensor.permute(2, 0, 1)  # (C, H, W)\n",
    "\n",
    "        return patch_tensor, true_label, x, y  # Also return (x, y) for positioning later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "575b807c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\finetune\\20250726_120310_model.pth.tar\n",
      "Creating model 20250726_120310_model.pth.tar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\submit-repo-ta\\env_repo_ta\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and moved to device\n",
      "saved_model for testing Parameter 30138242\n",
      "VGG16_HSI(\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "    )\n",
      "    (added_classifier): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_8900\\3084895309.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 64  # You can change this depending on your GPU capacity\n",
    "\n",
    "model_path = rf\"models\\finetune\\{timestamp}_model.pth.tar\"\n",
    "model_name = model_path.split('\\\\')[-1]\n",
    "print(model_path)\n",
    "\n",
    "print(f\"Creating model {model_name}...\")\n",
    "saved_model = VGG16_HSI().to(device)\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "saved_model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Model loaded and moved to device\")\n",
    "\n",
    "saved_model_parameters = sum(p.numel() for p in saved_model.parameters())\n",
    "print(f\"saved_model for testing Parameter {saved_model_parameters}\")\n",
    "print(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13871a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScoreTest(prediction, y_probs, groundtruth):\n",
    "    groundtruths = groundtruth\n",
    "    groundtruth_in = []\n",
    "\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "    predictions = prediction\n",
    "    prediction_in = []\n",
    "\n",
    "    for x in predictions:\n",
    "        for y in x:\n",
    "            prediction_in.append(y)\n",
    "\n",
    "\n",
    "    y_prob_in = []\n",
    "\n",
    "    for x in y_probs:\n",
    "        for y in x:\n",
    "            y_prob_in.append(y)\n",
    "\n",
    "    print(len(groundtruth_in))\n",
    "    print(len(prediction_in))\n",
    "    print(len(y_prob_in))\n",
    "\n",
    "    y_test = groundtruth_in\n",
    "    y_pred = prediction_in\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in zip(y_test, y_pred):\n",
    "        total += 1\n",
    "        if x == y:\n",
    "            correct += 1\n",
    "    \n",
    "    print(f'{correct}/{total}')\n",
    "\n",
    "    y_test_np = np.array([label.item() for label in y_test])\n",
    "    # Ensure labels are binary (0 and 1)\n",
    "    # print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "    # # Check if y_pred is probability (float) or hard prediction (int)\n",
    "    # print(\"Sample y_pred values:\", y_pred[:5])\n",
    "\n",
    "    test_df = pd.DataFrame(\n",
    "        {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Two Models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "    y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "    # Precision, Recall, F1\n",
    "    precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Overall Accuracy (OA)\n",
    "    oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Average Accuracy (AA) — mean of per-class accuracies\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    aa = per_class_acc.mean()\n",
    "\n",
    "    # Print all metrics\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"OA:        {oa:.4f}\")\n",
    "    print(f\"AA:        {aa:.4f}\")\n",
    "\n",
    "    performance = {\n",
    "        'AUC': float(roc_auc),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'F1 Score': float(f1),\n",
    "        'OA': float(oa),\n",
    "        'AA': float(aa),\n",
    "    }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a467139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(prediction, y_probs, groundtruth):\n",
    "    groundtruths = groundtruth\n",
    "    groundtruth_in = []\n",
    "\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "    predictions = prediction\n",
    "    prediction_in = []\n",
    "\n",
    "    for x in predictions:\n",
    "        for y in x:\n",
    "            prediction_in.append(y)\n",
    "\n",
    "\n",
    "    y_prob_in = []\n",
    "\n",
    "    for x in y_probs:\n",
    "        for y in x:\n",
    "            y_prob_in.append(y)\n",
    "\n",
    "    # print(len(groundtruth_in))\n",
    "    # print(len(prediction_in))\n",
    "    # print(len(y_prob_in))\n",
    "\n",
    "    y_test = groundtruth_in\n",
    "    y_pred = prediction_in\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in zip(y_test, y_pred):\n",
    "        total += 1\n",
    "        if x == y:\n",
    "            correct += 1\n",
    "    \n",
    "    print(f'{correct}/{total}')\n",
    "\n",
    "    y_test_np = np.array([label.item() for label in y_test])\n",
    "    # Ensure labels are binary (0 and 1)\n",
    "    # print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "    # # Check if y_pred is probability (float) or hard prediction (int)\n",
    "    # print(\"Sample y_pred values:\", y_pred[:5])\n",
    "\n",
    "    test_df = pd.DataFrame(\n",
    "        {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Two Models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "    y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "    # Precision, Recall, F1\n",
    "    precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Overall Accuracy (OA)\n",
    "    oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Average Accuracy (AA) — mean of per-class accuracies\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    aa = per_class_acc.mean()\n",
    "\n",
    "    # Print all metrics\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"OA:        {oa:.4f}\")\n",
    "    print(f\"AA:        {aa:.4f}\")\n",
    "\n",
    "    performance = {\n",
    "        'AUC': float(roc_auc),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'F1 Score': float(f1),\n",
    "        'OA': float(oa),\n",
    "        'AA': float(aa),\n",
    "    }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9ae6c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tes: 0\n",
      "dataset: 1\n",
      "img shape: (1243, 684, 224)\n",
      "img shape after padding (1251, 692, 224)\n",
      "number of pixel 850212\n",
      "ground truth shape: (1243, 684)\n",
      "indices = 0 shape: (820876, 2)\n",
      "indices = 1 shape: (29336, 2)\n",
      "820876\n",
      "29336\n",
      "generate data loader using seed\n",
      "torch.Size([64, 224, 9, 9])\n",
      "torch.Size([64])\n",
      "data loader size: 13285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 13285/13285 [10:05<00:00, 21.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823465/850212\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7730\n",
      "Recall:    0.6786\n",
      "F1 Score:  0.7150\n",
      "OA:        0.9685\n",
      "AA:        0.6786\n",
      "correct0 = 812692\n",
      "correct1 = 10773\n",
      "Score: 823465/850212\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "scores = []\n",
    "\n",
    "groundtruth = []\n",
    "prediction = []\n",
    "y_probs = []\n",
    "\n",
    "\n",
    "if mode == \"test\":\n",
    "    for hsi_test in range(len(dataset)):\n",
    "        print(f\"tes: {hsi_test + 1}\")\n",
    "\n",
    "        hsi_prediction = []\n",
    "        hsi_yprobs = []\n",
    "        hsi_groundtruth = []\n",
    "\n",
    "\n",
    "        test_indices, test_gt, matrix, indices_0_shape, indices_1_shape = testWithDataset(hsi_test)\n",
    "\n",
    "        total = len(test_indices)\n",
    "        correct0 = 0\n",
    "        correct1 = 0\n",
    "\n",
    "        input_patches = []\n",
    "        true_labels = []\n",
    "\n",
    "        # Prepare all patches\n",
    "        for x_pos, y_pos in test_indices:\n",
    "            true_label = test_gt[x_pos][y_pos]\n",
    "\n",
    "            selected_rows = matrix[x_pos:x_pos + 2*half_patch + 1, :]\n",
    "            testing_patch = selected_rows[:, y_pos:y_pos + 2*half_patch + 1]\n",
    "\n",
    "            patch_tensor = torch.tensor(testing_patch, dtype=torch.float32)\n",
    "            patch_tensor = patch_tensor.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "            input_patches.append(patch_tensor)\n",
    "            true_labels.append(true_label)\n",
    "\n",
    "        input_patches = torch.cat(input_patches, dim=0)  # Shape: (N, C, H, W)\n",
    "        true_labels = torch.tensor(true_labels)\n",
    "\n",
    "        # Process in batches\n",
    "        for i in tqdm(range(0, total, batch_size), desc=\"Predicting\"):\n",
    "            batch = input_patches[i:i+batch_size]\n",
    "            labels = true_labels[i:i+batch_size]\n",
    "\n",
    "            groundtruth.append(labels)\n",
    "            \n",
    "\n",
    "            preds, postive_class_probs = predict_batch(saved_model, batch, device)\n",
    "\n",
    "            prediction.append(preds)\n",
    "            hsi_prediction.append(preds)\n",
    "\n",
    "            hsi_yprobs.append(postive_class_probs)\n",
    "            y_probs.append(postive_class_probs)\n",
    "\n",
    "            for j in range(len(preds)):\n",
    "                index = i + j\n",
    "                hsi_groundtruth.append(labels[j])\n",
    "                # print(f\"{index+1}: prediction = {preds[j]}, confidence: {confs[j]:.4f}, expected: {labels[j].item()}\")\n",
    "                if preds[j] == labels[j].item():\n",
    "                    if labels[j].item() == 0:\n",
    "                        correct0 += 1\n",
    "                    elif labels[j] == 1:\n",
    "                        correct1 += 1\n",
    "\n",
    "        performance_metrics = getScoreTest(hsi_prediction, hsi_yprobs, hsi_groundtruth) \n",
    "        correct = correct0 + correct1\n",
    "        print(f\"Score: {correct}/{total}\")\n",
    "        \n",
    "        score = {\n",
    "            'dataset': hsi_test,\n",
    "            'class0_size': indices_0_shape[0],\n",
    "            'class1_size': indices_1_shape[0],\n",
    "            'correct_0': correct0,\n",
    "            'correct_1': correct1,\n",
    "            'correct_total': correct,\n",
    "            'total': total,\n",
    "            'AUC': float(performance_metrics['AUC']),\n",
    "            'precision': float(performance_metrics['precision']),\n",
    "            'recall': float(performance_metrics['recall']),\n",
    "            'F1 Score': float(performance_metrics['F1 Score']),\n",
    "            'OA': float(performance_metrics['OA']),\n",
    "            'AA': float(performance_metrics['AA']),\n",
    "        }\n",
    "        scores.append(score)\n",
    "\n",
    "if mode == \"full\":\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    os.makedirs(f\"predictions/{timestamp}\", exist_ok=True)\n",
    "    for hsi_full in range(len(dataset)):\n",
    "        if hsi_full > 0:\n",
    "            break\n",
    "        print(f\"tes: {hsi_full}\")\n",
    "        # if hsi_full > 2:\n",
    "        #     break\n",
    "        print(f\"dataset: {hsi_full + 1}\")\n",
    "        hsi_prediction = []\n",
    "        hsi_yprobs = []\n",
    "        hsi_groundtruth = []\n",
    "\n",
    "        score = []\n",
    "        patch_size = 9\n",
    "        half_patch = patch_size // 2\n",
    "\n",
    "        data_sampler = None\n",
    "        batch_size = 64\n",
    "\n",
    "        correct0 = 0\n",
    "        correct1 = 0\n",
    "        matrix = []\n",
    "        gt = []\n",
    "        expected_patch_shape = []\n",
    "        dataset_patches = []\n",
    "        data_loader = []\n",
    "        patch_tensor = []\n",
    "        true_label = [] \n",
    "        x = []\n",
    "        y = []\n",
    "        pred_matrix = []\n",
    "\n",
    "        matrix, gt, indices_0_shape, indices_1_shape = testWithWholeDataset(hsi_full)\n",
    "        print(indices_0_shape[0])\n",
    "        print(indices_1_shape[0])\n",
    "\n",
    "        expected_patch_shape = (2 * half_patch + 1, 2 * half_patch + 1, matrix.shape[2])\n",
    "        dataset_patches = PatchDataset(matrix, gt, half_patch, expected_patch_shape)\n",
    "\n",
    "        if seeded_run:\n",
    "            g = torch.Generator()\n",
    "            g.manual_seed(seed)\n",
    "\n",
    "            data_loader = DataLoader(\n",
    "                dataset_patches,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,  # set to True if needed\n",
    "                num_workers=0,\n",
    "                pin_memory=True,\n",
    "                drop_last=False,\n",
    "                generator=g\n",
    "            )\n",
    "            print(\"generate data loader using seed\")\n",
    "        else:\n",
    "            data_loader = DataLoader(dataset_patches, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        patch_tensor, true_label, x, y = next(iter(data_loader))\n",
    "\n",
    "        print(patch_tensor.size())\n",
    "        print(true_label.size())\n",
    "        print(f\"data loader size: {len(data_loader)}\")\n",
    "\n",
    "        pred_matrix = np.full(gt.shape, -1, dtype=np.int32)\n",
    "        correct = 0\n",
    "\n",
    "        for input_batch, label_batch, x_batch, y_batch in tqdm(data_loader, desc=\"Predicting\"):\n",
    "\n",
    "\n",
    "            preds, confs = predict_batch(saved_model, input_batch, device)\n",
    "\n",
    "            hsi_prediction.append(preds)\n",
    "            prediction.append(preds)\n",
    "            hsi_yprobs.append(confs)\n",
    "            y_probs.append(confs)\n",
    "            \n",
    "            label_batch = label_batch.numpy()\n",
    "            x_batch = x_batch.numpy()\n",
    "            y_batch = y_batch.numpy()\n",
    "\n",
    "            for pred, label, x, y in zip(preds, label_batch, x_batch, y_batch):\n",
    "                hsi_groundtruth.append(label)\n",
    "                groundtruth.append(label)\n",
    "                pred_matrix[x - half_patch, y - half_patch] = pred\n",
    "                if pred == label:\n",
    "                    if label == 0:\n",
    "                        correct0 += 1\n",
    "                    elif label == 1:\n",
    "                        correct1 += 1\n",
    "\n",
    "        performance_metrics = getScore(hsi_prediction, hsi_yprobs, hsi_groundtruth)      \n",
    "            \n",
    "        correct = correct0+correct1\n",
    "        print(f\"correct0 = {correct0}\")\n",
    "        print(f\"correct1 = {correct1}\")\n",
    "        total = gt.shape[0] * gt.shape[1]\n",
    "        print(f\"Score: {correct}/{total}\")\n",
    "\n",
    "        score = {\n",
    "            'dataset': hsi_full,\n",
    "            'class0_size': indices_0_shape[0],\n",
    "            'class1_size': indices_1_shape[0],\n",
    "            'correct_0': correct0,\n",
    "            'correct_1': correct1,\n",
    "            'correct_total': correct,\n",
    "            'total': total,\n",
    "            'AUC': float(performance_metrics['AUC']),\n",
    "            'precision': float(performance_metrics['precision']),\n",
    "            'recall': float(performance_metrics['recall']),\n",
    "            'F1 Score': float(performance_metrics['F1 Score']),\n",
    "            'OA': float(performance_metrics['OA']),\n",
    "            'AA': float(performance_metrics['AA']),\n",
    "        }\n",
    "        # print(score)\n",
    "        scores.append(score)\n",
    "        # Save prediction matrix\n",
    "        # timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        np.save(f\"predictions/{timestamp}/results {hsi_full} MyMethod.npy\", pred_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3802cccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: 0\t 812692/820876\t 10773/29336\t 823465/850212\t 0.9685407874741829 0.6786290710868791\n",
      "dataset: 0\t AUC: 0.9669696473034792 precission: 0.772977413486929 recall: 0.6786290710868791 F1 SCore0.7149811109969174\n",
      "total: \t\t 812692/410438.0 \t 10773/14668.0 \t 823465/850212\n",
      "acc: 0.9685407874741829\n"
     ]
    }
   ],
   "source": [
    "all_correct = 0\n",
    "all_total = 0\n",
    "all_correct0 = 0\n",
    "all_correct1 = 0\n",
    "class0_total = 0\n",
    "class1_total = 0\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    dataset = score['dataset']\n",
    "    correct0 = score['correct_0']\n",
    "    correct1 = score['correct_1']\n",
    "    class0_size = score['class0_size']\n",
    "    class1_size = score['class1_size']\n",
    "    correct = score['correct_total']\n",
    "    total = score['total']\n",
    "    auc_score = score['AUC']\n",
    "    precission = score['precision']\n",
    "    recall = score['recall']\n",
    "    f1 = score['F1 Score']\n",
    "    oa = score['OA']\n",
    "    aa = score['AA']\n",
    "    \n",
    "    print(f\"dataset: {dataset}\\t\", f'{correct0}/{class0_size}\\t', f'{correct1}/{class1_size}\\t', f'{correct}/{total}\\t', f\"{oa}\", f\"{aa}\")\n",
    "\n",
    "    all_correct += correct\n",
    "    all_total += total\n",
    "    all_correct0 += correct0\n",
    "    all_correct1 += correct1\n",
    "    class0_total += class0_size\n",
    "    class1_total += class1_size\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    dataset = score['dataset']\n",
    "    correct0 = score['correct_0']\n",
    "    correct1 = score['correct_1']\n",
    "    class0_size = score['class0_size']\n",
    "    class1_size = score['class1_size']\n",
    "    correct = score['correct_total']\n",
    "    total = score['total']\n",
    "    auc_score = score['AUC']\n",
    "    precission = score['precision']\n",
    "    recall = score['recall']\n",
    "    f1 = score['F1 Score']\n",
    "    oa = score['OA']\n",
    "    aa = score['AA']\n",
    "    print(f\"dataset: {dataset}\\t\", f\"AUC: {auc_score}\", f\"precission: {precission}\", f\"recall: {recall}\", f\"F1 SCore{f1}\")\n",
    "\n",
    "print(f\"total: \\t\\t {all_correct0}/{class0_total/2} \\t {all_correct1}/{class1_total/2} \\t {all_correct}/{all_total}\")\n",
    "\n",
    "print(f\"acc: {all_correct/all_total}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c74a969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_total_score = {\n",
    "    'dataset': 'Total Dataset',\n",
    "    'correct_0': all_correct0,\n",
    "    'correct_1': all_correct1,\n",
    "    'class0_total': class0_total,\n",
    "    'class1_total': class1_total,\n",
    "    'correct_total': all_correct,\n",
    "    'total': all_total\n",
    "}\n",
    "\n",
    "scores.append(all_total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddab0694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850212\n",
      "850212\n",
      "850212\n"
     ]
    }
   ],
   "source": [
    "groundtruths = groundtruth\n",
    "groundtruth_in = []\n",
    "\n",
    "if mode == \"test\":\n",
    "    for x in groundtruths:\n",
    "        for y in x:\n",
    "            groundtruth_in.append(y)    \n",
    "\n",
    "if mode == \"full\":\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "predictions = prediction\n",
    "prediction_in = []\n",
    "\n",
    "for x in predictions:\n",
    "    for y in x:\n",
    "        prediction_in.append(y)\n",
    "\n",
    "\n",
    "y_prob_in = []\n",
    "\n",
    "for x in y_probs:\n",
    "    for y in x:\n",
    "        y_prob_in.append(y)\n",
    "\n",
    "print(len(groundtruth_in))\n",
    "print(len(prediction_in))\n",
    "print(len(y_prob_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e85a806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823465/850212\n"
     ]
    }
   ],
   "source": [
    "y_test = groundtruth_in\n",
    "y_pred = prediction_in\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for x, y in zip(y_test, y_pred):\n",
    "    total += 1\n",
    "    if x == y:\n",
    "        correct += 1\n",
    "\n",
    "print(f'{correct}/{total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a4761e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_test: [0 1]\n",
      "Sample y_pred values: [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n"
     ]
    }
   ],
   "source": [
    "y_test_np = np.array([label.item() for label in y_test])\n",
    "# Ensure labels are binary (0 and 1)\n",
    "print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "# Check if y_pred is probability (float) or hard prediction (int)\n",
    "print(\"Sample y_pred values:\", y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29515cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(\n",
    "    {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Two Models')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6a288ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7730\n",
      "Recall:    0.6786\n",
      "F1 Score:  0.7150\n",
      "OA:        0.9685\n",
      "AA:        0.6786\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "# Precision, Recall, F1\n",
    "precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "# Overall Accuracy (OA)\n",
    "oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Average Accuracy (AA) — mean of per-class accuracies\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "aa = per_class_acc.mean()\n",
    "\n",
    "# Print all metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"OA:        {oa:.4f}\")\n",
    "print(f\"AA:        {aa:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8abb93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {\n",
    "    'AUC': float(roc_auc),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'F1 Score': float(f1),\n",
    "    'OA': float(oa),\n",
    "    'AA': float(aa),\n",
    "}\n",
    "result_json = {\n",
    "    'prediction' : scores,\n",
    "    'performance' : performance,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c0c5d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [{'dataset': 0, 'class0_size': 820876, 'class1_size': 29336, 'correct_0': 812692, 'correct_1': 10773, 'correct_total': 823465, 'total': 850212, 'AUC': 0.9669696473034792, 'precision': 0.772977413486929, 'recall': 0.6786290710868791, 'F1 Score': 0.7149811109969174, 'OA': 0.9685407874741829, 'AA': 0.6786290710868791}, {'dataset': 'Total Dataset', 'correct_0': 812692, 'correct_1': 10773, 'class0_total': 820876, 'class1_total': 29336, 'correct_total': 823465, 'total': 850212}], 'performance': {'AUC': 0.9669696473034792, 'precision': 0.772977413486929, 'recall': 0.6786290710868791, 'F1 Score': 0.7149811109969174, 'OA': 0.9685407874741829, 'AA': 0.6786290710868791}}\n",
      "JSON saved to results.json\n"
     ]
    }
   ],
   "source": [
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "print(result_json)\n",
    "\n",
    "with open(f\"performance/MyMethod {timestamp}_results.json\", \"w\") as f:\n",
    "    json.dump(result_json, f, indent=2)\n",
    "\n",
    "print(\"JSON saved to results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "901b6440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 43.7414 seconds\n",
      "predicting time: 629.3333 seconds\n",
      "Run time: 673.0747 seconds\n",
      "mode used: full\n",
      "finetune Parameter 30138242\n",
      "Pretrain Parameter 34077184\n",
      "saved_model for testing Parameter 30138242\n",
      "20250726_120325\n",
      "seet used: 10\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Train time: {train_time - start_time:.4f} seconds\")\n",
    "print(f\"predicting time: {end_time - train_time:.4f} seconds\")\n",
    "print(f\"Run time: {end_time - start_time:.4f} seconds\")\n",
    "print(f\"mode used: {mode}\")\n",
    "print(f\"finetune Parameter {finetune_parameter}\")\n",
    "print(f\"Pretrain Parameter {pretrain_parameters}\")\n",
    "print(f\"saved_model for testing Parameter {saved_model_parameters}\")\n",
    "print(timestamp)\n",
    "print(f\"seet used: {seed}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_repo_ta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
